{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "from utils import *\n",
    "from model_FCNN import generate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'callback_custom' from '/home/kumamon/src/segDGM_3DCNN/callback_custom.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import keras\n",
    "reload(keras)\n",
    "from keras import backend as K\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "\n",
    "import model_FCNN\n",
    "reload(model_FCNN)\n",
    "from model_FCNN import generate_model\n",
    "\n",
    "import callback_custom\n",
    "reload(callback_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11\n",
    "num_channel = 3\n",
    "\n",
    "# K-fold validation (K=5)\n",
    "n_training = 16\n",
    "n_test = 4\n",
    "\n",
    "idxs_training = list(range(1, 1+16))\n",
    "idxs_test = list(range(17, 17+4))\n",
    "\n",
    "patience = 5\n",
    "model_filename = 'models/outrun_step_{}.h5'\n",
    "csv_filename = 'log/outrun_step_{}.cvs'\n",
    "\n",
    "nb_epoch = 40\n",
    "validation_split = 0.10\n",
    "monitor = 'val_loss'#'val_categorical_accuracy'\n",
    "\n",
    "class_mapper = {0:0}\n",
    "class_mapper.update({ i+1:i for i in range(1, 1+10) })\n",
    "class_mapper_inv = {0:0}\n",
    "class_mapper_inv.update({ i:i+1 for i in range(1, 1+10) })\n",
    "\n",
    "matrix_size = (160, 220, 48)\n",
    "\n",
    "#extraction_step = (3, 3, 3)\n",
    "extraction_step = (6, 6, 3)\n",
    "\n",
    "segment_size = (27, 27, 21)\n",
    "core_size = (9, 9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "MAG_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "R2S_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "label_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_training):\n",
    "    QSM_train[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_train[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_train[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_train[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.stack((QSM_train, MAG_train, R2S_train), axis = 1)\n",
    "#data_train = np.stack((QSM_train,), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "MAG_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "R2S_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "label_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_test):\n",
    "    QSM_test[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_test[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_test[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_test[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = np.stack((QSM_test, MAG_test, R2S_test), axis = 1)\n",
    "#data_test = np.stack((QSM_test,), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intensity normalisation (zero mean and unit variance)\n",
    "input_mean = 127.0\n",
    "input_std = 128.0\n",
    "data_train = (data_train - input_mean) / input_std\n",
    "data_test = (data_test - input_mean) / input_std\n",
    "\n",
    "# Map class label\n",
    "tmp = np.copy(label_train)\n",
    "for class_idx in class_mapper:\n",
    "    label_train[tmp == class_idx] = class_mapper[class_idx]\n",
    "tmp = np.copy(label_test)\n",
    "for class_idx in class_mapper:\n",
    "    label_test[tmp == class_idx] = class_mapper[class_idx]\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEACAYAAABBOusMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb35114588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0,:,:,[29,25]]), scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2731, 3, 27, 27, 21), (2731, 243, 11))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Configure callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('1'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('1'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2457 samples, validate on 274 samples\n",
      "Epoch 1/40\n",
      "2457/2457 [==============================] - 17s 7ms/step - loss: 0.9840 - categorical_accuracy: 0.7623 - val_loss: 0.7589 - val_categorical_accuracy: 0.7744\n",
      "Epoch 2/40\n",
      "2457/2457 [==============================] - 15s 6ms/step - loss: 0.6995 - categorical_accuracy: 0.7873 - val_loss: 0.7682 - val_categorical_accuracy: 0.7902\n",
      "Epoch 3/40\n",
      "2457/2457 [==============================] - 15s 6ms/step - loss: 0.6199 - categorical_accuracy: 0.8058 - val_loss: 0.6587 - val_categorical_accuracy: 0.8111\n",
      "Epoch 4/40\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.4926 - categorical_accuracy: 0.8473 - val_loss: 0.5111 - val_categorical_accuracy: 0.8491\n",
      "Epoch 5/40\n",
      "2457/2457 [==============================] - 15s 6ms/step - loss: 0.3950 - categorical_accuracy: 0.8724 - val_loss: 0.4379 - val_categorical_accuracy: 0.8649\n",
      "Epoch 6/40\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.2887 - categorical_accuracy: 0.9010 - val_loss: 0.3674 - val_categorical_accuracy: 0.8746\n",
      "Epoch 7/40\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.2147 - categorical_accuracy: 0.9210 - val_loss: 0.3180 - val_categorical_accuracy: 0.8883\n",
      "Epoch 8/40\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.1580 - categorical_accuracy: 0.9378 - val_loss: 0.2457 - val_categorical_accuracy: 0.9144\n",
      "Epoch 9/40\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.1379 - categorical_accuracy: 0.9446 - val_loss: 0.2099 - val_categorical_accuracy: 0.9252\n",
      "Epoch 10/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.1191 - categorical_accuracy: 0.95080.001 1e-05\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.1187 - categorical_accuracy: 0.9511 - val_loss: 0.2490 - val_categorical_accuracy: 0.9161\n",
      "Epoch 11/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.1040 - categorical_accuracy: 0.95730.001 1e-05\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.1039 - categorical_accuracy: 0.9574 - val_loss: 0.2341 - val_categorical_accuracy: 0.9214\n",
      "Epoch 12/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.0922 - categorical_accuracy: 0.96200.001 1e-05\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.0922 - categorical_accuracy: 0.9620 - val_loss: 0.3369 - val_categorical_accuracy: 0.9067\n",
      "Epoch 13/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.0780 - categorical_accuracy: 0.96770.001 1e-05\n",
      "2457/2457 [==============================] - 16s 7ms/step - loss: 0.0784 - categorical_accuracy: 0.9675 - val_loss: 0.3309 - val_categorical_accuracy: 0.9101\n",
      "Epoch 14/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.0714 - categorical_accuracy: 0.97070.001 1e-05\n",
      "2457/2457 [==============================] - 16s 7ms/step - loss: 0.0714 - categorical_accuracy: 0.9708 - val_loss: 0.3650 - val_categorical_accuracy: 0.9078\n",
      "Epoch 15/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.0603 - categorical_accuracy: 0.9752\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2457/2457 [==============================] - 16s 7ms/step - loss: 0.0604 - categorical_accuracy: 0.9752 - val_loss: 0.3591 - val_categorical_accuracy: 0.9151\n",
      "Epoch 16/40\n",
      "2457/2457 [==============================] - 16s 7ms/step - loss: 0.1048 - categorical_accuracy: 0.9569 - val_loss: 0.2578 - val_categorical_accuracy: 0.9156\n",
      "Epoch 17/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.0962 - categorical_accuracy: 0.96040.0001 1e-05\n",
      "2457/2457 [==============================] - 16s 7ms/step - loss: 0.0961 - categorical_accuracy: 0.9605 - val_loss: 0.2618 - val_categorical_accuracy: 0.9170\n",
      "Epoch 18/40\n",
      "2457/2457 [==============================] - 16s 7ms/step - loss: 0.0919 - categorical_accuracy: 0.9618 - val_loss: 0.2566 - val_categorical_accuracy: 0.9191\n",
      "Epoch 19/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.0884 - categorical_accuracy: 0.96330.0001 1e-05\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.0884 - categorical_accuracy: 0.9633 - val_loss: 0.2690 - val_categorical_accuracy: 0.9178\n",
      "Epoch 20/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.0854 - categorical_accuracy: 0.9647\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "2457/2457 [==============================] - 16s 7ms/step - loss: 0.0851 - categorical_accuracy: 0.9648 - val_loss: 0.2668 - val_categorical_accuracy: 0.9193\n",
      "Epoch 21/40\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.1120 - categorical_accuracy: 0.9547 - val_loss: 0.2300 - val_categorical_accuracy: 0.9192\n",
      "Epoch 22/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.1047 - categorical_accuracy: 0.95731.001e-05 1e-05\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.1047 - categorical_accuracy: 0.9573 - val_loss: 0.2342 - val_categorical_accuracy: 0.9196\n",
      "Epoch 23/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.1018 - categorical_accuracy: 0.95821.001e-05 1e-05\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.1020 - categorical_accuracy: 0.9582 - val_loss: 0.2409 - val_categorical_accuracy: 0.9185\n",
      "Epoch 24/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.0999 - categorical_accuracy: 0.95891.001e-05 1e-05\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.1002 - categorical_accuracy: 0.9587 - val_loss: 0.2487 - val_categorical_accuracy: 0.9171\n",
      "Epoch 25/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.0988 - categorical_accuracy: 0.95941.001e-05 1e-05\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.0990 - categorical_accuracy: 0.9593 - val_loss: 0.2504 - val_categorical_accuracy: 0.9175\n",
      "Epoch 26/40\n",
      "2432/2457 [============================>.] - ETA: 0s - loss: 0.0978 - categorical_accuracy: 0.95971.001e-05 1e-05\n",
      "2457/2457 [==============================] - 16s 6ms/step - loss: 0.0979 - categorical_accuracy: 0.9597 - val_loss: 0.2520 - val_categorical_accuracy: 0.9176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feafcbc82e8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 47\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21035868368851832, 0.924976089935163]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_patch = extract_patches(read_data(1, 'QSM'), patch_shape=segment_size, extraction_step=(9, 9, 3)).shape[0]\n",
    "len_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3300/3300 [==============================] - 3s 907us/step\n",
      "2\n",
      "3300/3300 [==============================] - 3s 807us/step\n",
      "3\n",
      "3300/3300 [==============================] - 3s 817us/step\n",
      "4\n",
      "3300/3300 [==============================] - 3s 814us/step\n",
      "5\n",
      "3300/3300 [==============================] - 3s 834us/step\n",
      "6\n",
      "3300/3300 [==============================] - 3s 814us/step\n",
      "7\n",
      "3300/3300 [==============================] - 3s 811us/step\n",
      "8\n",
      "3300/3300 [==============================] - 3s 824us/step\n",
      "9\n",
      "3300/3300 [==============================] - 3s 817us/step\n",
      "10\n",
      "3300/3300 [==============================] - 3s 832us/step\n",
      "11\n",
      "3300/3300 [==============================] - 3s 827us/step\n",
      "12\n",
      "3300/3300 [==============================] - 3s 828us/step\n",
      "13\n",
      "3300/3300 [==============================] - 3s 820us/step\n",
      "14\n",
      "3300/3300 [==============================] - 3s 821us/step\n",
      "15\n",
      "3300/3300 [==============================] - 3s 833us/step\n",
      "16\n",
      "3300/3300 [==============================] - 3s 831us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_train = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_training):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_train = data_train[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_train[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    \n",
    "    segmentations_train = segmentations_train + [segmentation]\n",
    "    \n",
    "segmentations_train = np.stack(segmentations_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB50gGBd8oorSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa86ee7a0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGDJJREFUeJzt3fFx27jWN2Dom23CV2VYZWhchlyGx2UoZWhdhl2GsmXo\n+yMvHRomKUqmRPDgeWYyd9dxsrw+AvjjIUisTqdTAgAA/vp/cx8AAACURkgGAICMkAwAABkhGQAA\nMkIyAABkhGQAAMgIyQAAkBGSAQAgIyQDAEDmn7kPIKWUVquVbf9mdDqdVlP9XWo5L7WMY6paquO8\njMk41DKOsbXUSQYAgIyQDAAAGSEZAAAyQjIAAGSEZAAAyAjJAACQKeIVcACXOh6P3762Xq9nOBLu\n4Xg8qu8CqBORCMlwY02Yc+K4va4TtJ8/3Ecz1lzAEoXlFnBj6/U6rdfrzhMH1xt70m3//JtfwH0Z\ndyzR6nSaf9OXUneeqeW2kV2E4lDL8UrvMNtxL4aaxuTpdEq/f//uHFOlj7cxaqpldGNrKSRj4Aei\nlpedjEs+cQvJMRiTcdRYy+12m97e3uY+jMkJyYxW48CPSi27g+/pdEqrVfePptSgLCTHYEzGoZZx\njK2lNclAOP/999/o7y0tHNOvhKYOUA8huWW73abD4TD3YQA/sF6v02az+fK1vi5y+89QvnN1BJhS\ntcsthm6/Dom4PsctpOs/D6VRyziWttzi4eHhog5+LYzJONQyDsstBmy326v/XLSAjFu4MAUBGYim\n2k7yXErsttR6ddx89iN0kBu11jKipXWS6WZMxqGWcXi7BaMZ+HGoZRxCcgzGZBxqGYflFsAiXbsc\nCgCm9M/cBwCQ0t9wbN0/ACWw3AK3kAJRyz/e398Hfz9/RVyJIi+3qOkhaGMyjpprud/v0263S79+\n/UqPj4+D3xtpfhWSqXrgR6OWf72/v6ePj4/FTuiRQ3JNjMk4aq7lfr//9rXn5+fBhkSpc2tKQvLN\nNR+MoZNwyR+QtpoHfjRLqeU93kudT+pDE3qJY1VIjmEpY5Lzaq9lV1BOKS0yAwnJd9L+0Cz1qqr2\ngR9JjbUcunV/yaRe2vgUkmOocUxGpZZ/9XWW29r5srRXrXq7xZ20PxT7/T59fHz0nmzPrZMELrff\n73vfiJFP2o2ucWp8lmu/3/de8PCdN8Rwa8/Pz73za0rfN+kqoSF7DZ3kEcZsANI1gS+hW5WSq+NI\nll7Lw+GQnp6eLvozx+Mxrdfrwe/pC1jtuz+ljU2d5BiWPib5Sy27NfNrE5r7cmVJ3WSd5Ik8PDxc\n/Wfzk25pJ2EozaUBOaV0NiCfs9lsjM0F0lmGMpzrKqdUVkC+hE7yxLoeFmrkP+tSPjSujuOotZZj\nO9BD47M0OsnD8u5VqWodkxGp5TilZp02neQzdrvdXf97JVyMMGy32939c8E0xnagx3Q8KEs+Jq1P\nhnItISBfotpO8uPjY/r4+LjLf6v09Tmujv9qTsi/fv2a+Uiuo5bj7Pf74sOyTnIMtY/JZgOKCGqv\nZSQ6yQVbrVbFBGT+aB6ybCZzHeXYSg/I/HFuIxiWwXzKUlXbSW5ekXOPrVFLfldgSq6OU/p7Mr7X\n3YVbUcs4dJLve8fvVqKPya73lLcvbpZev7YaaxnV2Fr+c+sDKdU9PwglBmOA0kUKWFC6WgLyJRbb\nSZ76imfMu5Cjin51XJMSa3mPLagj0kmOocQx2SffhERo+mpJtWSYbakZzcCPQy3jEJJjMCbjUMs4\nLLeAkdobxtR6N6E2Ly8vKaWUXl9fZz4ShtR8h2/JzKlEUfXbLe71xO3xePz8BYx3i3dXNwGZ8glY\ny6RuZdlut9+W0jCO5RZ3kIfjn26jOzW3kP5qTyRLXI+nlsPygFxyJ9lyiz+6xmS7jiXXMCVj8p5v\nkrq10mtZ2tspjsdjcXmn4T3JM3t5eentWOkoA1ym7+TvzkD5SgpukZXyc77VnfM5xrpO8sT6OlVd\nH5hSrrBKvzq+hyhPdUep5dQdiK7JtZYO5FLHZJ8l3Q1IKc6YRC3HeHl56VwiV0reaegkT+Dh4eHz\n1xhDVzmlfUDo9vb2ttiAHMmtx0sTrA6Hw03/O9xG6cEYavX6+hoq7+gknzF2J7a+gNy1rerT09PP\nD2xCro7jUMvvusZmPi5LG5Mp6STnlvpGEmMyDrXs1jU2S757npJO8mQ+Pj5CB2SIrOvW/BICMiyJ\nNyfUqz3HRnw+wHuSb6ArHAP3l4/F9vIK4Xg5ltpFroUlavUZCsSHwyF9fHykp6enz45ySV3kS1hu\n8QP5h2QoHJd8QnYLKY7Sa9meb+6xVXW+5rjkcZiz3OKrl5eXRYbk0sck46nluOVrbaXOuXbcu7Hm\nSulc13joA1LyOwThln7//n2XDkOpEzSX8YAlzKvWMaiT/ANL7lK1uTqOY0m1XPptuFvTSY5hSWOS\nYbXX8tKgXHImGltLIZnqB34kahmHkByDMRnHkmr5/v6eNpvNTf7uobBccjBuE5IZbUkDn2GRajlV\np/lwOCxm4m4rNSRH2mb4HiKNydqpZRxCMqMZ+OedTqe7PGj2U2oZR6khOaX7BeWljLshxmQcahmH\nkMxoBn4cajmNEsJZySGZ8YzJONQyDpuJAFyhhMYBAPMTkgEyc3eRAZif9yQDtAjIcLn21tQe6iQK\nneQLbLdbe9QDQEYwJiIP7o203W7T29tbyF3yPIwQh1rG4cG9GIzJONQyDg/u3Ui0gAwAkHPnXCeZ\n5Oo4ErWMQyc5BmMyDrWMQyf5zk6nk1dHAQAEISRPZLVaeSoeAAjl8fFx7kOYjeUWuIUUiFrGYblF\nDMZkHGoZh+UWAABwJSEZAAAyQjIAAGSEZAAAyAjJAACQEZIBACAjJAMAQEZIBgCATBGbiQAAQEl0\nkgEAICMkAwBARkgGAICMkAwAABkhGQAAMkIyAABkhGQAAMgIyQAAkBGSAQAgIyQDAEBGSAYAgIyQ\nDAAAGSEZAAAyQjIAAGSEZAAAyAjJAACQEZIBACAjJAMAQEZIBgCAjJAMAAAZIRkAADJCMgAAZIRk\nAADICMkAAJARkgEAICMkAwBARkgGAICMkAwAABkhGQAAMkIyAABkhGQAAMgIyQAAkBGSAQAgIyQD\nAEBGSAYAgIyQDAAAGSEZAAAyQjIAAGSEZAAAyAjJAACQEZIBACAjJAMAQEZIBgCAjJAMAACZf+Y+\ngJRSWq1Wp7mPoWan02k11d+llvNSyzimqqU6zsuYjEMt4xhbS51kAADICMkAAJARkgEAICMkAwBA\nRkgGAICMkAwAAJkiXgEHQD2Ox2Nar9ffvpbLvwfgnnSSAbirroDcFYi7gjPLczwe1ZJFWp1O87/P\n2ku15+UF6XGoZX/gWpqaNhM5nU5ptfr6f7cdqpZcT2NyHreYB9RyOnPP02NrKSRTxcBvTrh9g3Lu\nATuVGmpZi5pC8qXOjeeSGJNxqOXPdF0Mz8WOe/B/xt7mcztw2Q6HQyrhop/7MWZhOZqAfDqdPn+V\nTieZUFfH7Q7Tpd2mCN3kSLWsnU5yDMZkHGoZh07yDe12u7kPgR7r9foz6F4aeJcekCGqpXSdgFi8\nAu4Kv3//nvsQGEnwhWUSioG56SQDULxSHvgB6mFNMtZZBaKWcViTHIMxGYdaxmFNMgAAXElIBgCA\njJAMAAAZIRkAADJeAQdAkd7f3zu/vtls7nwkQI283WICfRN5SsuYzEt8Yrf5XP7777/p6elpir+y\nCiXWkuvU/HaLoTm1S8nzrDEZh1rGMbaWQvIE3t/f02azSfv9Pj0/P3dO8CbxyxwOB+H4CiXWkuvU\nHJJT+jOvfnx8fPv64+Nj758pcZ41JuOovZaR7uwIyXe03+87v76UwFzSwN9ut2m3250NyMfj0W56\nHUqqJT9z75C83W7T29vbFP/JSfXNryn1B+aS5lhjMo5otXx8fOy8EB3SjMfn5+eUUndwLmn89RGS\nb+Dh4SH9999/vb/fNZkvISiXMvBLPUkvSSm15OeW1En+ydjd7XYppZR+/frV+z1LDsrGZBy113Kp\nGaeLkDyTsR+ikj5AtQ/8SNQyjiWF5Hs4d8dus9l8/m9JjMk4aqjlbre7+IJ1iUHZjnsF2e/3Xz4s\nm80mlXBxAlCK7XY7+PvN7d1ce35t5tbmF3CZf//99/PuTpeucbjf7zuXbVz6AG6JhOSJ9U3kKf2Z\nwNsB2SQ+n6FJgPt6eHgY9X3b7fZskGI+Qw/UjTFmucbQ/CoYwzSGOskp9Y/DJuO0/33pLLe4kfyW\nRPOhav+8V6vJ7tz8SA23kNq222363//+9+Vr5yaFpYhcy751r+0Lnih1TMlyiyHt+bVrbk3J/Mr0\noteyaUKMfb6gb+nFEliTXIB8IjeJlydawKq1lmMe/loaIfkyJTYgUqp3TEYUvZaXhuSU+huCpROS\nC9X8vE3i82puDee3iJcesmqrZVO/S19jtARCcgy1jcnI1DIOD+4VarVaFRWQa9QOxksPxTVr1/Gn\n62G5Pc8B1G232/kMsDg6yVR5dRy1A1lbLa95Gf5SROskn3u1VFS1jcnIItay1v0JdJJhwMfHR9hw\nVaJmrdvUb6dQw+WoMSDjLg/LppNMyKvjIe1Xjg3toLhEpddyym5i5DqmNG8n+dzuooxX+phkPLWM\nw4N7jFbbwM/fyxspDNRUSyF5nNLrOKXj8ZhSSmm9Xs98JH/VNCajU8s4hOQCNRN4SibxOeXhqr0E\nYOlrs2qsZROQr3l9UcmE5PNeXl5SSim9vr5+mV9TKmeOrW1M5pr5NsKFbO21jGRsLf+59YHUrpnE\nc8fjsZhJPJpzP9s8VDWihKua5Osd1bAO+bz68vKS1uv1l6Bsji1HhIDMsJeXl/T6+vr576U2BS+l\nk3xD7Ym8+fCU2O2o7eq46+GxKOGqplpGugPQRSe5W1/jodQ5tqYxOSTCnR61/C4fj13jcO4x2MXb\nLWbW1elI6fuHJZ/Qub32JP329rboSbsWXe9XbWqnfvMamsNOp9O3nUZ/oi8gp5TS4XBIKZV5QoYl\n2e12o7LJ0Hhcr9efY3HJOUcnueV0Op3d6GPMOwXPdToapTxk4uo4DrWMY+md5Kl3Fx06IbeX3Tw9\nPaWUylluYUzGUUMtx743eSjnNBesKf0dj6Xx4N5M+j44Xe+KLOXDU8PAr4VaxrH0kDyVseE4Z35l\najXUcsyymCXmnJzlFjO45IPDV8fjMb2/v1/958de7LWvcIHlMq/CdYbOl+eWsNWWc3SSJ9L1wclv\nO7SVdHVV0tXx+/t72mw2Ux1OdUqqJT+jk3z9Ra35lVuovZYROsgNyy3uqJnIPz4+FnH7L1fawBeU\nr1daLbmekPzH2KBsfuXWaq/l0sdim5B8R+c+OKV/YGof+JGoZRxCcgzGZBy113Io65Sec3JCMqPV\nPvAjUcs4hOQYjMm/8g0nlkYt4xCSGc3Aj0Mt4xCSYzAm41DLOLzdgpCOx+OiX0wOACxDtZ3kMRuH\n1MLV8XilbFDQRy3j0EmOwZiMQy3j0Ek+Q0DmUjrYAFCPakMyULftdvu5uxQA5IRkGKnkZRZcZ2hn\nKe6nhGV/ADkhGS4gKJdnt9td/Ge2262AXJDVaiUoA8Wp9sG9nyj94a1LeRghDrWMo7YH96I+TG1M\nxqGWcXhw70Y8vAUAEJ9O8oUidjtcHcehlnHU1kmOypiMQy3j0Em+kWgBGQCA74RkAADICMkAAJAR\nkgEAICMkAwBARkgGAICMkAwAABkhGQAAMkIyAABkhGQAAMgIyQAAkBGSAQAgszqdTnMfAwAAFEUn\nGQAAMkIyAABkhGQAAMgIyQAAkBGSAQAgIyQDAEBGSAYAgIyQDAAAGSEZAAAyQjIAAGSEZAAAyAjJ\nAACQEZIBACAjJAMAQEZIBgCAjJAMAAAZIRkAADJCMgAAZIRkAADICMkAAJARkgEAICMkAwBARkgG\nAICMkAwAABkhGQAAMkIyAABkhGQAAMgIyQAAkBGSAQAgIyQDAEBGSAYAgIyQDAAAGSEZAAAyQjIA\nAGSEZAAAyAjJAACQEZIBACAjJAMAQEZIBgCAjJAMAAAZIRkAADJCMgAAZIRkAADICMkAAJD5Z+4D\nSCml1Wp1mvsYanY6nVZT/V1qOS+1jGPKWgJwOZ1kAADICMkAAJARkgEAICMkAwBARkgGAICMkAwA\nABkhuRDH4zEdj8e5DwNCMa4AuJaQXIj1ep3W6/XchxFWOyh1hSZhKja1BeBSq9Np/v0CSt20oDmx\nNuH1eDyGDLI1bUCR1zSammoZnc1EAOYlJA8Y6j61g3P+taWpLViNDcpLvCiqrZaRCckA86p6ucW5\nW7Dr9Tq9vr6e/Z723+e2/XJst9vB319aQAYAplN1SB4Tgn79+nXV3y0oAwAsl+UWI7V/TqvVqvf3\nfv/+/eX3ltCNdIs+DrW8nXuvZ7fcAmBeQvIP5T+/PEAvQc3Barvdpre3t7kPYzI11/Ie7hmUhWSA\neQnJV+r6uS0xIKckWEWilrclJAPUQ0hGsApELeMQkgHmVfWDezClc2/L4KvD4ZAOh8PchwEAnYRk\nmEiktc338vT0NPchAEAnyy1wiz4QtYzDcguAef0z9wEATOX9/f3znzebzYxHAsDShekkHw4Ht26v\nVGv3sR2oGksPVrXWMqXuevZZQp11kgHmFSYk31PfyXgJJ94utQarMaFqaTWttZaN/X6fUkrp+fn5\n82tLHa9CMsC8hOQrnAtXpZ98czUHq/f39896RahrzbVsNEG50QTmpYVlIRlgXkLylfITcUp/TsZL\nvIVfe7DqqmVKKT0+Pvb+mVJruqRaNhtzpHTd5hzH43Hwz40NyzXUEoDLVRuSf3qCTilOUF5SsLqV\nvqCcUndYLrWeS6llvh34LXay66tpe4yWWseUhGSAuXlP8sT2+336+PiY+zC4UHsNa64rSF3ykBjf\n5e+UXq/XnwG5fQH7E3013e/3abPZfKnr6XT6/AUAKVUckpsT8k86V2ODVcndqho8PDyM+r5zoaqR\nByymNWU3eWiMppQEYwB6VbvcYkpDt3VTSl9OwqtVeXdQl3KL/l7O1bNkatmta31y39xXyhi13AJg\nXtV2kqf0/PzcG6BKD8h8t4QwzGWGxigAdNFJnli7Y5V3q0oNybqP3fJaLoFajtc195U0RnWSAeYl\nJCNYDejanKJk0WqZvwVjaiVfxArJAPMSkgkXrGqmlnEIyQDzsiYZAAAyQjJFGfu6NgCAW7LcArfo\nA1HLOCy3AJjXP3MfAMAc8p39hjYxOR6Pk25yAkD5LLe4kZeXl5TSn5PrVNvs0m232819CCzMy8vL\ntzeWGKcAtFluMaEmGLe9vr5+nnxL7US5Rd8tr6daLl+7pnk9+2o7VxfZcguAeVluMZGugNxoTsBu\n2cahlsvSNz7bY7OPOgPUyXKLAdvtdtT39Z2AX19f0+FwSCn9OdE62c5n6CLmku9v19Dt+ds6nU6d\nu+JN4fX19fOfjUsAulhukf7uunXtjlt9gerx8fHzn5+enq76u+/BLfqvztXz6enpS0AuKWRFqeWU\nO+H1LYMqneUWAPOqPiT/5GQ8Jhw3hORlGHNXoFFiTdXyq6565uOzxDqmJCQDzM1yi//z025Voysg\nM78xdRlakpEHZMo3JiCnpLYAdKv+wb2pllj0hbBSu1TRnFsy8/HxkbbbbXp7e+v8/Us6yJRv7PgE\ngD7VL7e4xrnQtLRgXPst+msCVak1rqGWp9Op92JozAXNUO1KemuJ5RYA86q+k3yNp6enRaxPZZxL\nuozqvFxjaldKQAZgftV1kkvfDGIONXQf+4xdSrGUcFxzLaPRSQaYV3Uhme9qD1btoLyUMNynxlr+\n9BWOpRKSAeYVPiQPrV/kjxqDVVRLr+U1758WkgG4hdBrkku4AACuM3ZpVLRwDEAZwneSOW/p3cd7\na7Yr73ud3Jwi1NJzA3/oJAPMS0jukL8GqqTXQt1ChGDFH2oZh5AMMC877nXoC8Tt9ZIAAMQlJI+w\nXq8/A7KgHEOzZAIAoIvlFiPl4TjS8ouab9FHW/9acy2jsdwCYF5C8oD81VJRg7JgFYdaxiEkA8zL\ncosrRQnIAAB8p5Pco/1zif4eVt3HONQyDp1kgHnpJPdYrVbhwzEAAN2E5DMEZQCA+gjJAACQEZIB\nACAjJAMAQEZIBgCAjJAMAAAZIRkAADJCMgAAZIRkAADICMkAAJBZnU6nuY8BAACKopMMAAAZIRkA\nADJCMgAAZIRkAADICMkAAJARkgEAICMkAwBARkgGAICMkAwAABkhGQAAMkIyAABkhGQAAMgIyQAA\nkBGSAQAgIyQDAEBGSAYAgIyQDAAAGSEZAAAyQjIAAGSEZAAAyAjJAACQEZIBACAjJAMAQOb/AwfI\njgInpsNrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feae83fc2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Check false-positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_fpos = (label_train == 0) & (segmentations_train != 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_fpos = np.zeros(label_train.shape, dtype=precision_global)\n",
    "mask_fpos[idx_fpos == True] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSAYAgEJIBgCA4v/oFbEPjg429gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feae847edd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(200*(np.squeeze(mask_fpos[0:15,:,:,25])), rows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Rebuild training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((15864, 3, 27, 27, 21), (15864, 243, 11))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size, mask_fpos)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array('tmp/x_train.bc', x_train)\n",
    "save_array('tmp/y_train.bc', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_array('tmp/x_train.bc')\n",
    "y_train = load_array('tmp/y_train.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Regenerate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('2'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('2'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14277 samples, validate on 1587 samples\n",
      "Epoch 1/40\n",
      "14277/14277 [==============================] - 87s 6ms/step - loss: 0.0258 - categorical_accuracy: 0.9901 - val_loss: 0.1352 - val_categorical_accuracy: 0.9717\n",
      "Epoch 2/40\n",
      "14277/14277 [==============================] - 86s 6ms/step - loss: 0.0185 - categorical_accuracy: 0.9926 - val_loss: 0.1320 - val_categorical_accuracy: 0.9732\n",
      "Epoch 3/40\n",
      "14277/14277 [==============================] - 87s 6ms/step - loss: 0.0162 - categorical_accuracy: 0.9933 - val_loss: 0.1345 - val_categorical_accuracy: 0.9735\n",
      "Epoch 4/40\n",
      "14272/14277 [============================>.] - ETA: 0s - loss: 0.0145 - categorical_accuracy: 0.99400.0001 1e-05\n",
      "14277/14277 [==============================] - 87s 6ms/step - loss: 0.0145 - categorical_accuracy: 0.9940 - val_loss: 0.1706 - val_categorical_accuracy: 0.9721\n",
      "Epoch 5/40\n",
      "14272/14277 [============================>.] - ETA: 0s - loss: 0.0128 - categorical_accuracy: 0.99480.0001 1e-05\n",
      "14277/14277 [==============================] - 87s 6ms/step - loss: 0.0128 - categorical_accuracy: 0.9948 - val_loss: 0.1773 - val_categorical_accuracy: 0.9717\n",
      "Epoch 6/40\n",
      "14272/14277 [============================>.] - ETA: 0s - loss: 0.0114 - categorical_accuracy: 0.99530.0001 1e-05\n",
      "14277/14277 [==============================] - 88s 6ms/step - loss: 0.0114 - categorical_accuracy: 0.9953 - val_loss: 0.1640 - val_categorical_accuracy: 0.9741\n",
      "Epoch 7/40\n",
      "14272/14277 [============================>.] - ETA: 0s - loss: 0.0107 - categorical_accuracy: 0.99570.0001 1e-05\n",
      "14277/14277 [==============================] - 88s 6ms/step - loss: 0.0107 - categorical_accuracy: 0.9956 - val_loss: 0.1714 - val_categorical_accuracy: 0.9724\n",
      "Epoch 8/40\n",
      "14272/14277 [============================>.] - ETA: 0s - loss: 0.0093 - categorical_accuracy: 0.9962\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "14277/14277 [==============================] - 89s 6ms/step - loss: 0.0093 - categorical_accuracy: 0.9962 - val_loss: 0.1837 - val_categorical_accuracy: 0.9728\n",
      "Epoch 9/40\n",
      "14277/14277 [==============================] - 89s 6ms/step - loss: 0.0151 - categorical_accuracy: 0.9938 - val_loss: 0.1364 - val_categorical_accuracy: 0.9731\n",
      "Epoch 10/40\n",
      "14277/14277 [==============================] - 89s 6ms/step - loss: 0.0145 - categorical_accuracy: 0.9940 - val_loss: 0.1349 - val_categorical_accuracy: 0.9737\n",
      "Epoch 11/40\n",
      "14272/14277 [============================>.] - ETA: 0s - loss: 0.0142 - categorical_accuracy: 0.99421.001e-05 1e-05\n",
      "14277/14277 [==============================] - 89s 6ms/step - loss: 0.0142 - categorical_accuracy: 0.9942 - val_loss: 0.1459 - val_categorical_accuracy: 0.9726\n",
      "Epoch 12/40\n",
      "14272/14277 [============================>.] - ETA: 0s - loss: 0.0138 - categorical_accuracy: 0.99431.001e-05 1e-05\n",
      "14277/14277 [==============================] - 89s 6ms/step - loss: 0.0138 - categorical_accuracy: 0.9943 - val_loss: 0.1524 - val_categorical_accuracy: 0.9726\n",
      "Epoch 13/40\n",
      "14272/14277 [============================>.] - ETA: 0s - loss: 0.0135 - categorical_accuracy: 0.99441.001e-05 1e-05\n",
      "14277/14277 [==============================] - 89s 6ms/step - loss: 0.0135 - categorical_accuracy: 0.9944 - val_loss: 0.1569 - val_categorical_accuracy: 0.9725\n",
      "Epoch 14/40\n",
      "14272/14277 [============================>.] - ETA: 0s - loss: 0.0132 - categorical_accuracy: 0.99451.001e-05 1e-05\n",
      "14277/14277 [==============================] - 89s 6ms/step - loss: 0.0132 - categorical_accuracy: 0.9945 - val_loss: 0.1629 - val_categorical_accuracy: 0.9718\n",
      "Epoch 15/40\n",
      "14272/14277 [============================>.] - ETA: 0s - loss: 0.0129 - categorical_accuracy: 0.99471.001e-05 1e-05\n",
      "14277/14277 [==============================] - 89s 6ms/step - loss: 0.0129 - categorical_accuracy: 0.9947 - val_loss: 0.1675 - val_categorical_accuracy: 0.9719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feac41dd860>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "# Load optimized weights\n",
    "model.load_weights(model_filename.format('1'))\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-4)\n",
    "\n",
    "# Start fine-tuning\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1586/1586 [==============================] - 2s 976us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.132123952630472, 0.97314185527955444]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "3300/3300 [==============================] - 3s 835us/step\n",
      "18\n",
      "3300/3300 [==============================] - 3s 829us/step\n",
      "19\n",
      "3300/3300 [==============================] - 3s 829us/step\n",
      "20\n",
      "3300/3300 [==============================] - 3s 840us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_test = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_test = data_test[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_test[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    \n",
    "    segmentations_test = segmentations_test + [segmentation]\n",
    "    \n",
    "segmentations_test = np.stack(segmentations_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABBEMgAABJEMAADhP3KgFw3Y0TWkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea16d06be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_test[:,:,:,22]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea4be0e588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_test[:,:,:,22]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pick the largest connected component for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    segmentation = np.squeeze(segmentations_test[i_case,:,:,:]);\n",
    "    tmp = np.zeros(segmentation.shape, dtype=segmentation.dtype)\n",
    "    \n",
    "    for class_idx in class_mapper_inv :\n",
    "        mask = (segmentation == class_idx)\n",
    "        \n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            labeled_mask, num_cc = ndimage.label(mask)\n",
    "            largest_cc_mask = (labeled_mask == (np.bincount(labeled_mask.flat)[1:].argmax() + 1))\n",
    "            \n",
    "            tmp[largest_cc_mask == 1] = class_idx\n",
    "        \n",
    "    segmentations_test[i_case,:,:,:] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Done with Step 3\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx)\n",
    "    \n",
    "    segmentation = np.copy(np.squeeze(segmentations_test[i_case,:,:,:]))\n",
    "    \n",
    "    tmp = np.copy(segmentation)\n",
    "    for class_idx in class_mapper_inv:\n",
    "        segmentation[tmp == class_idx] = class_mapper_inv[class_idx]\n",
    "    del tmp\n",
    "\n",
    "    save_data(segmentation, case_idx, 'label')    \n",
    "\n",
    "print(\"Done with Step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Calculate metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(m1, m2):\n",
    "    return 2*((m1==1) & (m2==1)).sum()/((m1==1).sum() + (m2==1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\t0.9989\tN/A\t1.0000\t1.0000\t1.0000\t0.8598\t0.7097\t0.9585\t0.9007\t0.9050\t0.9299\t0.7322\t\n",
      "18\t0.9990\tN/A\t0.9348\t0.9459\t0.8130\t0.8571\t0.6865\t0.7677\t0.7677\t0.7633\t0.8109\t0.6846\t\n",
      "19\t0.9980\tN/A\tN/A\tN/A\tN/A\tN/A\t1.0000\t0.9819\t0.9167\t1.0000\t0.7113\t1.0000\t\n",
      "20\t0.9988\tN/A\t0.8108\t0.7901\t0.8756\t0.9173\t0.9543\t0.9079\t0.6240\t0.6546\t0.7175\t0.6903\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    print('{:.4f}'.format(accuracy_score(label_test[i_case,:,:,:].flat, segmentations_test[i_case,:,:,:].flat)), end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(precision_score(label_test[i_case,:,:,:][mask], segmentations_test[i_case,:,:,:][mask], average='micro')), end='\\t')\n",
    "        else:\n",
    "            print('N/A', end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\t0\t0.1386\t0.2376\t0.0824\t0.7188\t0.7933\t0.8813\t0.8661\t0.8360\t0.8436\t0.6163\t\n",
      "18\t0\t0.8037\t0.7527\t0.8000\t0.7261\t0.7954\t0.8316\t0.7357\t0.4697\t0.8295\t0.7846\t\n",
      "19\t0\t0\t0\t0\t0\t0.2193\t0.6260\t0.1692\t0.0913\t0.4363\t0.1872\t\n",
      "20\t0\t0.8824\t0.8000\t0.7860\t0.9071\t0.7786\t0.7532\t0.6809\t0.7548\t0.7794\t0.7471\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(calc_dice((label_test[i_case,:,:,:]==class_idx).flat, (segmentations_test[i_case,:,:,:]==class_idx).flat)), end='\\t')\n",
    "        else:\n",
    "            print(0, end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
