{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "from utils import *\n",
    "from model_FCNN import generate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import keras\n",
    "reload(keras)\n",
    "from keras import backend as K\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "\n",
    "import model_FCNN\n",
    "reload(model_FCNN)\n",
    "from model_FCNN import generate_model\n",
    "\n",
    "import callback_custom\n",
    "reload(callback_custom);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11\n",
    "num_channel = 2\n",
    "\n",
    "# K-fold validation (K=5)\n",
    "n_training = 16\n",
    "n_test = 4\n",
    "\n",
    "idxs_training = list(range(1, 1+16))\n",
    "idxs_test = list(range(17, 17+4))\n",
    "\n",
    "patience = 5\n",
    "model_filename = 'models/outrun_step_{}.h5'\n",
    "csv_filename = 'log/outrun_step_{}.cvs'\n",
    "\n",
    "nb_epoch = 40\n",
    "validation_split = 0.10\n",
    "monitor = 'val_loss'#'val_categorical_accuracy'\n",
    "\n",
    "class_mapper = {0:0}\n",
    "class_mapper.update({ i+1:i for i in range(1, 1+10) })\n",
    "class_mapper_inv = {0:0}\n",
    "class_mapper_inv.update({ i:i+1 for i in range(1, 1+10) })\n",
    "\n",
    "matrix_size = (160, 220, 48)\n",
    "\n",
    "#extraction_step = (3, 3, 3)\n",
    "extraction_step = (5, 5, 3)\n",
    "\n",
    "segment_size = (27, 27, 21)\n",
    "core_size = (9, 9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "MAG_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "R2S_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "label_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_training):\n",
    "    QSM_train[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_train[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_train[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_train[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = np.stack((QSM_train, MAG_train, R2S_train), axis = 1)\n",
    "data_train = np.stack((QSM_train, R2S_train), axis = 1)\n",
    "#data_train = np.stack((QSM_train,), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "MAG_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "R2S_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "label_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_test):\n",
    "    QSM_test[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_test[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_test[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_test[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test = np.stack((QSM_test, MAG_test, R2S_test), axis = 1)\n",
    "data_test = np.stack((QSM_test, R2S_test), axis = 1)\n",
    "#data_test = np.stack((QSM_test,), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intensity normalisation (zero mean and unit variance)\n",
    "input_mean = 127.0\n",
    "input_std = 128.0\n",
    "data_train = (data_train - input_mean) / input_std\n",
    "data_test = (data_test - input_mean) / input_std\n",
    "\n",
    "# Map class label\n",
    "tmp = np.copy(label_train)\n",
    "for class_idx in class_mapper:\n",
    "    label_train[tmp == class_idx] = class_mapper[class_idx]\n",
    "tmp = np.copy(label_test)\n",
    "for class_idx in class_mapper:\n",
    "    label_test[tmp == class_idx] = class_mapper[class_idx]\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEACAYAAABBOusMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc6e1a33438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0,:,:,[29,25]]), scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3964, 2, 27, 27, 21), (3964, 243, 11))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Configure callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('1'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('1'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3567 samples, validate on 397 samples\n",
      "Epoch 1/40\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.8834 - categorical_accuracy: 0.7729 - val_loss: 0.7942 - val_categorical_accuracy: 0.7931\n",
      "Epoch 2/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.5836 - categorical_accuracy: 0.8190 - val_loss: 0.6544 - val_categorical_accuracy: 0.8049\n",
      "Epoch 3/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.4559 - categorical_accuracy: 0.8527 - val_loss: 0.4912 - val_categorical_accuracy: 0.8504\n",
      "Epoch 4/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.3269 - categorical_accuracy: 0.8873 - val_loss: 0.4090 - val_categorical_accuracy: 0.8744\n",
      "Epoch 5/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.2098 - categorical_accuracy: 0.9217 - val_loss: 0.2761 - val_categorical_accuracy: 0.9000\n",
      "Epoch 6/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1535 - categorical_accuracy: 0.9390 - val_loss: 0.3262 - val_categorical_accuracy: 0.8905\n",
      "Epoch 7/40\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1722 - categorical_accuracy: 0.9349 - val_loss: 0.2597 - val_categorical_accuracy: 0.9088\n",
      "Epoch 8/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1197 - categorical_accuracy: 0.9511 - ETA: 16s - loss: 0.1248 -  - ETA: 100.001 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1196 - categorical_accuracy: 0.9511 - val_loss: 0.2899 - val_categorical_accuracy: 0.9070\n",
      "Epoch 9/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1014 - categorical_accuracy: 0.9584 ETA: 2s - loss: 0.1010 - categori0.001 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1017 - categorical_accuracy: 0.9583 - val_loss: 0.3123 - val_categorical_accuracy: 0.8994\n",
      "Epoch 10/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0903 - categorical_accuracy: 0.96290.001 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.0902 - categorical_accuracy: 0.9629 - val_loss: 0.3118 - val_categorical_accuracy: 0.9137\n",
      "Epoch 11/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0800 - categorical_accuracy: 0.96710.001 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.0800 - categorical_accuracy: 0.9671 - val_loss: 0.2921 - val_categorical_accuracy: 0.9159\n",
      "Epoch 12/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0681 - categorical_accuracy: 0.97220.001 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.0680 - categorical_accuracy: 0.9722 - val_loss: 0.3707 - val_categorical_accuracy: 0.9101\n",
      "Epoch 13/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0533 - categorical_accuracy: 0.9783\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.0533 - categorical_accuracy: 0.9783 - val_loss: 0.4304 - val_categorical_accuracy: 0.9047\n",
      "Epoch 14/40\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1126 - categorical_accuracy: 0.9539 - val_loss: 0.2569 - val_categorical_accuracy: 0.9108\n",
      "Epoch 15/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1037 - categorical_accuracy: 0.95690.0001 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1037 - categorical_accuracy: 0.9569 - val_loss: 0.2712 - val_categorical_accuracy: 0.9106\n",
      "Epoch 16/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0984 - categorical_accuracy: 0.95910.0001 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.0983 - categorical_accuracy: 0.9592 - val_loss: 0.2717 - val_categorical_accuracy: 0.9132\n",
      "Epoch 17/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0936 - categorical_accuracy: 0.96110.0001 1e-05\n",
      "3567/3567 [==============================] - 23s 7ms/step - loss: 0.0934 - categorical_accuracy: 0.9612 - val_loss: 0.2791 - val_categorical_accuracy: 0.9113\n",
      "Epoch 18/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0887 - categorical_accuracy: 0.96320.0001 1e-05\n",
      "3567/3567 [==============================] - 23s 7ms/step - loss: 0.0889 - categorical_accuracy: 0.9631 - val_loss: 0.2881 - val_categorical_accuracy: 0.9105\n",
      "Epoch 19/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0844 - categorical_accuracy: 0.96500.0001 1e-05\n",
      "3567/3567 [==============================] - 23s 7ms/step - loss: 0.0845 - categorical_accuracy: 0.9649 - val_loss: 0.2976 - val_categorical_accuracy: 0.9102\n",
      "Epoch 20/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0800 - categorical_accuracy: 0.9669\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "3567/3567 [==============================] - 23s 7ms/step - loss: 0.0800 - categorical_accuracy: 0.9669 - val_loss: 0.3153 - val_categorical_accuracy: 0.9097\n",
      "Epoch 21/40\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1039 - categorical_accuracy: 0.9572 - val_loss: 0.2577 - val_categorical_accuracy: 0.9119\n",
      "Epoch 22/40\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1027 - categorical_accuracy: 0.9576 - val_loss: 0.2554 - val_categorical_accuracy: 0.9132\n",
      "Epoch 23/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1019 - categorical_accuracy: 0.95791.001e-05 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1019 - categorical_accuracy: 0.9578 - val_loss: 0.2597 - val_categorical_accuracy: 0.9121\n",
      "Epoch 24/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1011 - categorical_accuracy: 0.95821.001e-05 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1011 - categorical_accuracy: 0.9582 - val_loss: 0.2582 - val_categorical_accuracy: 0.9129\n",
      "Epoch 25/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1002 - categorical_accuracy: 0.95851.001e-05 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1003 - categorical_accuracy: 0.9584 - val_loss: 0.2600 - val_categorical_accuracy: 0.9123\n",
      "Epoch 26/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0994 - categorical_accuracy: 0.95891.001e-05 1e-05\n",
      "3567/3567 [==============================] - 23s 7ms/step - loss: 0.0996 - categorical_accuracy: 0.9588 - val_loss: 0.2605 - val_categorical_accuracy: 0.9123\n",
      "Epoch 27/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0987 - categorical_accuracy: 0.95911.001e-05 1e-05\n",
      "3567/3567 [==============================] - 23s 7ms/step - loss: 0.0987 - categorical_accuracy: 0.9591 - val_loss: 0.2653 - val_categorical_accuracy: 0.9119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0135a16e48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 47\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396/396 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25584094756931969, 0.91306046404019747]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_patch = extract_patches(read_data(1, 'QSM'), patch_shape=segment_size, extraction_step=(9, 9, 3)).shape[0]\n",
    "len_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3300/3300 [==============================] - 3s 814us/step\n",
      "2\n",
      "3300/3300 [==============================] - 3s 763us/step\n",
      "3\n",
      "3300/3300 [==============================] - 3s 769us/step\n",
      "4\n",
      "3300/3300 [==============================] - 3s 776us/step\n",
      "5\n",
      "3300/3300 [==============================] - 3s 770us/step\n",
      "6\n",
      "3300/3300 [==============================] - 3s 774us/step\n",
      "7\n",
      "3300/3300 [==============================] - 3s 775us/step\n",
      "8\n",
      "3300/3300 [==============================] - 3s 783us/step\n",
      "9\n",
      "3300/3300 [==============================] - 3s 780us/step\n",
      "10\n",
      "3300/3300 [==============================] - 3s 781us/step\n",
      "11\n",
      "3300/3300 [==============================] - 3s 782us/step\n",
      "12\n",
      "3300/3300 [==============================] - 3s 782us/step\n",
      "13\n",
      "3300/3300 [==============================] - 3s 781us/step\n",
      "14\n",
      "3300/3300 [==============================] - 3s 781us/step\n",
      "15\n",
      "3300/3300 [==============================] - 3s 784us/step\n",
      "16\n",
      "3300/3300 [==============================] - 3s 781us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_train = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_training):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_train = data_train[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_train[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    \n",
    "    segmentations_train = segmentations_train + [segmentation]\n",
    "    \n",
    "segmentations_train = np.stack(segmentations_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB50gGBd8oorSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0135a54cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f00e80b76d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Check false-positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_fpos = (label_train == 0) & (segmentations_train != 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_fpos = np.zeros(label_train.shape, dtype=precision_global)\n",
    "mask_fpos[idx_fpos == True] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f00de124828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(200*(np.squeeze(mask_fpos[0:15,:,:,25])), rows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Rebuild training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((12135, 2, 27, 27, 21), (12135, 243, 11))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size, mask_fpos)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array('tmp/x_train.bc', x_train)\n",
    "save_array('tmp/y_train.bc', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_array('tmp/x_train.bc')\n",
    "y_train = load_array('tmp/y_train.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Regenerate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('2'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('2'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10921 samples, validate on 1214 samples\n",
      "Epoch 1/40\n",
      "10921/10921 [==============================] - 65s 6ms/step - loss: 0.0585 - categorical_accuracy: 0.9775 - val_loss: 0.0076 - val_categorical_accuracy: 0.9978\n",
      "Epoch 2/40\n",
      "10921/10921 [==============================] - 65s 6ms/step - loss: 0.0442 - categorical_accuracy: 0.9822 - val_loss: 0.0048 - val_categorical_accuracy: 0.9987\n",
      "Epoch 3/40\n",
      "10921/10921 [==============================] - 66s 6ms/step - loss: 0.0372 - categorical_accuracy: 0.9848 - val_loss: 0.0047 - val_categorical_accuracy: 0.9984\n",
      "Epoch 4/40\n",
      "10921/10921 [==============================] - 66s 6ms/step - loss: 0.0320 - categorical_accuracy: 0.9868 - val_loss: 0.0054 - val_categorical_accuracy: 0.9981\n",
      "Epoch 5/40\n",
      "10921/10921 [==============================] - 67s 6ms/step - loss: 0.0287 - categorical_accuracy: 0.9882 - val_loss: 0.0040 - val_categorical_accuracy: 0.9986\n",
      "Epoch 6/40\n",
      "10912/10921 [============================>.] - ETA: 0s - loss: 0.0253 - categorical_accuracy: 0.98960.0001 1e-05\n",
      "10921/10921 [==============================] - 67s 6ms/step - loss: 0.0253 - categorical_accuracy: 0.9896 - val_loss: 0.0048 - val_categorical_accuracy: 0.9983\n",
      "Epoch 7/40\n",
      "10921/10921 [==============================] - 68s 6ms/step - loss: 0.0229 - categorical_accuracy: 0.9905 - val_loss: 0.0035 - val_categorical_accuracy: 0.9988\n",
      "Epoch 8/40\n",
      "10912/10921 [============================>.] - ETA: 0s - loss: 0.0204 - categorical_accuracy: 0.99170.0001 1e-05\n",
      "10921/10921 [==============================] - 69s 6ms/step - loss: 0.0204 - categorical_accuracy: 0.9917 - val_loss: 0.0074 - val_categorical_accuracy: 0.9977\n",
      "Epoch 9/40\n",
      "10912/10921 [============================>.] - ETA: 0s - loss: 0.0182 - categorical_accuracy: 0.99270.0001 1e-05\n",
      "10921/10921 [==============================] - 69s 6ms/step - loss: 0.0182 - categorical_accuracy: 0.9927 - val_loss: 0.0054 - val_categorical_accuracy: 0.9985\n",
      "Epoch 10/40\n",
      "10912/10921 [============================>.] - ETA: 0s - loss: 0.0152 - categorical_accuracy: 0.9939 E - ETA: 3s - loss: 0.0152 0.0001 1e-05\n",
      "10921/10921 [==============================] - 69s 6ms/step - loss: 0.0152 - categorical_accuracy: 0.9939 - val_loss: 0.0055 - val_categorical_accuracy: 0.9986\n",
      "Epoch 11/40\n",
      "10912/10921 [============================>.] - ETA: 0s - loss: 0.0138 - categorical_accuracy: 0.9945 - ETA: 52s - los - ETA: 44s0.0001 1e-05\n",
      "10921/10921 [==============================] - 69s 6ms/step - loss: 0.0138 - categorical_accuracy: 0.9945 - val_loss: 0.0084 - val_categorical_accuracy: 0.9981\n",
      "Epoch 12/40\n",
      "10912/10921 [============================>.] - ETA: 0s - loss: 0.0131 - categorical_accuracy: 0.99480.0001 1e-05\n",
      "10921/10921 [==============================] - 69s 6ms/step - loss: 0.0131 - categorical_accuracy: 0.9948 - val_loss: 0.0099 - val_categorical_accuracy: 0.9976\n",
      "Epoch 13/40\n",
      "10912/10921 [============================>.] - ETA: 0s - loss: 0.0108 - categorical_accuracy: 0.9958\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "10921/10921 [==============================] - 69s 6ms/step - loss: 0.0108 - categorical_accuracy: 0.9958 - val_loss: 0.0089 - val_categorical_accuracy: 0.9980\n",
      "Epoch 14/40\n",
      "10921/10921 [==============================] - 69s 6ms/step - loss: 0.0181 - categorical_accuracy: 0.9928 - val_loss: 0.0052 - val_categorical_accuracy: 0.9984\n",
      "Epoch 15/40\n",
      "10912/10921 [============================>.] - ETA: 0s - loss: 0.0173 - categorical_accuracy: 0.99311.001e-05 1e-05\n",
      "10921/10921 [==============================] - 70s 6ms/step - loss: 0.0173 - categorical_accuracy: 0.9931 - val_loss: 0.0055 - val_categorical_accuracy: 0.9984\n",
      "Epoch 16/40\n",
      "10912/10921 [============================>.] - ETA: 0s - loss: 0.0168 - categorical_accuracy: 0.99331.001e-05 1e-05\n",
      "10921/10921 [==============================] - 70s 6ms/step - loss: 0.0168 - categorical_accuracy: 0.9933 - val_loss: 0.0054 - val_categorical_accuracy: 0.9984\n",
      "Epoch 17/40\n",
      "10912/10921 [============================>.] - ETA: 0s - loss: 0.0164 - categorical_accuracy: 0.99351.001e-05 1e-05\n",
      "10921/10921 [==============================] - 70s 6ms/step - loss: 0.0164 - categorical_accuracy: 0.9935 - val_loss: 0.0057 - val_categorical_accuracy: 0.9984\n",
      "Epoch 18/40\n",
      "10912/10921 [============================>.] - ETA: 0s - loss: 0.0160 - categorical_accuracy: 0.99371.001e-05 1e-05\n",
      "10921/10921 [==============================] - 69s 6ms/step - loss: 0.0160 - categorical_accuracy: 0.9937 - val_loss: 0.0062 - val_categorical_accuracy: 0.9984\n",
      "Epoch 19/40\n",
      "10912/10921 [============================>.] - ETA: 0s - loss: 0.0155 - categorical_accuracy: 0.99391.001e-05 1e-05\n",
      "10921/10921 [==============================] - 69s 6ms/step - loss: 0.0156 - categorical_accuracy: 0.9939 - val_loss: 0.0061 - val_categorical_accuracy: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f00de286e80>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "# Load optimized weights\n",
    "model.load_weights(model_filename.format('1'))\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-4)\n",
    "\n",
    "# Start fine-tuning\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1213/1213 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0034708751899920412, 0.99879543287932926]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "3300/3300 [==============================] - 3s 815us/step\n",
      "18\n",
      "3300/3300 [==============================] - 3s 766us/step\n",
      "19\n",
      "3300/3300 [==============================] - 3s 767us/step\n",
      "20\n",
      "3300/3300 [==============================] - 3s 775us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_test = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_test = data_test[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_test[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    #segmentation = reconstruct_volume_majority(pred_classes, matrix_size, extraction_step=(3, 3, 3))\n",
    "    \n",
    "    segmentations_test = segmentations_test + [segmentation]\n",
    "    \n",
    "segmentations_test = np.stack(segmentations_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f01c85b5b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAgiGQAAwr9/p9GEJVyDOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f00a41ec2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pick the largest connected component for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    segmentation = np.squeeze(segmentations_test[i_case,:,:,:]);\n",
    "    tmp = np.zeros(segmentation.shape, dtype=segmentation.dtype)\n",
    "    \n",
    "    for class_idx in class_mapper_inv :\n",
    "        mask = (segmentation == class_idx)\n",
    "        \n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            labeled_mask, num_cc = ndimage.label(mask)\n",
    "            largest_cc_mask = (labeled_mask == (np.bincount(labeled_mask.flat)[1:].argmax() + 1))\n",
    "            \n",
    "            tmp[largest_cc_mask == 1] = class_idx\n",
    "        \n",
    "    segmentations_test[i_case,:,:,:] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Done with Step 3\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx)\n",
    "    \n",
    "    segmentation = np.copy(np.squeeze(segmentations_test[i_case,:,:,:]))\n",
    "    \n",
    "    tmp = np.copy(segmentation)\n",
    "    for class_idx in class_mapper_inv:\n",
    "        segmentation[tmp == class_idx] = class_mapper_inv[class_idx]\n",
    "    del tmp\n",
    "\n",
    "    save_data(segmentation, case_idx, 'label')    \n",
    "\n",
    "print(\"Done with Step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Calculate metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(m1, m2):\n",
    "    return 2*((m1==1) & (m2==1)).sum()/((m1==1).sum() + (m2==1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\t0.9992\tN/A\t0.9231\t0.8514\t0.7846\t0.6980\t0.7263\t0.9431\t0.8711\t0.8754\t0.9589\t0.7337\t\n",
      "18\t0.9989\tN/A\t0.0000\t0.8333\t0.8986\t0.8644\t0.7743\t0.7606\t0.8802\t0.7556\t0.8200\t0.8149\t\n",
      "19\t0.9991\tN/A\t0.9200\t0.9375\t0.9503\t0.8862\t0.9586\t0.9850\t0.8686\t0.8241\t0.6980\t0.7333\t\n",
      "20\t0.9988\tN/A\t0.8169\t0.8485\t0.7870\t0.9156\t0.9389\t0.9510\t0.6667\t0.6760\t0.7367\t0.7293\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    print('{:.4f}'.format(accuracy_score(label_test[i_case,:,:,:].flat, segmentations_test[i_case,:,:,:].flat)), end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(precision_score(label_test[i_case,:,:,:][mask], segmentations_test[i_case,:,:,:][mask], average='micro')), end='\\t')\n",
    "        else:\n",
    "            print('N/A', end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\t0\t0.9081\t0.7730\t0.8547\t0.8034\t0.8218\t0.9031\t0.8789\t0.8897\t0.8544\t0.8026\t\n",
      "18\t0\t0.0000\t0.1613\t0.6327\t0.8547\t0.8344\t0.8155\t0.7132\t0.6012\t0.3388\t0.7884\t\n",
      "19\t0\t0.6053\t0.6316\t0.8384\t0.7475\t0.8774\t0.8698\t0.8330\t0.8349\t0.6721\t0.1719\t\n",
      "20\t0\t0.8722\t0.7724\t0.7752\t0.8527\t0.7696\t0.7791\t0.6337\t0.6725\t0.6824\t0.7413\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(calc_dice((label_test[i_case,:,:,:]==class_idx).flat, (segmentations_test[i_case,:,:,:]==class_idx).flat)), end='\\t')\n",
    "        else:\n",
    "            print(0, end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
