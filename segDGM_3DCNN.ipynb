{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "from utils import *\n",
    "from model_FCNN import generate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import keras\n",
    "reload(keras)\n",
    "from keras import backend as K\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "\n",
    "import model_FCNN\n",
    "reload(model_FCNN)\n",
    "from model_FCNN import generate_model\n",
    "\n",
    "import callback_custom\n",
    "reload(callback_custom);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11\n",
    "num_channel = 2\n",
    "\n",
    "# K-fold validation (K=5)\n",
    "n_training = 16\n",
    "n_test = 4\n",
    "\n",
    "idxs_training = list(range(1, 1+16))\n",
    "idxs_test = list(range(17, 17+4))\n",
    "\n",
    "patience = 5\n",
    "model_filename = 'models/outrun_step_{}.h5'\n",
    "csv_filename = 'log/outrun_step_{}.cvs'\n",
    "\n",
    "nb_epoch = 40\n",
    "validation_split = 0.10\n",
    "monitor = 'val_loss'#'val_categorical_accuracy'\n",
    "\n",
    "class_mapper = {0:0}\n",
    "class_mapper.update({ i+1:i for i in range(1, 1+10) })\n",
    "class_mapper_inv = {0:0}\n",
    "class_mapper_inv.update({ i:i+1 for i in range(1, 1+10) })\n",
    "\n",
    "matrix_size = (160, 220, 48)\n",
    "\n",
    "extraction_step = (3, 3, 1)\n",
    "#extraction_step = (5, 5, 3)\n",
    "\n",
    "segment_size = (27, 27, 21)\n",
    "core_size = (9, 9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "MAG_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "R2S_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "label_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_training):\n",
    "    QSM_train[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_train[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_train[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_train[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = np.stack((QSM_train, MAG_train, R2S_train), axis = 1)\n",
    "data_train = np.stack((QSM_train, R2S_train), axis = 1)\n",
    "#data_train = np.stack((QSM_train,), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "MAG_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "R2S_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "label_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_test):\n",
    "    QSM_test[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_test[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_test[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_test[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test = np.stack((QSM_test, MAG_test, R2S_test), axis = 1)\n",
    "data_test = np.stack((QSM_test, R2S_test), axis = 1)\n",
    "#data_test = np.stack((QSM_test,), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intensity normalisation (zero mean and unit variance)\n",
    "input_mean = 127.0\n",
    "input_std = 128.0\n",
    "data_train = (data_train - input_mean) / input_std\n",
    "data_test = (data_test - input_mean) / input_std\n",
    "\n",
    "# Map class label\n",
    "tmp = np.copy(label_train)\n",
    "for class_idx in class_mapper:\n",
    "    label_train[tmp == class_idx] = class_mapper[class_idx]\n",
    "tmp = np.copy(label_test)\n",
    "for class_idx in class_mapper:\n",
    "    label_test[tmp == class_idx] = class_mapper[class_idx]\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEACAYAAABBOusMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d272f5da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0,:,:,[29,25]]), scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((33015, 2, 27, 27, 21), (33015, 243, 11))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Configure callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('1'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('1'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29713 samples, validate on 3302 samples\n",
      "Epoch 1/40\n",
      "29713/29713 [==============================] - 187s 6ms/step - loss: 0.3351 - categorical_accuracy: 0.8946 - val_loss: 0.2441 - val_categorical_accuracy: 0.9162\n",
      "Epoch 2/40\n",
      "29713/29713 [==============================] - 183s 6ms/step - loss: 0.0824 - categorical_accuracy: 0.9658 - val_loss: 0.4243 - val_categorical_accuracy: 0.9086\n",
      "Epoch 3/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0387 - categorical_accuracy: 0.98440.001 1e-05\n",
      "29713/29713 [==============================] - 183s 6ms/step - loss: 0.0387 - categorical_accuracy: 0.9844 - val_loss: 0.6648 - val_categorical_accuracy: 0.9029\n",
      "Epoch 4/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0210 - categorical_accuracy: 0.99210.001 1e-05\n",
      "29713/29713 [==============================] - 184s 6ms/step - loss: 0.0210 - categorical_accuracy: 0.9921 - val_loss: 0.5353 - val_categorical_accuracy: 0.9132\n",
      "Epoch 5/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0222 - categorical_accuracy: 0.99210.001 1e-05\n",
      "29713/29713 [==============================] - 185s 6ms/step - loss: 0.0222 - categorical_accuracy: 0.9921 - val_loss: 0.4863 - val_categorical_accuracy: 0.9138\n",
      "Epoch 6/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0074 - categorical_accuracy: 0.9974 - ETA: 31s - loss: - ETA: 23s - loss: 0.0077 - categorical_accura - ETA: 21s - 0.001 1e-05\n",
      "29713/29713 [==============================] - 188s 6ms/step - loss: 0.0074 - categorical_accuracy: 0.9974 - val_loss: 0.7299 - val_categorical_accuracy: 0.9132\n",
      "Epoch 7/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0071 - categorical_accuracy: 0.9976 - ETA: 57s - loss: 0.0070 - categorica - ETA: 5 - ETA: 10s - \n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "29713/29713 [==============================] - 188s 6ms/step - loss: 0.0071 - categorical_accuracy: 0.9976 - val_loss: 0.7247 - val_categorical_accuracy: 0.9124\n",
      "Epoch 8/40\n",
      "29713/29713 [==============================] - 188s 6ms/step - loss: 0.0764 - categorical_accuracy: 0.9679 - val_loss: 0.4582 - val_categorical_accuracy: 0.9107\n",
      "Epoch 9/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0462 - categorical_accuracy: 0.9810 - ETA: 4s - los0.0001 1e-05\n",
      "29713/29713 [==============================] - 189s 6ms/step - loss: 0.0461 - categorical_accuracy: 0.9811 - val_loss: 0.6806 - val_categorical_accuracy: 0.9050\n",
      "Epoch 10/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0260 - categorical_accuracy: 0.9898 ETA: 0s - loss: 0.0260 - categorical_accuracy: 0.0001 1e-05\n",
      "29713/29713 [==============================] - 189s 6ms/step - loss: 0.0260 - categorical_accuracy: 0.9898 - val_loss: 0.8177 - val_categorical_accuracy: 0.9057\n",
      "Epoch 11/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0148 - categorical_accuracy: 0.99460.0001 1e-05\n",
      "29713/29713 [==============================] - 190s 6ms/step - loss: 0.0148 - categorical_accuracy: 0.9946 - val_loss: 0.9357 - val_categorical_accuracy: 0.9044\n",
      "Epoch 12/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0083 - categorical_accuracy: 0.9971\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "29713/29713 [==============================] - 192s 6ms/step - loss: 0.0083 - categorical_accuracy: 0.9971 - val_loss: 1.0586 - val_categorical_accuracy: 0.9023\n",
      "Epoch 13/40\n",
      "29713/29713 [==============================] - 193s 6ms/step - loss: 0.0944 - categorical_accuracy: 0.9602 - val_loss: 0.3312 - val_categorical_accuracy: 0.9117\n",
      "Epoch 14/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0870 - categorical_accuracy: 0.96321.001e-05 1e-05\n",
      "29713/29713 [==============================] - 194s 7ms/step - loss: 0.0870 - categorical_accuracy: 0.9632 - val_loss: 0.3499 - val_categorical_accuracy: 0.9108\n",
      "Epoch 15/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0823 - categorical_accuracy: 0.96521.001e-05 1e-05\n",
      "29713/29713 [==============================] - 194s 7ms/step - loss: 0.0823 - categorical_accuracy: 0.9652 - val_loss: 0.3714 - val_categorical_accuracy: 0.9100\n",
      "Epoch 16/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0779 - categorical_accuracy: 0.9670 - ETA: 51s - loss: 0.0783 - categorical_ac1.001e-05 1e-05\n",
      "29713/29713 [==============================] - 192s 6ms/step - loss: 0.0779 - categorical_accuracy: 0.9670 - val_loss: 0.4037 - val_categorical_accuracy: 0.9078\n",
      "Epoch 17/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0736 - categorical_accuracy: 0.96891.001e-05 1e-05\n",
      "29713/29713 [==============================] - 188s 6ms/step - loss: 0.0736 - categorical_accuracy: 0.9689 - val_loss: 0.4202 - val_categorical_accuracy: 0.9085\n",
      "Epoch 18/40\n",
      "29696/29713 [============================>.] - ETA: 0s - loss: 0.0693 - categorical_accuracy: 0.9708 - ETA: 21s1.001e-05 1e-05\n",
      "29713/29713 [==============================] - 187s 6ms/step - loss: 0.0693 - categorical_accuracy: 0.9708 - val_loss: 0.4520 - val_categorical_accuracy: 0.9085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2d00863a58>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 47\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3301/3301 [==============================] - 3s 883us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24420018160421716, 0.91617561157672056]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_patch = extract_patches(read_data(1, 'QSM'), patch_shape=segment_size, extraction_step=(9, 9, 3)).shape[0]\n",
    "len_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3300/3300 [==============================] - 3s 858us/step\n",
      "2\n",
      "3300/3300 [==============================] - 3s 824us/step\n",
      "3\n",
      "3300/3300 [==============================] - 3s 824us/step\n",
      "4\n",
      "3300/3300 [==============================] - 3s 821us/step\n",
      "5\n",
      "3300/3300 [==============================] - 3s 836us/step\n",
      "6\n",
      "3300/3300 [==============================] - 3s 837us/step\n",
      "7\n",
      "3300/3300 [==============================] - 3s 836us/step\n",
      "8\n",
      "3300/3300 [==============================] - 3s 830us/step\n",
      "9\n",
      "3300/3300 [==============================] - 3s 840us/step\n",
      "10\n",
      "3300/3300 [==============================] - 3s 834us/step\n",
      "11\n",
      "3300/3300 [==============================] - 3s 834us/step\n",
      "12\n",
      "3300/3300 [==============================] - 3s 832us/step\n",
      "13\n",
      "3300/3300 [==============================] - 3s 822us/step\n",
      "14\n",
      "3300/3300 [==============================] - 3s 838us/step\n",
      "15\n",
      "3300/3300 [==============================] - 3s 832us/step\n",
      "16\n",
      "3300/3300 [==============================] - 3s 836us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_train = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_training):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_train = data_train[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_train[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    \n",
    "    segmentations_train = segmentations_train + [segmentation]\n",
    "    \n",
    "segmentations_train = np.stack(segmentations_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB50gGBd8oorSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ce8eeab70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ce8be9c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Check false-positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_fpos = (label_train == 0) & (segmentations_train != 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_fpos = np.zeros(label_train.shape, dtype=precision_global)\n",
    "mask_fpos[idx_fpos == True] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ce867c048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(200*(np.squeeze(mask_fpos[0:15,:,:,25])), rows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Rebuild training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((18426, 2, 27, 27, 21), (18426, 243, 11))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_step_ft = (6,6,3)\n",
    "x_train, y_train = build_set(data_train, label_train, extraction_step_ft, segment_size, core_size, mask_fpos)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array('tmp/x_train.bc', x_train)\n",
    "save_array('tmp/y_train.bc', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_array('tmp/x_train.bc')\n",
    "y_train = load_array('tmp/y_train.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Regenerate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('2'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('2'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16583 samples, validate on 1843 samples\n",
      "Epoch 1/40\n",
      "16583/16583 [==============================] - 100s 6ms/step - loss: 0.0253 - categorical_accuracy: 0.9903 - val_loss: 0.0023 - val_categorical_accuracy: 0.9994\n",
      "Epoch 2/40\n",
      "16583/16583 [==============================] - 100s 6ms/step - loss: 0.0176 - categorical_accuracy: 0.9927 - val_loss: 5.3485e-04 - val_categorical_accuracy: 0.9999\n",
      "Epoch 3/40\n",
      "16583/16583 [==============================] - 101s 6ms/step - loss: 0.0151 - categorical_accuracy: 0.9937 - val_loss: 8.0246e-04 - val_categorical_accuracy: 0.9998\n",
      "Epoch 4/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0137 - categorical_accuracy: 0.99430.0001 1e-05\n",
      "16583/16583 [==============================] - 101s 6ms/step - loss: 0.0137 - categorical_accuracy: 0.9943 - val_loss: 8.4026e-04 - val_categorical_accuracy: 0.9997\n",
      "Epoch 5/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0127 - categorical_accuracy: 0.99470.0001 1e-05\n",
      "16583/16583 [==============================] - 101s 6ms/step - loss: 0.0127 - categorical_accuracy: 0.9947 - val_loss: 8.1469e-04 - val_categorical_accuracy: 0.9997\n",
      "Epoch 6/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0110 - categorical_accuracy: 0.99540.0001 1e-05\n",
      "16583/16583 [==============================] - 102s 6ms/step - loss: 0.0110 - categorical_accuracy: 0.9954 - val_loss: 0.0013 - val_categorical_accuracy: 0.9995\n",
      "Epoch 7/40\n",
      "16583/16583 [==============================] - 103s 6ms/step - loss: 0.0105 - categorical_accuracy: 0.9957 - val_loss: 7.3571e-04 - val_categorical_accuracy: 0.9997\n",
      "Epoch 8/40\n",
      "16583/16583 [==============================] - 102s 6ms/step - loss: 0.0095 - categorical_accuracy: 0.9961 - val_loss: 3.3057e-04 - val_categorical_accuracy: 0.9999\n",
      "Epoch 9/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0082 - categorical_accuracy: 0.9967 - ETA: 15s - loss: 0.0083 - categoric - ETA: 11s - los - ETA: 6s - loss: 0.0083 - categorical_ac0.0001 1e-05\n",
      "16583/16583 [==============================] - 104s 6ms/step - loss: 0.0082 - categorical_accuracy: 0.9967 - val_loss: 5.1147e-04 - val_categorical_accuracy: 0.9998\n",
      "Epoch 10/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0081 - categorical_accuracy: 0.99670.0001 1e-05\n",
      "16583/16583 [==============================] - 105s 6ms/step - loss: 0.0081 - categorical_accuracy: 0.9967 - val_loss: 0.0012 - val_categorical_accuracy: 0.9996\n",
      "Epoch 11/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0070 - categorical_accuracy: 0.9972   ETA: 1: - ETA: 1:10 - loss: 0.0068 - categorical_accuracy - ETA: 1:09 - loss: 0.0068 - categorical_accuracy:  - ET - ETA: 32s - l - ETA: 23s - loss: 0.0069 - categorical_accuracy: 0 - ETA:0.0001 1e-05\n",
      "16583/16583 [==============================] - 105s 6ms/step - loss: 0.0070 - categorical_accuracy: 0.9972 - val_loss: 6.6947e-04 - val_categorical_accuracy: 0.9997\n",
      "Epoch 12/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0062 - categorical_accuracy: 0.99760.0001 1e-05\n",
      "16583/16583 [==============================] - 105s 6ms/step - loss: 0.0062 - categorical_accuracy: 0.9976 - val_loss: 4.8501e-04 - val_categorical_accuracy: 0.9999\n",
      "Epoch 13/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0058 - categorical_accuracy: 0.9978   ETA: 1: - ETA: 27s - loss: 0.0058 - categorical_a - ETA: 13 - ETA: 6s - loss: 0.0058 - categorical_accu0.0001 1e-05\n",
      "16583/16583 [==============================] - 105s 6ms/step - loss: 0.0058 - categorical_accuracy: 0.9978 - val_loss: 0.0022 - val_categorical_accuracy: 0.9994\n",
      "Epoch 14/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0051 - categorical_accuracy: 0.9980\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "16583/16583 [==============================] - 105s 6ms/step - loss: 0.0051 - categorical_accuracy: 0.9980 - val_loss: 9.0475e-04 - val_categorical_accuracy: 0.9997\n",
      "Epoch 15/40\n",
      "16583/16583 [==============================] - 106s 6ms/step - loss: 0.0071 - categorical_accuracy: 0.9972 - val_loss: 2.5705e-04 - val_categorical_accuracy: 0.9999\n",
      "Epoch 16/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0067 - categorical_accuracy: 0.99741.001e-05 1e-05\n",
      "16583/16583 [==============================] - 105s 6ms/step - loss: 0.0067 - categorical_accuracy: 0.9974 - val_loss: 2.5883e-04 - val_categorical_accuracy: 0.9999\n",
      "Epoch 17/40\n",
      "16583/16583 [==============================] - 105s 6ms/step - loss: 0.0064 - categorical_accuracy: 0.9975 - val_loss: 2.3480e-04 - val_categorical_accuracy: 0.9999orical_accuracy: 0 - ETA: 46s - loss: 0.0065 - categorical_accuracy: 0. - ETA: 46s - loss: 0.0065 - cate - ETA: 41s - loss: 0.0066 - categorical_accuracy: 0.99 - ETA: - ETA: 31s - loss: 0.0066 - ETA: 24s - loss: 0.0066 - categorical_ac - ETA: 22s - loss: 0.0065 - categorical_acc - ETA: 19s - loss: 0.0065 - categorical_accuracy: 0 - ETA: 18s - loss: 0.0065 - categorical - ETA: 15s - loss: 0.0064 - categorical_a - ETA: - ETA: 6s - loss: 0.0064 - ca - ETA: 3s - loss: 0\n",
      "Epoch 18/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0062 - categorical_accuracy: 0.9976 - ETA: 19s - l - ETA: 1 - ETA: 6s - loss: 0.0062 - cate - ETA: 3s - loss: 01.001e-05 1e-05\n",
      "16583/16583 [==============================] - 104s 6ms/step - loss: 0.0062 - categorical_accuracy: 0.9976 - val_loss: 3.2493e-04 - val_categorical_accuracy: 0.9999\n",
      "Epoch 19/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0060 - categorical_accuracy: 0.99771.001e-05 1e-05\n",
      "16583/16583 [==============================] - 105s 6ms/step - loss: 0.0060 - categorical_accuracy: 0.9977 - val_loss: 2.5234e-04 - val_categorical_accuracy: 0.9999\n",
      "Epoch 20/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0058 - categorical_accuracy: 0.9978 - ETA: 42s - - ETA: 33s - ETA: 24s - loss: 0.0058 - categorical_accuracy: 0. - ETA: 23s - loss: 0.0058 - categorical_accurac - ETA: 10s - 1.001e-05 1e-05\n",
      "16583/16583 [==============================] - 105s 6ms/step - loss: 0.0058 - categorical_accuracy: 0.9978 - val_loss: 3.3035e-04 - val_categorical_accuracy: 0.9999\n",
      "Epoch 21/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0056 - categorical_accuracy: 0.9979 ETA: 2s - loss: 0.0056 - catego1.001e-05 1e-05\n",
      "16583/16583 [==============================] - 106s 6ms/step - loss: 0.0056 - categorical_accuracy: 0.9979 - val_loss: 3.0872e-04 - val_categorical_accuracy: 0.9999\n",
      "Epoch 22/40\n",
      "16576/16583 [============================>.] - ETA: 0s - loss: 0.0054 - categorical_accuracy: 0.99791.001e-05 1e-05\n",
      "16583/16583 [==============================] - 105s 6ms/step - loss: 0.0054 - categorical_accuracy: 0.9979 - val_loss: 4.9716e-04 - val_categorical_accuracy: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2cf817b7b8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "# Load optimized weights\n",
    "model.load_weights(model_filename.format('1'))\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-4)\n",
    "\n",
    "# Start fine-tuning\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1842/1842 [==============================] - 2s 942us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00023492626337577228, 0.99990375331895232]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "3300/3300 [==============================] - 3s 810us/step\n",
      "18\n",
      "3300/3300 [==============================] - 3s 780us/step\n",
      "19\n",
      "3300/3300 [==============================] - 3s 785us/step\n",
      "20\n",
      "3300/3300 [==============================] - 3s 788us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_test = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_test = data_test[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_test[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    #segmentation = reconstruct_volume_majority(pred_classes, matrix_size, extraction_step=(3, 3, 3))\n",
    "    \n",
    "    segmentations_test = segmentations_test + [segmentation]\n",
    "    \n",
    "segmentations_test = np.stack(segmentations_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ce8d891d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2cd6c59710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pick the largest connected component for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    segmentation = np.squeeze(segmentations_test[i_case,:,:,:]);\n",
    "    tmp = np.zeros(segmentation.shape, dtype=segmentation.dtype)\n",
    "    \n",
    "    for class_idx in class_mapper_inv :\n",
    "        mask = (segmentation == class_idx)\n",
    "        \n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            labeled_mask, num_cc = ndimage.label(mask)\n",
    "            largest_cc_mask = (labeled_mask == (np.bincount(labeled_mask.flat)[1:].argmax() + 1))\n",
    "            \n",
    "            tmp[largest_cc_mask == 1] = class_idx\n",
    "        \n",
    "    segmentations_test[i_case,:,:,:] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Done with Step 3\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx)\n",
    "    \n",
    "    segmentation = np.copy(np.squeeze(segmentations_test[i_case,:,:,:]))\n",
    "    \n",
    "    tmp = np.copy(segmentation)\n",
    "    for class_idx in class_mapper_inv:\n",
    "        segmentation[tmp == class_idx] = class_mapper_inv[class_idx]\n",
    "    del tmp\n",
    "\n",
    "    save_data(segmentation, case_idx, 'label')    \n",
    "\n",
    "print(\"Done with Step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Calculate metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(m1, m2):\n",
    "    return 2*((m1==1) & (m2==1)).sum()/((m1==1).sum() + (m2==1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\t0.9993\tN/A\t0.8990\t0.9178\t0.7884\t0.7735\t0.7988\t0.9391\t0.8498\t0.8645\t0.9261\t0.8571\t\n",
      "18\t0.9990\tN/A\t0.8837\t0.9000\t0.9038\t0.7953\t0.7459\t0.7520\t0.7654\t0.6948\t0.7602\t0.7486\t\n",
      "19\t0.9988\tN/A\t1.0000\t0.8810\t0.9659\t0.8690\t0.9568\t0.9933\t0.9091\t0.8655\t0.7576\t0.7425\t\n",
      "20\t0.9989\tN/A\t0.9811\t0.8000\t0.8465\t0.8750\t0.9488\t0.9208\t0.7157\t0.6382\t0.8054\t0.7485\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    print('{:.4f}'.format(accuracy_score(label_test[i_case,:,:,:].flat, segmentations_test[i_case,:,:,:].flat)), end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(precision_score(label_test[i_case,:,:,:][mask], segmentations_test[i_case,:,:,:][mask], average='micro')), end='\\t')\n",
    "        else:\n",
    "            print('N/A', end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\t0\t0.9223\t0.8272\t0.8466\t0.8485\t0.8539\t0.8937\t0.8774\t0.8932\t0.8631\t0.7619\t\n",
      "18\t0\t0.7308\t0.2727\t0.8139\t0.7727\t0.8240\t0.8145\t0.8042\t0.6137\t0.5937\t0.8140\t\n",
      "19\t0\t0.3810\t0.7048\t0.5822\t0.6738\t0.8304\t0.8558\t0.4120\t0.8143\t0.5144\t0.4901\t\n",
      "20\t0\t0.9043\t0.7517\t0.8053\t0.9000\t0.8128\t0.7825\t0.7502\t0.7507\t0.8285\t0.6193\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(calc_dice((label_test[i_case,:,:,:]==class_idx).flat, (segmentations_test[i_case,:,:,:]==class_idx).flat)), end='\\t')\n",
    "        else:\n",
    "            print(0, end='\\t')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
