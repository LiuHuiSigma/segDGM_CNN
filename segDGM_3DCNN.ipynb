{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "from utils import *\n",
    "from model_FCNN import generate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import keras\n",
    "reload(keras)\n",
    "from keras import backend as K\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "\n",
    "import model_FCNN\n",
    "reload(model_FCNN)\n",
    "from model_FCNN import generate_model\n",
    "\n",
    "import callback_custom\n",
    "reload(callback_custom);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11\n",
    "num_channel = 2\n",
    "\n",
    "# K-fold validation (K=5)\n",
    "n_training = 16\n",
    "n_test = 4\n",
    "\n",
    "#idxs_training = list(range(1, 1+16))\n",
    "#idxs_test = list(range(17, 17+4))\n",
    "idxs_training = list(range(1, 1+12)) + list(range(17, 17+4))\n",
    "idxs_test = list(range(13,13+4))\n",
    "\n",
    "patience = 5\n",
    "model_filename = 'models/outrun_step_{}.h5'\n",
    "csv_filename = 'log/outrun_step_{}.cvs'\n",
    "\n",
    "nb_epoch = 40\n",
    "validation_split = 0.10\n",
    "monitor = 'val_loss'#'val_categorical_accuracy'\n",
    "\n",
    "class_mapper = {0:0}\n",
    "class_mapper.update({ i+1:i for i in range(1, 1+10) })\n",
    "class_mapper_inv = {0:0}\n",
    "class_mapper_inv.update({ i:i+1 for i in range(1, 1+10) })\n",
    "\n",
    "matrix_size = (160, 220, 48)\n",
    "\n",
    "extraction_step = (3, 3, 1)\n",
    "#extraction_step = (5, 5, 3)\n",
    "\n",
    "segment_size = (27, 27, 21)\n",
    "core_size = (9, 9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "MAG_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "R2S_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "label_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_training):\n",
    "    QSM_train[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_train[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_train[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_train[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = np.stack((QSM_train, MAG_train, R2S_train), axis = 1)\n",
    "data_train = np.stack((QSM_train, R2S_train), axis = 1)\n",
    "#data_train = np.stack((QSM_train,), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "MAG_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "R2S_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "label_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_test):\n",
    "    QSM_test[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_test[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_test[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_test[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test = np.stack((QSM_test, MAG_test, R2S_test), axis = 1)\n",
    "data_test = np.stack((QSM_test, R2S_test), axis = 1)\n",
    "#data_test = np.stack((QSM_test,), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intensity normalisation (zero mean and unit variance)\n",
    "input_mean = 127.0\n",
    "input_std = 128.0\n",
    "data_train = (data_train - input_mean) / input_std\n",
    "data_test = (data_test - input_mean) / input_std\n",
    "\n",
    "# Map class label\n",
    "tmp = np.copy(label_train)\n",
    "for class_idx in class_mapper:\n",
    "    label_train[tmp == class_idx] = class_mapper[class_idx]\n",
    "tmp = np.copy(label_test)\n",
    "for class_idx in class_mapper:\n",
    "    label_test[tmp == class_idx] = class_mapper[class_idx]\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEACAYAAABBOusMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe8a76ebc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0,:,:,[29,25]]), scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((32629, 2, 27, 27, 21), (32629, 243, 11))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Configure callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('1'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('1'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29366 samples, validate on 3263 samples\n",
      "Epoch 1/40\n",
      "29366/29366 [==============================] - 182s 6ms/step - loss: 0.3901 - categorical_accuracy: 0.8737 - val_loss: 0.2947 - val_categorical_accuracy: 0.9054\n",
      "Epoch 2/40\n",
      "29366/29366 [==============================] - 180s 6ms/step - loss: 0.0921 - categorical_accuracy: 0.9624 - val_loss: 0.4249 - val_categorical_accuracy: 0.9055\n",
      "Epoch 3/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0459 - categorical_accuracy: 0.98140.001 1e-05\n",
      "29366/29366 [==============================] - 181s 6ms/step - loss: 0.0459 - categorical_accuracy: 0.9814 - val_loss: 0.4917 - val_categorical_accuracy: 0.9111\n",
      "Epoch 4/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0224 - categorical_accuracy: 0.99150.001 1e-05\n",
      "29366/29366 [==============================] - 181s 6ms/step - loss: 0.0224 - categorical_accuracy: 0.9915 - val_loss: 0.5812 - val_categorical_accuracy: 0.9204\n",
      "Epoch 5/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0151 - categorical_accuracy: 0.99460.001 1e-05\n",
      "29366/29366 [==============================] - 181s 6ms/step - loss: 0.0151 - categorical_accuracy: 0.9946 - val_loss: 0.6244 - val_categorical_accuracy: 0.9171\n",
      "Epoch 6/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0105 - categorical_accuracy: 0.99640.001 1e-05\n",
      "29366/29366 [==============================] - 181s 6ms/step - loss: 0.0105 - categorical_accuracy: 0.9964 - val_loss: 0.6295 - val_categorical_accuracy: 0.9099\n",
      "Epoch 7/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0075 - categorical_accuracy: 0.9974\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "29366/29366 [==============================] - 181s 6ms/step - loss: 0.0075 - categorical_accuracy: 0.9974 - val_loss: 0.7181 - val_categorical_accuracy: 0.9125\n",
      "Epoch 8/40\n",
      "29366/29366 [==============================] - 181s 6ms/step - loss: 0.0830 - categorical_accuracy: 0.9655 - val_loss: 0.3534 - val_categorical_accuracy: 0.9113\n",
      "Epoch 9/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0543 - categorical_accuracy: 0.97770.0001 1e-05\n",
      "29366/29366 [==============================] - 186s 6ms/step - loss: 0.0543 - categorical_accuracy: 0.9777 - val_loss: 0.4746 - val_categorical_accuracy: 0.9094\n",
      "Epoch 10/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0336 - categorical_accuracy: 0.9866 - ETA: 59s - loss: 0.03 - ETA: 52s - loss: 0.0358 - c0.0001 1e-05\n",
      "29366/29366 [==============================] - 187s 6ms/step - loss: 0.0336 - categorical_accuracy: 0.9866 - val_loss: 0.6115 - val_categorical_accuracy: 0.9083\n",
      "Epoch 11/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0199 - categorical_accuracy: 0.99240.0001 1e-05\n",
      "29366/29366 [==============================] - 189s 6ms/step - loss: 0.0199 - categorical_accuracy: 0.9924 - val_loss: 0.7244 - val_categorical_accuracy: 0.9081\n",
      "Epoch 12/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0115 - categorical_accuracy: 0.9959\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "29366/29366 [==============================] - 189s 6ms/step - loss: 0.0115 - categorical_accuracy: 0.9959 - val_loss: 0.9004 - val_categorical_accuracy: 0.9065\n",
      "Epoch 13/40\n",
      "29366/29366 [==============================] - 189s 6ms/step - loss: 0.0997 - categorical_accuracy: 0.9589 - val_loss: 0.3404 - val_categorical_accuracy: 0.9078\n",
      "Epoch 14/40\n",
      "29366/29366 [==============================] - 184s 6ms/step - loss: 0.0925 - categorical_accuracy: 0.9616 - val_loss: 0.3219 - val_categorical_accuracy: 0.9099\n",
      "Epoch 15/40\n",
      "29366/29366 [==============================] - 183s 6ms/step - loss: 0.0880 - categorical_accuracy: 0.9634 - val_loss: 0.3178 - val_categorical_accuracy: 0.9107\n",
      "Epoch 16/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0838 - categorical_accuracy: 0.9651 - ETA: 30s - loss: 0. - ETA:1.001e-05 1e-05\n",
      "29366/29366 [==============================] - 186s 6ms/step - loss: 0.0838 - categorical_accuracy: 0.9651 - val_loss: 0.3327 - val_categorical_accuracy: 0.9106\n",
      "Epoch 17/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0797 - categorical_accuracy: 0.9668 - ETA: 42s - loss: 0.0803 - categorical_accurac - ETA: 40s - loss:  - ETA: 33s - loss: 0.0801 - categoric - ETA: 29s - loss: 0.0801 - c1.001e-05 1e-05\n",
      "29366/29366 [==============================] - 186s 6ms/step - loss: 0.0797 - categorical_accuracy: 0.9668 - val_loss: 0.3526 - val_categorical_accuracy: 0.9104\n",
      "Epoch 18/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0755 - categorical_accuracy: 0.9686 ETA: 3s - loss: 0.0755 - categorical_ac - ETA: 2s - loss: 0.0755 - cate1.001e-05 1e-05\n",
      "29366/29366 [==============================] - 186s 6ms/step - loss: 0.0756 - categorical_accuracy: 0.9686 - val_loss: 0.3555 - val_categorical_accuracy: 0.9107\n",
      "Epoch 19/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0714 - categorical_accuracy: 0.97041.001e-05 1e-05\n",
      "29366/29366 [==============================] - 190s 6ms/step - loss: 0.0714 - categorical_accuracy: 0.9704 - val_loss: 0.3724 - val_categorical_accuracy: 0.9096\n",
      "Epoch 20/40\n",
      "29344/29366 [============================>.] - ETA: 0s - loss: 0.0673 - categorical_accuracy: 0.97211.001e-05 1e-05\n",
      "29366/29366 [==============================] - 191s 6ms/step - loss: 0.0673 - categorical_accuracy: 0.9721 - val_loss: 0.3982 - val_categorical_accuracy: 0.9095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe880c5da90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 47\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3262/3262 [==============================] - 3s 893us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29481033337657103, 0.90539377405188848]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_patch = extract_patches(read_data(1, 'QSM'), patch_shape=segment_size, extraction_step=(9, 9, 3)).shape[0]\n",
    "len_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3300/3300 [==============================] - 2s 740us/step\n",
      "2\n",
      "3300/3300 [==============================] - 2s 744us/step\n",
      "3\n",
      "3300/3300 [==============================] - 3s 773us/step\n",
      "4\n",
      "3300/3300 [==============================] - 2s 747us/step\n",
      "5\n",
      "3300/3300 [==============================] - 2s 746us/step\n",
      "6\n",
      "3300/3300 [==============================] - 2s 752us/step\n",
      "7\n",
      "3300/3300 [==============================] - 2s 752us/step\n",
      "8\n",
      "3300/3300 [==============================] - 2s 754us/step\n",
      "9\n",
      "3300/3300 [==============================] - 2s 754us/step\n",
      "10\n",
      "3300/3300 [==============================] - 2s 757us/step\n",
      "11\n",
      "3300/3300 [==============================] - 2s 756us/step\n",
      "12\n",
      "3300/3300 [==============================] - 2s 757us/step\n",
      "17\n",
      "3300/3300 [==============================] - 2s 757us/step\n",
      "18\n",
      "3300/3300 [==============================] - 3s 760us/step\n",
      "19\n",
      "3300/3300 [==============================] - 2s 757us/step\n",
      "20\n",
      "3300/3300 [==============================] - 3s 782us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_train = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_training):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_train = data_train[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_train[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    \n",
    "    segmentations_train = segmentations_train + [segmentation]\n",
    "    \n",
    "segmentations_train = np.stack(segmentations_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe8692ff0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEMkAABCIZAAACEQyAAAEIhkAAIL/AXYhwGuBRSnUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe834fe2cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Check false-positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_fpos = (label_train == 0) & (segmentations_train != 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_fpos = np.zeros(label_train.shape, dtype=precision_global)\n",
    "mask_fpos[idx_fpos == True] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADsJJREFUeJzt3VGS27oVBFAxNYvi/r+4K+bDmVi+lmRKQwlA45yq95e4\nWNO6VBMEqWXf9wsAAPDbf1ofAAAA9EZJBgCAQkkGAIBCSQYAgEJJBgCAQkkGAIBCSQYAgEJJBgCA\nQkkGAIDiq/UBXC6Xy7IsfvavoX3fl7P+LVm2JcscZ2Upx7bMZA5Z5jiapZVkAAAolGQAACiUZAAA\nKJRkAAAolGQAACiUZAAAKJRkAAAolGQAACiUZAAAKJRkAAAolOQHtm1rfQgAAB+nAynJAADcMHtR\n/mp9AL25/kCs69rwSAAA2pm9By37vrc+hsuyLO0P4vK7IM/2odj3fTnr3+oly1nNnOW2bVGze1aW\no+WYZuaZTCPLHEeztN2iSPqShZmYXQDOZCUZV8dBZJnDSnIGM5lDljmsJAPx3vlQyewPrADMzkoy\nro6DyDKHleQMZjKHLHNYSYY3scIIAPmsJOPqOIgsc1hJzmAmc8gyh5VkYEpHVvrdDQDgX6wk4+o4\niCyf1+v7la0kZzCTOWT5p5F/W+Jolkryi5J+mc/g55Dla3osykpyBjOZQ5Y5lGQOM/g5ZsvylZWM\nHgvxLUpyhtlmMpksn9fr+dae5EbsdYTP27bt8Oz1eMKe3dHsnF/7JBfuGf18qySfbPQPBLT07Jdt\nnTdf1tnWdfVgZod875FKSX4jJ2o47pXbcnXGfFmP6ae5//TfA173zJ280diTjH1WQUbN8idPSf/0\n/9trobInOcOoM8nfZJnDg3uN3PrS7f01KQY/hyz/redifE1JzmAmn9PzfMoyhwf3GvkebreBoU9m\nET7j2VvwqbfsGde0K8k9X61+mqvjHLLMYSU5g5nMIcsctltwmMHPIcscSnIGM5kjPcvet4aeSUnm\nsPTBn4kscyjJGcxkjhmyTPo14UeiS/JPtkrYZvG3GQZ/FiNnOdMqxhGpJfnWvtPkzEeaSc/SPDZS\nljwWXZI5l8HPIcscSSX50Vt/LpfsMmYmc8gyh5LMYQY/hyxzJJXkmY08k+68/mnkLPmTV8AdkPwr\nMZDAfPKIz8d7ff8MuL8zs7KSfGXWPZGzXB3PsCoyS5ZVYrZWkv80asazzmQiWeawkvyCdV0/dhJ2\nZQ59MItjGLEgA2NTkk929AvXCf/zvm8d/ovSNKZXft1L1uOSHYxh5Fm13eKA9G0YbiHlmDHLV+ez\n97m23SLDjDOZSpav6227lO0WJ7heafrXKqQVShjL9fYqswnwPj0V5GdYSf6HV69+ertqesTVcQ5Z\n3ndv5bjXWbWSnMFM5pDlcb2eV795T3JDvX84KoOfQ5a/fc9h79sq7lGS/zZilmYyhyxzKMkNjFaO\nvxn8HKNkOeqsfJKS/LcRPzejzCT/Jssc9iR/yE9+WtU+SGY1WtGhvRELMjA2K8m4Og4iyxxWkjOY\nyRwjZDnilqQWbLfgsBEGn2NkmUNJzmAmc8jyl4S7Okoyhxn8HLLMoSRnMJM5ZJnDnmQAAHiRkgwA\nAIWSDAAAhZIMAACFknwi7z0GANLM2m+83QJP7AaRZQ5vt8hgJnPIMoe3WwAAwIuUZAAAKJRkAABu\nmnU/8uWiJAMA8MCsRVlJBgDgrnVdWx9CE95ugSd2g8gyh7dbZDCTOWSZw9stAADgRUoyAAAUSjIA\nABRKMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAUXfyYCAAA9MRKMgAAFEoyAAAUSjIAABRKMgAAFEoy\nAAAUSjIAABRKMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAUSjIAABRKMgAA\nFEoyAAAUSjIAABRKMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAUSjIAABRK\nMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAUSjIA\nABRKMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAUX60P4HK5XJZl2Vsfw8z2fV/O+rdk2ZYsc5yVpRzb\nMpM5ZJnjaJZWkgEAoFCSAQCgUJIBAKBQkgEAoFCSAQCgUJIBAKBQkgEAoFCSAQCgUJIBAKBQkgEA\noFCSgeFt23bZtq31YQAQREl+ki9i6Mv3TK7r2vhIAEiy7Pve+hguy7K0P4iDEr+Q931fzvq3Rsoy\nkSxznJWlHNsykzlkmeNollaSn5RUjgEAuM1KMq6Og8gyh5XkDGYyhyxzWEkGAIAXKckAAFAoyQAA\nUCjJAABQKMkAwGF+L4BZeLsFntgNIssc3m6RwUzmkGWOo1l+vftA4FnXqxTeSw0AtGC7xYe4PXWM\nvxPwbdu2P/478r8HOIvtFh+2bVt3q6O93ELq8W8zml6y5Odm2W7x6tyPcr4wkzlk+csos/eIHxPp\nRF3ZGP2D9U7+NjCnV1aA13W1cgwNXH9Xp8+gkvxm907k6R+s3vh7f9bR2+Nwubx+gawow7menadH\nM5gwm7ZbfEh9GK2n2xVuIeXoKcuePuMjmmW7xZl6vHPX00zyM7L8JeHcfjRLJflJP/1w9PjhMvg5\nZJljtJLc47mtB2Yyhyz/7dbqcY/nBSW5Q/VLpJcvFYOfY7Yse5mhdxitJH/a95dx7/nPNpPJZHnM\nCOdlJbkjvZ/MZx38EQb5WbLMoSRnmHUmE8kyh5LMYTMPflq5mjnLNEpyBjOZQ5aPfX+fjvCDYF4B\nB09KeBJ3JvLqgzeZwOf0PGvfhXhd1///Nzo/S31D79sjeA95j0VefZADjEvfeWzqkuzDMYZ33rqR\n/WeMcPsNoHfOn59lTzJD7LNK2zv8Lr1nKcfjkvckz7RA0ftMcpwsc3hwj8MMfo4RslSUj0kuyd9m\n+CyMMJMcI8scHtyDA3p+CCLVO0qRHMf005+VljscY1ZeYyW5oV5WUUa/Ou7l79iD0bPktxlWkmdg\nJnPI8r7RtlDZbsFhBj/HjFmmXiQpyc/r8bMw40ymkmUO2y0641YHvEdvpYg2bv2QAfAac/TL1K+A\nA2Bs9Tbv9UVTjyvLMIKfzE3SKz9tt/iQeiLv6eTtFlIOWeaw3eKXR+fKns6j95jJHLJ8bKR9yfYk\nN3DrhD3Ch6aXwR/hC693vWTJzynJ4xfky8VMJpFlDiWZw3oZ/KRbNK30kiU/pyT/vS9yxPPCTDM5\nyoXLq3rMsteFuN4/C0ryh41c8Hob/JH/lq31liWvU5IzmMkcvWb5iaLce+l9lpLMYT0Ofq9Xx73r\nMUteoyRnMJM5ZJlDSeYwg59DljmU5AxmMocsc3hPMgAAvEhJZihecM67+GwBcM12C4a7hZT2AMGZ\nRsuS+2y3yGAmc8gyh+0WxFKQOYOVYwAeUZLhCdu2KVcAMAElGQAACnuSsc8qiCxz2JOcwUzmkGUO\ne5IBAOBFSjIAABRKMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAUSjIAABRK\nMgAAFEoyAAAUSjIAABRKMgAAFMu+762PAQAAumIlGQAACiUZAAAKJRkAAAolGQAACiUZAAAKJRkA\nAAolGQAACiUZAAAKJRkAAAolGQAACiUZAAAKJRkAAAolGQAACiUZAAAKJRkAAAolGQAACiUZAAAK\nJRkAAAolGQAACiUZAAAKJRkAAAolGQAACiUZAAAKJRkAAAolGQAACiUZAAAKJRkAAAolGQAACiUZ\nAAAKJRkAAAolGQAACiUZAAAKJRkAAAolGQAACiUZAAAKJRkAAAolGQAACiUZAAAKJRkAAAolGQAA\nCiUZAAAKJRkAAAolGQAACiUZAACKr9YHcLlcLsuy7K2PYWb7vi9n/VuybEuWOc7MEoDnWUkGAIBC\nSQYAgEJJBgCAQkkGAIBCSQYAgEJJBgCAQkkGAIBCSQYAgEJJBgCAQkkGAIBCSQYAgEJJBgCAQkkG\nAIBCSQYAgEJJBgCAQkkm2rZtl23bWh8GADCYZd/31sdwWZal/UFMbN/35ax/S5ZtyTLHmVkC8Dwr\nyQAAUCjJAABQKMkAAFAoyQAAUHy1PoDRXL8pYV3XhkcCAMC7eLvFSbZtG7Y0eyNCDlnm8HYLgLaU\nZBSry+Wvdym74Bk3y2rUC1glGaCtKfYkf/LHJPx4RT75jmVdV5kB8DQryVh9vHJ0z3mvq5OyfE2P\neVpJBmhLSX6T77LV2xfvLYrVn0Z+OFOWOZRkgLam2G7xCbf2tLrNO6brYiw/AJiTleSTXd+2vXcL\nt7dbu1Yfc8gyh5VkgLasJJ/suvzeK8I9FWR+rxbfWjW2kpyjZukhWwAesZKM1ccgssxhJRmgLSvJ\nxTtWl6xWAQCMJXoleaQ3TLRk9TGHLHNYSQZoK7okP6O3h+k+SbHKIcscSjJAW0oyilUQWeZQkgHa\nsif5f+wb5h6fDQCYj5L8P+/aauE1U+O4zunRa+EAgHxfrQ8g3az7nEcnNwCYmz3J2McaRJY57EkG\naMt2C7jBNhkAmJuS/GaK1ni8XzvPvTk0nwDcY7vFG1x/8Y5QtNyi/230gizLY0Z4L7rtFgBtKckn\nuvfF2/sXci/FavSC2oNeshxNjzOqJAO0pSSfoMcv2Gf0VKxG/1u21lOW/IySDNCWkoxiFUSWvyTc\nlVCSAdry4N5Bzz7g44Ggc/g78op1XYcuyAC0ZyX5CalbAaw+5pBlDivJAG0pyShWQWSZQ0kGaMt2\nCwAAKL5aHwD8xGjvpAYAxmC7BcPfor/1cN+shXn0LPnNdguAtpRkFKsgssyhJAO0ZU8yAAAUSjIA\nABRKMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAUSjIAABRKMgAAFEoyAAAU\nSjIAABRKMgAAFEoyAAAUSjIAABTLvu+tjwEAALpiJRkAAAolGQAACiUZAAAKJRkAAAolGQAACiUZ\nAAAKJRkAAAolGQAACiUZAAAKJRkAAAolGQAACiUZAAAKJRkAAAolGQAACiUZAAAKJRkAAAolGQAA\nCiUZAAAKJRkAAAolGQAACiUZAAAKJRkAAAolGQAAiv8C09hX1qVjxR0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe86911de48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(200*(np.squeeze(mask_fpos[0:15,:,:,25])), rows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Rebuild training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10547, 2, 27, 27, 21), (10547, 243, 11))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_step_ft = (6,6,3)\n",
    "x_train, y_train = build_set(data_train, label_train, extraction_step_ft, segment_size, core_size, mask_fpos)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "#idxs_shuffle = shuffle(x_train)\n",
    "#idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array('tmp/x_train.bc', x_train)\n",
    "save_array('tmp/y_train.bc', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = load_array('tmp/x_train.bc')\n",
    "#y_train = load_array('tmp/y_train.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Regenerate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('2'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('2'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9492 samples, validate on 1055 samples\n",
      "Epoch 1/40\n",
      "9492/9492 [==============================] - 57s 6ms/step - loss: 0.0449 - categorical_accuracy: 0.9833 - val_loss: 0.0039 - val_categorical_accuracy: 0.9987\n",
      "Epoch 2/40\n",
      "9492/9492 [==============================] - 57s 6ms/step - loss: 0.0327 - categorical_accuracy: 0.9870 - val_loss: 0.0015 - val_categorical_accuracy: 0.9996\n",
      "Epoch 3/40\n",
      "9492/9492 [==============================] - 57s 6ms/step - loss: 0.0290 - categorical_accuracy: 0.9883 - val_loss: 0.0017 - val_categorical_accuracy: 0.9995\n",
      "Epoch 4/40\n",
      "9492/9492 [==============================] - 58s 6ms/step - loss: 0.0266 - categorical_accuracy: 0.9892 - val_loss: 8.2780e-04 - val_categorical_accuracy: 0.9997\n",
      "Epoch 5/40\n",
      "9472/9492 [============================>.] - ETA: 0s - loss: 0.0250 - categorical_accuracy: 0.98980.0001 1e-05\n",
      "9492/9492 [==============================] - 58s 6ms/step - loss: 0.0250 - categorical_accuracy: 0.9898 - val_loss: 0.0017 - val_categorical_accuracy: 0.9994\n",
      "Epoch 6/40\n",
      "9472/9492 [============================>.] - ETA: 0s - loss: 0.0221 - categorical_accuracy: 0.99090.0001 1e-05\n",
      "9492/9492 [==============================] - 58s 6ms/step - loss: 0.0221 - categorical_accuracy: 0.9909 - val_loss: 9.1122e-04 - val_categorical_accuracy: 0.9996\n",
      "Epoch 7/40\n",
      "9472/9492 [============================>.] - ETA: 0s - loss: 0.0208 - categorical_accuracy: 0.9914 ETA: 8s - loss: 0.00.0001 1e-05\n",
      "9492/9492 [==============================] - 59s 6ms/step - loss: 0.0208 - categorical_accuracy: 0.9915 - val_loss: 0.0014 - val_categorical_accuracy: 0.9995\n",
      "Epoch 8/40\n",
      "9472/9492 [============================>.] - ETA: 0s - loss: 0.0187 - categorical_accuracy: 0.9923 - ETA: 55s 0.0001 1e-05\n",
      "9492/9492 [==============================] - 60s 6ms/step - loss: 0.0188 - categorical_accuracy: 0.9923 - val_loss: 0.0013 - val_categorical_accuracy: 0.9995\n",
      "Epoch 9/40\n",
      "9472/9492 [============================>.] - ETA: 0s - loss: 0.0178 - categorical_accuracy: 0.9927 - ETA0.0001 1e-05\n",
      "9492/9492 [==============================] - 59s 6ms/step - loss: 0.0177 - categorical_accuracy: 0.9927 - val_loss: 0.0012 - val_categorical_accuracy: 0.9996\n",
      "Epoch 10/40\n",
      "9472/9492 [============================>.] - ETA: 0s - loss: 0.0158 - categorical_accuracy: 0.9936\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "9492/9492 [==============================] - 59s 6ms/step - loss: 0.0158 - categorical_accuracy: 0.9936 - val_loss: 0.0010 - val_categorical_accuracy: 0.9996\n",
      "Epoch 11/40\n",
      "9472/9492 [============================>.] - ETA: 0s - loss: 0.0230 - categorical_accuracy: 0.99061.001e-05 1e-05\n",
      "9492/9492 [==============================] - 59s 6ms/step - loss: 0.0230 - categorical_accuracy: 0.9906 - val_loss: 0.0015 - val_categorical_accuracy: 0.9996\n",
      "Epoch 12/40\n",
      "9472/9492 [============================>.] - ETA: 0s - loss: 0.0224 - categorical_accuracy: 0.99081.001e-05 1e-05\n",
      "9492/9492 [==============================] - 60s 6ms/step - loss: 0.0224 - categorical_accuracy: 0.9908 - val_loss: 0.0016 - val_categorical_accuracy: 0.9995\n",
      "Epoch 13/40\n",
      "9472/9492 [============================>.] - ETA: 0s - loss: 0.0221 - categorical_accuracy: 0.99091.001e-05 1e-05\n",
      "9492/9492 [==============================] - 59s 6ms/step - loss: 0.0221 - categorical_accuracy: 0.9909 - val_loss: 0.0014 - val_categorical_accuracy: 0.9995\n",
      "Epoch 14/40\n",
      "9472/9492 [============================>.] - ETA: 0s - loss: 0.0218 - categorical_accuracy: 0.99101.001e-05 1e-05\n",
      "9492/9492 [==============================] - 59s 6ms/step - loss: 0.0218 - categorical_accuracy: 0.9910 - val_loss: 0.0016 - val_categorical_accuracy: 0.9995\n",
      "Epoch 15/40\n",
      "9472/9492 [============================>.] - ETA: 0s - loss: 0.0214 - categorical_accuracy: 0.99121.001e-05 1e-05\n",
      "9492/9492 [==============================] - 59s 6ms/step - loss: 0.0215 - categorical_accuracy: 0.9912 - val_loss: 0.0013 - val_categorical_accuracy: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe878732320>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "# Load optimized weights\n",
    "model.load_weights(model_filename.format('1'))\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-4)\n",
    "\n",
    "# Start fine-tuning\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054/1054 [==============================] - 1s 923us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00082844707712158207, 0.99971090367442061]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "3300/3300 [==============================] - 2s 757us/step\n",
      "14\n",
      "3300/3300 [==============================] - 2s 756us/step\n",
      "15\n",
      "3300/3300 [==============================] - 2s 746us/step\n",
      "16\n",
      "3300/3300 [==============================] - 2s 749us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_test = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_test = data_test[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_test[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    #segmentation = reconstruct_volume_majority(pred_classes, matrix_size, extraction_step=(3, 3, 3))\n",
    "    \n",
    "    segmentations_test = segmentations_test + [segmentation]\n",
    "    \n",
    "segmentations_test = np.stack(segmentations_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQEkGAIBASQYAgOB/U6YZko3D2EIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe857290a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe857cd95c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pick the largest connected component for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    segmentation = np.squeeze(segmentations_test[i_case,:,:,:]);\n",
    "    tmp = np.zeros(segmentation.shape, dtype=segmentation.dtype)\n",
    "    \n",
    "    for class_idx in class_mapper_inv :\n",
    "        mask = (segmentation == class_idx)\n",
    "        \n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            labeled_mask, num_cc = ndimage.label(mask)\n",
    "            largest_cc_mask = (labeled_mask == (np.bincount(labeled_mask.flat)[1:].argmax() + 1))\n",
    "            \n",
    "            tmp[largest_cc_mask == 1] = class_idx\n",
    "        \n",
    "    segmentations_test[i_case,:,:,:] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "Done with Step 3\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx)\n",
    "    \n",
    "    segmentation = np.copy(np.squeeze(segmentations_test[i_case,:,:,:]))\n",
    "    \n",
    "    tmp = np.copy(segmentation)\n",
    "    for class_idx in class_mapper_inv:\n",
    "        segmentation[tmp == class_idx] = class_mapper_inv[class_idx]\n",
    "    del tmp\n",
    "\n",
    "    save_data(segmentation, case_idx, 'label')    \n",
    "\n",
    "print(\"Done with Step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Calculate metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(m1, m2):\n",
    "    return 2*((m1==1) & (m2==1)).sum()/((m1==1).sum() + (m2==1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\t0.9993\tN/A\t0.8889\t0.9434\t0.8922\t0.9892\t0.9177\t0.9281\t0.9210\t0.8951\t0.8536\t0.9389\t\n",
      "14\t0.9985\tN/A\t0.9796\t0.9839\t0.8617\t0.9679\t0.8262\t0.7761\t0.9261\t0.9201\t0.9072\tN/A\t\n",
      "15\t0.9981\tN/A\t0.9524\t1.0000\t0.8452\t0.8842\t0.9633\t0.9879\t0.9107\t1.0000\t0.9889\t1.0000\t\n",
      "16\t0.9986\tN/A\t0.9231\t0.9474\t0.8778\t0.8808\t0.8864\t0.9556\t0.9599\t0.9180\t1.0000\t0.8636\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    print('{:.4f}'.format(accuracy_score(label_test[i_case,:,:,:].flat, segmentations_test[i_case,:,:,:].flat)), end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(precision_score(label_test[i_case,:,:,:][mask], segmentations_test[i_case,:,:,:][mask], average='micro')), end='\\t')\n",
    "        else:\n",
    "            print('N/A', end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\t0\t0.8205\t0.8475\t0.8445\t0.8026\t0.9161\t0.8558\t0.8701\t0.7800\t0.6846\t0.7376\t\n",
      "14\t0\t0.8727\t0.6421\t0.8417\t0.8229\t0.8459\t0.8232\t0.5165\t0.7031\t0.7002\t0\t\n",
      "15\t0\t0.7619\t0.3836\t0.9034\t0.7814\t0.9164\t0.9142\t0.5249\t0.2778\t0.1926\t0.0743\t\n",
      "16\t0\t0.8623\t0.8623\t0.9159\t0.8339\t0.9007\t0.9232\t0.7769\t0.7635\t0.0109\t0.0968\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(calc_dice((label_test[i_case,:,:,:]==class_idx).flat, (segmentations_test[i_case,:,:,:]==class_idx).flat)), end='\\t')\n",
    "        else:\n",
    "            print(0, end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
