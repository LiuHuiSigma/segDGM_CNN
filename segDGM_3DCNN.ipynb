{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "from utils import *\n",
    "from model_FCNN import generate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import keras\n",
    "reload(keras)\n",
    "from keras import backend as K\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "\n",
    "import model_FCNN\n",
    "reload(model_FCNN)\n",
    "from model_FCNN import generate_model\n",
    "\n",
    "import callback_custom\n",
    "reload(callback_custom);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11\n",
    "num_channel = 2\n",
    "\n",
    "# K-fold validation (K=5)\n",
    "n_training = 16\n",
    "n_test = 4\n",
    "\n",
    "#idxs_training = list(range(1, 1+16))\n",
    "#idxs_test = list(range(17, 17+4))\n",
    "idxs_training = list(range(1, 1+8)) + list(range(13, 13+8))\n",
    "idxs_test = list(range(9,9+4))\n",
    "\n",
    "patience = 5\n",
    "model_filename = 'models/outrun_step_{}.h5'\n",
    "csv_filename = 'log/outrun_step_{}.cvs'\n",
    "\n",
    "nb_epoch = 40\n",
    "validation_split = 0.10\n",
    "monitor = 'val_loss'#'val_categorical_accuracy'\n",
    "\n",
    "class_mapper = {0:0}\n",
    "class_mapper.update({ i+1:i for i in range(1, 1+10) })\n",
    "class_mapper_inv = {0:0}\n",
    "class_mapper_inv.update({ i:i+1 for i in range(1, 1+10) })\n",
    "\n",
    "matrix_size = (160, 220, 48)\n",
    "\n",
    "extraction_step = (3, 3, 1)\n",
    "#extraction_step = (5, 5, 3)\n",
    "\n",
    "segment_size = (27, 27, 21)\n",
    "core_size = (9, 9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "MAG_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "R2S_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "label_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_training):\n",
    "    QSM_train[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_train[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_train[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_train[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = np.stack((QSM_train, MAG_train, R2S_train), axis = 1)\n",
    "data_train = np.stack((QSM_train, R2S_train), axis = 1)\n",
    "#data_train = np.stack((QSM_train,), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "MAG_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "R2S_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "label_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_test):\n",
    "    QSM_test[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_test[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_test[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_test[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test = np.stack((QSM_test, MAG_test, R2S_test), axis = 1)\n",
    "data_test = np.stack((QSM_test, R2S_test), axis = 1)\n",
    "#data_test = np.stack((QSM_test,), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intensity normalisation (zero mean and unit variance)\n",
    "input_mean = 127.0\n",
    "input_std = 128.0\n",
    "data_train = (data_train - input_mean) / input_std\n",
    "data_test = (data_test - input_mean) / input_std\n",
    "\n",
    "# Map class label\n",
    "tmp = np.copy(label_train)\n",
    "for class_idx in class_mapper:\n",
    "    label_train[tmp == class_idx] = class_mapper[class_idx]\n",
    "tmp = np.copy(label_test)\n",
    "for class_idx in class_mapper:\n",
    "    label_test[tmp == class_idx] = class_mapper[class_idx]\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEACAYAAABBOusMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ed66e10f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0,:,:,[29,25]]), scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((33591, 2, 27, 27, 21), (33591, 243, 11))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Configure callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('1'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('1'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30231 samples, validate on 3360 samples\n",
      "Epoch 1/40\n",
      "30231/30231 [==============================] - 187s 6ms/step - loss: 0.3914 - categorical_accuracy: 0.8774 - val_loss: 0.2578 - val_categorical_accuracy: 0.9208\n",
      "Epoch 2/40\n",
      "30231/30231 [==============================] - 186s 6ms/step - loss: 0.0902 - categorical_accuracy: 0.9628 - val_loss: 0.3923 - val_categorical_accuracy: 0.9211\n",
      "Epoch 3/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0427 - categorical_accuracy: 0.98270.001 1e-05\n",
      "30231/30231 [==============================] - 186s 6ms/step - loss: 0.0427 - categorical_accuracy: 0.9827 - val_loss: 0.4559 - val_categorical_accuracy: 0.9235\n",
      "Epoch 4/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0278 - categorical_accuracy: 0.98930.001 1e-05\n",
      "30231/30231 [==============================] - 187s 6ms/step - loss: 0.0278 - categorical_accuracy: 0.9893 - val_loss: 0.5318 - val_categorical_accuracy: 0.9263\n",
      "Epoch 5/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0117 - categorical_accuracy: 0.99580.001 1e-05\n",
      "30231/30231 [==============================] - 188s 6ms/step - loss: 0.0117 - categorical_accuracy: 0.9958 - val_loss: 0.6242 - val_categorical_accuracy: 0.9221\n",
      "Epoch 6/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0217 - categorical_accuracy: 0.99250.001 1e-05\n",
      "30231/30231 [==============================] - 189s 6ms/step - loss: 0.0217 - categorical_accuracy: 0.9925 - val_loss: 0.4515 - val_categorical_accuracy: 0.9222\n",
      "Epoch 7/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0065 - categorical_accuracy: 0.9978\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "30231/30231 [==============================] - 190s 6ms/step - loss: 0.0065 - categorical_accuracy: 0.9978 - val_loss: 0.7122 - val_categorical_accuracy: 0.9237\n",
      "Epoch 8/40\n",
      "30231/30231 [==============================] - 191s 6ms/step - loss: 0.0848 - categorical_accuracy: 0.9644 - val_loss: 0.3552 - val_categorical_accuracy: 0.9222\n",
      "Epoch 9/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0556 - categorical_accuracy: 0.97700.0001 1e-05\n",
      "30231/30231 [==============================] - 190s 6ms/step - loss: 0.0555 - categorical_accuracy: 0.9770 - val_loss: 0.4724 - val_categorical_accuracy: 0.9186\n",
      "Epoch 10/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0347 - categorical_accuracy: 0.98600.0001 1e-05\n",
      "30231/30231 [==============================] - 189s 6ms/step - loss: 0.0347 - categorical_accuracy: 0.9860 - val_loss: 0.5964 - val_categorical_accuracy: 0.9164\n",
      "Epoch 11/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0207 - categorical_accuracy: 0.99190.0001 1e-05\n",
      "30231/30231 [==============================] - 190s 6ms/step - loss: 0.0207 - categorical_accuracy: 0.9919 - val_loss: 0.7003 - val_categorical_accuracy: 0.9155\n",
      "Epoch 12/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0123 - categorical_accuracy: 0.9954\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "30231/30231 [==============================] - 191s 6ms/step - loss: 0.0123 - categorical_accuracy: 0.9954 - val_loss: 0.7942 - val_categorical_accuracy: 0.9161\n",
      "Epoch 13/40\n",
      "30231/30231 [==============================] - 191s 6ms/step - loss: 0.1001 - categorical_accuracy: 0.9583 - val_loss: 0.2669 - val_categorical_accuracy: 0.9239\n",
      "Epoch 14/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0936 - categorical_accuracy: 0.96081.001e-05 1e-05\n",
      "30231/30231 [==============================] - 192s 6ms/step - loss: 0.0936 - categorical_accuracy: 0.9608 - val_loss: 0.2783 - val_categorical_accuracy: 0.9240\n",
      "Epoch 15/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0893 - categorical_accuracy: 0.9626 - ETA: 53s - loss: 0.0899 - categorical_ac - ETA: 50s - loss: 0.0898 - categorical_1.001e-05 1e-05\n",
      "30231/30231 [==============================] - 192s 6ms/step - loss: 0.0893 - categorical_accuracy: 0.9626 - val_loss: 0.2882 - val_categorical_accuracy: 0.9241\n",
      "Epoch 16/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0851 - categorical_accuracy: 0.96431.001e-05 1e-05\n",
      "30231/30231 [==============================] - 193s 6ms/step - loss: 0.0851 - categorical_accuracy: 0.9643 - val_loss: 0.3046 - val_categorical_accuracy: 0.9234\n",
      "Epoch 17/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0810 - categorical_accuracy: 0.96601.001e-05 1e-05\n",
      "30231/30231 [==============================] - 195s 6ms/step - loss: 0.0810 - categorical_accuracy: 0.9660 - val_loss: 0.3202 - val_categorical_accuracy: 0.9228\n",
      "Epoch 18/40\n",
      "30208/30231 [============================>.] - ETA: 0s - loss: 0.0768 - categorical_accuracy: 0.96781.001e-05 1e-05\n",
      "30231/30231 [==============================] - 196s 6ms/step - loss: 0.0768 - categorical_accuracy: 0.9678 - val_loss: 0.3333 - val_categorical_accuracy: 0.9223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7eaf465a58>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 47\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3359/3359 [==============================] - 3s 842us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25783444805740069, 0.92078507255322528]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_patch = extract_patches(read_data(1, 'QSM'), patch_shape=segment_size, extraction_step=(9, 9, 3)).shape[0]\n",
    "len_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3300/3300 [==============================] - 3s 808us/step\n",
      "2\n",
      "3300/3300 [==============================] - 3s 776us/step\n",
      "3\n",
      "3300/3300 [==============================] - 3s 774us/step\n",
      "4\n",
      "3300/3300 [==============================] - 3s 766us/step\n",
      "5\n",
      "3300/3300 [==============================] - 3s 765us/step\n",
      "6\n",
      "3300/3300 [==============================] - 3s 772us/step\n",
      "7\n",
      "3300/3300 [==============================] - 3s 771us/step\n",
      "8\n",
      "3300/3300 [==============================] - 3s 783us/step\n",
      "13\n",
      "3300/3300 [==============================] - 3s 777us/step\n",
      "14\n",
      "3300/3300 [==============================] - 3s 779us/step\n",
      "15\n",
      "3300/3300 [==============================] - 3s 776us/step\n",
      "16\n",
      "3300/3300 [==============================] - 3s 777us/step\n",
      "17\n",
      "3300/3300 [==============================] - 3s 778us/step\n",
      "18\n",
      "3300/3300 [==============================] - 3s 784us/step\n",
      "19\n",
      "3300/3300 [==============================] - 3s 790us/step\n",
      "20\n",
      "3300/3300 [==============================] - 3s 793us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_train = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_training):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_train = data_train[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_train[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    \n",
    "    segmentations_train = segmentations_train + [segmentation]\n",
    "    \n",
    "segmentations_train = np.stack(segmentations_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7eb8e40898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e87233da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Check false-positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_fpos = (label_train == 0) & (segmentations_train != 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_fpos = np.zeros(label_train.shape, dtype=precision_global)\n",
    "mask_fpos[idx_fpos == True] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e86be74a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(200*(np.squeeze(mask_fpos[0:15,:,:,25])), rows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Rebuild training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7873, 2, 27, 27, 21), (7873, 243, 11))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_step_ft = (6,6,3)\n",
    "x_train, y_train = build_set(data_train, label_train, extraction_step_ft, segment_size, core_size, mask_fpos)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array('tmp/x_train.bc', x_train)\n",
    "save_array('tmp/y_train.bc', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_array('tmp/x_train.bc')\n",
    "y_train = load_array('tmp/y_train.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Regenerate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('2'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('2'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7085 samples, validate on 788 samples\n",
      "Epoch 1/40\n",
      "7085/7085 [==============================] - 43s 6ms/step - loss: 0.0587 - categorical_accuracy: 0.9772 - val_loss: 0.0035 - val_categorical_accuracy: 0.9990\n",
      "Epoch 2/40\n",
      "7085/7085 [==============================] - 42s 6ms/step - loss: 0.0452 - categorical_accuracy: 0.9816 - val_loss: 0.0037 - val_categorical_accuracy: 0.9991\n",
      "Epoch 3/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0406 - categorical_accuracy: 0.98330.0001 1e-05\n",
      "7085/7085 [==============================] - 43s 6ms/step - loss: 0.0405 - categorical_accuracy: 0.9834 - val_loss: 0.0037 - val_categorical_accuracy: 0.9989\n",
      "Epoch 4/40\n",
      "7085/7085 [==============================] - 43s 6ms/step - loss: 0.0373 - categorical_accuracy: 0.9845 - val_loss: 0.0021 - val_categorical_accuracy: 0.9993\n",
      "Epoch 5/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0346 - categorical_accuracy: 0.98560.0001 1e-05\n",
      "7085/7085 [==============================] - 43s 6ms/step - loss: 0.0346 - categorical_accuracy: 0.9856 - val_loss: 0.0039 - val_categorical_accuracy: 0.9987\n",
      "Epoch 6/40\n",
      "7085/7085 [==============================] - 43s 6ms/step - loss: 0.0322 - categorical_accuracy: 0.9867 - val_loss: 0.0019 - val_categorical_accuracy: 0.9994\n",
      "Epoch 7/40\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0298 - categorical_accuracy: 0.9877 - val_loss: 0.0014 - val_categorical_accuracy: 0.9996\n",
      "Epoch 8/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0276 - categorical_accuracy: 0.98860.0001 1e-05\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0276 - categorical_accuracy: 0.9886 - val_loss: 0.0035 - val_categorical_accuracy: 0.9986\n",
      "Epoch 9/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0259 - categorical_accuracy: 0.98940.0001 1e-05\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0259 - categorical_accuracy: 0.9894 - val_loss: 0.0016 - val_categorical_accuracy: 0.9994\n",
      "Epoch 10/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0245 - categorical_accuracy: 0.99000.0001 1e-05\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0245 - categorical_accuracy: 0.9900 - val_loss: 0.0019 - val_categorical_accuracy: 0.9993\n",
      "Epoch 11/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0223 - categorical_accuracy: 0.99100.0001 1e-05\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0222 - categorical_accuracy: 0.9910 - val_loss: 0.0017 - val_categorical_accuracy: 0.9993\n",
      "Epoch 12/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0200 - categorical_accuracy: 0.99190.0001 1e-05\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0200 - categorical_accuracy: 0.9919 - val_loss: 0.0015 - val_categorical_accuracy: 0.9994\n",
      "Epoch 13/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0186 - categorical_accuracy: 0.9925\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0187 - categorical_accuracy: 0.9925 - val_loss: 0.0026 - val_categorical_accuracy: 0.9991\n",
      "Epoch 14/40\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0260 - categorical_accuracy: 0.9894 - val_loss: 0.0015 - val_categorical_accuracy: 0.9995\n",
      "Epoch 15/40\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0253 - categorical_accuracy: 0.9897 - val_loss: 0.0015 - val_categorical_accuracy: 0.9995\n",
      "Epoch 16/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0249 - categorical_accuracy: 0.98991.001e-05 1e-05\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0249 - categorical_accuracy: 0.9899 - val_loss: 0.0016 - val_categorical_accuracy: 0.9994\n",
      "Epoch 17/40\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0246 - categorical_accuracy: 0.9900 - val_loss: 0.0015 - val_categorical_accuracy: 0.9995\n",
      "Epoch 18/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0243 - categorical_accuracy: 0.99011.001e-05 1e-05\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0242 - categorical_accuracy: 0.9901 - val_loss: 0.0016 - val_categorical_accuracy: 0.9994\n",
      "Epoch 19/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0240 - categorical_accuracy: 0.99031.001e-05 1e-05\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0239 - categorical_accuracy: 0.9903 - val_loss: 0.0016 - val_categorical_accuracy: 0.9994\n",
      "Epoch 20/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0236 - categorical_accuracy: 0.99051.001e-05 1e-05\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0236 - categorical_accuracy: 0.9905 - val_loss: 0.0015 - val_categorical_accuracy: 0.9995\n",
      "Epoch 21/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0233 - categorical_accuracy: 0.99051.001e-05 1e-05\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0233 - categorical_accuracy: 0.9906 - val_loss: 0.0018 - val_categorical_accuracy: 0.9994\n",
      "Epoch 22/40\n",
      "7072/7085 [============================>.] - ETA: 0s - loss: 0.0230 - categorical_accuracy: 0.99071.001e-05 1e-05\n",
      "7085/7085 [==============================] - 44s 6ms/step - loss: 0.0230 - categorical_accuracy: 0.9907 - val_loss: 0.0016 - val_categorical_accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e86a8bf60>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "# Load optimized weights\n",
    "model.load_weights(model_filename.format('1'))\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-4)\n",
    "\n",
    "# Start fine-tuning\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787/787 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0014225059498652929, 0.99955534351826325]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "3300/3300 [==============================] - 3s 792us/step\n",
      "10\n",
      "3300/3300 [==============================] - 3s 769us/step\n",
      "11\n",
      "3300/3300 [==============================] - 3s 770us/step\n",
      "12\n",
      "3300/3300 [==============================] - 3s 762us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_test = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_test = data_test[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_test[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    #segmentation = reconstruct_volume_majority(pred_classes, matrix_size, extraction_step=(3, 3, 3))\n",
    "    \n",
    "    segmentations_test = segmentations_test + [segmentation]\n",
    "    \n",
    "segmentations_test = np.stack(segmentations_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABtVJREFUeJzt3ett20gUgFFykS5UhlSH21AZgstQG6pDbbgO7g+DMX0j\nUqMn53EOsEAW+REBuRl8vhpR/TAMHQAA8OO/tV8AAADkRiQDAEAgkgEAIBDJAAAQiGQAAAhEMgAA\nBCIZAAACkQwAAIFIBgCA4M/aL6Druq7ve1/7x8OGYejf/WeaXZ7B7FKqd8+uueUZUufWJhkAAAKR\nDAAAgUgGAIBAJAMAQCCSAQAgEMkAABCIZAAACEQyAAAEIhkAAAKRDAAAgUgGAIBAJAMAQCCSAQAg\nEMkAABCIZAAACEQyAAAEIhkAAAKRDAAAgUgGAIBAJAMAQCCSAQAgEMkAABCIZAAACEQyAAAEIhkA\nAAKRDAAAgUgGAIBAJAMAQCCSAQAgEMkAABCIZAAACERyZo7HY3c8Hi/+3vl87s7n85tfEQBAe/ph\nGNZ+DV3f9+u/iAzEON7v97/+/1Ig73a7l76mkgzD0L/7zzS7l93yw5wZNruU692za255htS5FcmZ\nmNseT0M5JTxaDg6hkY9nvePRyjybXUolkilR6tz+efUL4THTeN7tdlfj43w+NxMW5GucQdeDKJnz\nlBJ45+51bJIzMrdNjvb7va3yBbZx+Xs0mmudabObj6UZrXX+HmGTvL57z9WW5zl1bn1wLyPxDvKc\n4/HY9HBTD3MM8Jh7z1Hv9F1nk5yplK3yGNXXBr2VELGNK8PSbG+327+/bmVuu87s5sRb17exSc7H\n9HrQrQHc2izbJBcudasMNdntdn//gzVMZ+/aHHosJzm5ZXYjc3yZTXIBljZvKU+/aCU4bOPKkTrT\no7lzqu/f/lf+EmY3X3FWp+92RK2ctVM2yXlZelKWzzL9sEluROqH/SAn+/3+Ygx7B4XcLUWEbRxr\nmztDfZbpPjbJBUnZvo2HdIv/GGzj6rR0Rtkk38/sppn7kqfW37kb2STn6Z6Nckuza5PcmPEfhPuc\nAK+ztKxw9pKLpY1ypBvm2SQXKOXb+VpkG1ef2u8ij8xu3q5da2v57LVJztul2V2a1+mZW9s5O2WT\nDABPcC2CfTaEXM19/iMahuGfpUQOS9S1+VrqArW8taBtNW82AF5lrhuE8DKRDGRLFJOLMTJsjalJ\n3/cXQ9nZ+811CwCABtgc30YkA0Ai190oWdwQ2yIv83QLquEJAZTK7JZpvHrRcjh7ukXZxgZsLYxT\n51YkUw2hQanMLqUSyZTII+AAAOBOIhkAAAKRDAAAgUgGAIDAl4kU6HA4dF3XdZ+fnyu/EniNr6+v\nxd/fbDZveiUAdZuet87W32ySgeJci2gArnOWLvMIuMKMW+QpG+VvHqNVn1Y2ymaXUnkEXPkunbO1\nnK1zPAIOAF7o0tICSmKTvEwkF8SBTM3umW8HPGsZ59W5TClumVVn6zeRXIiU4T6dTt3pdHrDq4Hn\nmpvvlLf8HOYA8w6Hw+wPdZvNpvqrFY/wdIvMpf7kN43j8dcfHx8veU3wDKmzvdlsFkPYAc872RxT\nirlZPRwO3Xa77brupxPGc9TS4TeRnLFrh/H4gb257fHpdBLKZOvz89PjDAFeYK4fYjfEpZqlw2+e\nbpGplEBOvVrRSih7QkD+Hr0O9PHxUeUzPc1u/pbO5JZ/yPN0i/wsBfK1M1gv/OZOcoZSN8jQovEO\nXS2BTD18JoS1zfXDdrs1n3dw3SIzNsjUxKFM6W79XIhrbuTg2nVM0ojkgqRukB3Q5MDhTAsuncs+\nPM0apj+g3XP+mtd/uZOckWvfpmeDvMy9znw94y5yzcxunlK2yONTAuaY3ecyt789axlR+5xGqXNr\nk5yxW98uaW3IKUeczVsOdnPNGlIC+Zbrb/BsAvn1bJIz4a2Rx9nGUSqzm49nxHFLZ7NN8vpu7YeW\n5nOOTXLFDDjAOpaeEuBsZg3m7nVskqmGbRylMrv5ct1tmU0yJbJJBoAbuPYGTIlkAJpnYwxErltQ\nDW9ZUyqzS6lct6BEvpYaAADuJJIBACAQyQAAEIhkAAAIRDIAAAQiGQAAApEMAACBSAYAgEAkAwBA\nIJIBACAQyQAAEIhkAAAIRDIAAAQiGQAAApEMAACBSAYAgEAkAwBAIJIBACAQyQAAEIhkAAAIRDIA\nAAQiGQAAApEMAACBSAYAgEAkAwBAIJIBACAQyQAAEIhkAAAIRDIAAAQiGQAAgn4YhrVfAwAAZMUm\nGQAAApEMAACBSAYAgEAkAwBAIJIBACAQyQAAEIhkAAAIRDIAAAQiGQAAApEMAACBSAYAgEAkAwBA\nIJIBACAQyQAAEIhkAAAIRDIAAAQiGQAAApEMAACBSAYAgEAkAwBAIJIBACAQyQAAEIhkAAAI/geS\noeUhLmIIuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e85be7cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e86a8b630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pick the largest connected component for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    segmentation = np.squeeze(segmentations_test[i_case,:,:,:]);\n",
    "    tmp = np.zeros(segmentation.shape, dtype=segmentation.dtype)\n",
    "    \n",
    "    for class_idx in class_mapper_inv :\n",
    "        mask = (segmentation == class_idx)\n",
    "        \n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            labeled_mask, num_cc = ndimage.label(mask)\n",
    "            largest_cc_mask = (labeled_mask == (np.bincount(labeled_mask.flat)[1:].argmax() + 1))\n",
    "            \n",
    "            tmp[largest_cc_mask == 1] = class_idx\n",
    "        \n",
    "    segmentations_test[i_case,:,:,:] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "Done with Step 3\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx)\n",
    "    \n",
    "    segmentation = np.copy(np.squeeze(segmentations_test[i_case,:,:,:]))\n",
    "    \n",
    "    tmp = np.copy(segmentation)\n",
    "    for class_idx in class_mapper_inv:\n",
    "        segmentation[tmp == class_idx] = class_mapper_inv[class_idx]\n",
    "    del tmp\n",
    "\n",
    "    save_data(segmentation, case_idx, 'label')    \n",
    "\n",
    "print(\"Done with Step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Calculate metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(m1, m2):\n",
    "    return 2*((m1==1) & (m2==1)).sum()/((m1==1).sum() + (m2==1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\t0.9991\tN/A\t0.7529\t0.8125\t0.9262\t0.9676\t0.8361\t0.6384\t0.9349\t0.7836\t0.7188\t0.8698\t\n",
      "10\t0.9991\tN/A\t0.8980\t0.8267\t0.7157\t0.8270\t0.7823\t0.7761\t0.9162\t0.9344\t0.7500\t0.7332\t\n",
      "11\t0.9992\tN/A\t0.7907\t0.8000\t0.8798\t0.8366\t0.8072\t0.7675\t0.8544\t0.8683\t0.8719\t0.5607\t\n",
      "12\t0.9993\tN/A\t0.8810\t0.8750\t0.9537\t0.9626\t0.9884\t0.9121\t0.8593\t0.9251\t0.5564\t0.5479\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    print('{:.4f}'.format(accuracy_score(label_test[i_case,:,:,:].flat, segmentations_test[i_case,:,:,:].flat)), end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(precision_score(label_test[i_case,:,:,:][mask], segmentations_test[i_case,:,:,:][mask], average='micro')), end='\\t')\n",
    "        else:\n",
    "            print('N/A', end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\t0\t0.8312\t0.8497\t0.7931\t0.8775\t0.8648\t0.7676\t0.8671\t0.7755\t0.7823\t0.8931\t\n",
      "10\t0\t0.8000\t0.8493\t0.5123\t0.7612\t0.8467\t0.8633\t0.8545\t0.8747\t0.7702\t0.7603\t\n",
      "11\t0\t0.8608\t0.8387\t0.9096\t0.8678\t0.8602\t0.7497\t0.8824\t0.6388\t0.8624\t0.6369\t\n",
      "12\t0\t0.8506\t0.7692\t0.7574\t0.8996\t0.9031\t0.9275\t0.8417\t0.8380\t0.6327\t0.6830\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(calc_dice((label_test[i_case,:,:,:]==class_idx).flat, (segmentations_test[i_case,:,:,:]==class_idx).flat)), end='\\t')\n",
    "        else:\n",
    "            print(0, end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
