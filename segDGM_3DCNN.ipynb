{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "from utils import *\n",
    "from model_FCNN import generate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'callback_custom' from '/home/kumamon/src/segDGM_3DCNN/callback_custom.py'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import keras\n",
    "reload(keras)\n",
    "from keras import backend as K\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "\n",
    "import model_FCNN\n",
    "reload(model_FCNN)\n",
    "from model_FCNN import generate_model\n",
    "\n",
    "import callback_custom\n",
    "reload(callback_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11\n",
    "num_channel = 1\n",
    "\n",
    "# K-fold validation (K=5)\n",
    "n_training = 16\n",
    "n_test = 4\n",
    "\n",
    "idxs_training = list(range(1, 1+16))\n",
    "idxs_test = list(range(17, 17+4))\n",
    "\n",
    "patience = 5\n",
    "model_filename = 'models/outrun_step_{}.h5'\n",
    "csv_filename = 'log/outrun_step_{}.cvs'\n",
    "\n",
    "nb_epoch = 40\n",
    "validation_split = 0.20\n",
    "monitor = 'val_loss'#'val_categorical_accuracy'\n",
    "\n",
    "class_mapper = {0:0}\n",
    "class_mapper.update({ i+1:i for i in range(1, 1+10) })\n",
    "class_mapper_inv = {0:0}\n",
    "class_mapper_inv.update({ i:i+1 for i in range(1, 1+10) })\n",
    "\n",
    "matrix_size = (160, 220, 48)\n",
    "\n",
    "extraction_step = (3, 3, 3)\n",
    "#extraction_step = (9, 9, 3)\n",
    "\n",
    "segment_size = (27, 27, 21)\n",
    "core_size = (9, 9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "MAG_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "R2S_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "label_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_training):\n",
    "    QSM_train[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_train[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_train[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_train[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = np.stack((QSM_train, MAG_train, R2S_train), axis = 1)\n",
    "data_train = np.stack((QSM_train,), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "MAG_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "R2S_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "label_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_test):\n",
    "    QSM_test[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_test[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_test[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_test[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test = np.stack((QSM_test, MAG_test, R2S_test), axis = 1)\n",
    "data_test = np.stack((QSM_test,), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intensity normalisation (zero mean and unit variance)\n",
    "input_mean = 127.0\n",
    "input_std = 128.0\n",
    "data_train = (data_train - input_mean) / input_std\n",
    "data_test = (data_test - input_mean) / input_std\n",
    "\n",
    "# Map class label\n",
    "tmp = np.copy(label_train)\n",
    "for class_idx in class_mapper:\n",
    "    label_train[tmp == class_idx] = class_mapper[class_idx]\n",
    "tmp = np.copy(label_test)\n",
    "for class_idx in class_mapper:\n",
    "    label_test[tmp == class_idx] = class_mapper[class_idx]\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEACAYAAABBOusMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b8d6bfb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0,:,:,[29,25]]), scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10850, 1, 27, 27, 21), (10850, 243, 11))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Configure callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping for reducing over-fitting risk\n",
    "stopper = EarlyStopping(patience=patience, monitor='val_categorical_accuracy')\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('1'),\n",
    "    monitor='val_categorical_accuracy',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_categorical_accuracy', \n",
    "                                            patience=patience, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.1, \n",
    "                                            min_lr=1e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('1'),\n",
    "    monitor=monitor,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('1'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8680 samples, validate on 2170 samples\n",
      "Epoch 1/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.6799 - categorical_accuracy: 0.8149Epoch 00001: val_loss improved from inf to 0.54188, saving model to models/outrun_step_1.h5\n",
      "8680/8680 [==============================] - 55s 6ms/step - loss: 0.6797 - categorical_accuracy: 0.8149 - val_loss: 0.5419 - val_categorical_accuracy: 0.8283\n",
      "Epoch 2/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.2810 - categorical_accuracy: 0.9024Epoch 00002: val_loss did not improve\n",
      "8680/8680 [==============================] - 52s 6ms/step - loss: 0.2808 - categorical_accuracy: 0.9025 - val_loss: 0.6537 - val_categorical_accuracy: 0.8613\n",
      "Epoch 3/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.1363 - categorical_accuracy: 0.9453Epoch 00003: val_loss improved from 0.54188 to 0.50965, saving model to models/outrun_step_1.h5\n",
      "8680/8680 [==============================] - 53s 6ms/step - loss: 0.1363 - categorical_accuracy: 0.9453 - val_loss: 0.5097 - val_categorical_accuracy: 0.8799\n",
      "Epoch 4/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.1026 - categorical_accuracy: 0.9581Epoch 00004: val_loss improved from 0.50965 to 0.45949, saving model to models/outrun_step_1.h5\n",
      "8680/8680 [==============================] - 54s 6ms/step - loss: 0.1027 - categorical_accuracy: 0.9581 - val_loss: 0.4595 - val_categorical_accuracy: 0.9025\n",
      "Epoch 5/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0765 - categorical_accuracy: 0.9683Epoch 00005: val_loss did not improve\n",
      "0.001 1e-05\n",
      "8680/8680 [==============================] - 54s 6ms/step - loss: 0.0765 - categorical_accuracy: 0.9683 - val_loss: 0.6237 - val_categorical_accuracy: 0.8943\n",
      "Epoch 6/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0557 - categorical_accuracy: 0.9771Epoch 00006: val_loss did not improve\n",
      "0.001 1e-05\n",
      "8680/8680 [==============================] - 54s 6ms/step - loss: 0.0557 - categorical_accuracy: 0.9771 - val_loss: 0.6760 - val_categorical_accuracy: 0.8973\n",
      "Epoch 7/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0454 - categorical_accuracy: 0.9817Epoch 00007: val_loss did not improve\n",
      "0.001 1e-05\n",
      "8680/8680 [==============================] - 54s 6ms/step - loss: 0.0454 - categorical_accuracy: 0.9817 - val_loss: 0.6133 - val_categorical_accuracy: 0.9029\n",
      "Epoch 8/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0372 - categorical_accuracy: 0.9853Epoch 00008: val_loss did not improve\n",
      "0.001 1e-05\n",
      "8680/8680 [==============================] - 54s 6ms/step - loss: 0.0372 - categorical_accuracy: 0.9853 - val_loss: 0.7462 - val_categorical_accuracy: 0.9006\n",
      "Epoch 9/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0262 - categorical_accuracy: 0.9898Epoch 00009: val_loss did not improve\n",
      "0.001 1e-05\n",
      "8680/8680 [==============================] - 54s 6ms/step - loss: 0.0262 - categorical_accuracy: 0.9898 - val_loss: 0.6461 - val_categorical_accuracy: 0.9011\n",
      "Epoch 10/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0266 - categorical_accuracy: 0.9898Epoch 00010: val_loss did not improve\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "8680/8680 [==============================] - 55s 6ms/step - loss: 0.0266 - categorical_accuracy: 0.9898 - val_loss: 0.8134 - val_categorical_accuracy: 0.9006\n",
      "Epoch 11/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0634 - categorical_accuracy: 0.9737 - ETA: 17s - los - ETA: 3s - loss: 0.0 - ETA: 0s - loss: 0.0634 - categorical_accuracy: 0.Epoch 00011: val_loss did not improve\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 0.0634 - categorical_accuracy: 0.9737 - val_loss: 0.5822 - val_categorical_accuracy: 0.9002\n",
      "Epoch 12/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0531 - categorical_accuracy: 0.9781Epoch 00012: val_loss did not improve\n",
      "0.0001 1e-05\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 0.0531 - categorical_accuracy: 0.9781 - val_loss: 0.6618 - val_categorical_accuracy: 0.8995\n",
      "Epoch 13/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0456 - categorical_accuracy: 0.9815Epoch 00013: val_loss did not improve\n",
      "0.0001 1e-05\n",
      "8680/8680 [==============================] - 56s 7ms/step - loss: 0.0456 - categorical_accuracy: 0.9815 - val_loss: 0.7148 - val_categorical_accuracy: 0.8985\n",
      "Epoch 14/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0385 - categorical_accuracy: 0.9847Epoch 00014: val_loss did not improve\n",
      "0.0001 1e-05\n",
      "8680/8680 [==============================] - 56s 7ms/step - loss: 0.0385 - categorical_accuracy: 0.9847 - val_loss: 0.7899 - val_categorical_accuracy: 0.8981\n",
      "Epoch 15/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0314 - categorical_accuracy: 0.9878 ETA: 4s - lEpoch 00015: val_loss did not improve\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 0.0314 - categorical_accuracy: 0.9878 - val_loss: 0.8798 - val_categorical_accuracy: 0.8963\n",
      "Epoch 16/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0694 - categorical_accuracy: 0.9710Epoch 00016: val_loss did not improve\n",
      "8680/8680 [==============================] - 56s 7ms/step - loss: 0.0694 - categorical_accuracy: 0.9710 - val_loss: 0.5076 - val_categorical_accuracy: 0.9012\n",
      "Epoch 17/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0643 - categorical_accuracy: 0.9732 ETA: 2s - loss: 0.0642 - Epoch 00017: val_loss did not improve\n",
      "1.001e-05 1e-05\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 0.0644 - categorical_accuracy: 0.9732 - val_loss: 0.5291 - val_categorical_accuracy: 0.9016\n",
      "Epoch 18/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0619 - categorical_accuracy: 0.9743Epoch 00018: val_loss did not improve\n",
      "1.001e-05 1e-05\n",
      "8680/8680 [==============================] - 56s 7ms/step - loss: 0.0619 - categorical_accuracy: 0.9743 - val_loss: 0.5566 - val_categorical_accuracy: 0.9006\n",
      "Epoch 19/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0599 - categorical_accuracy: 0.9751Epoch 00019: val_loss did not improve\n",
      "1.001e-05 1e-05\n",
      "8680/8680 [==============================] - 56s 7ms/step - loss: 0.0599 - categorical_accuracy: 0.9751 - val_loss: 0.5552 - val_categorical_accuracy: 0.9017\n",
      "Epoch 20/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0581 - categorical_accuracy: 0.9759Epoch 00020: val_loss did not improve\n",
      "1.001e-05 1e-05\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 0.0581 - categorical_accuracy: 0.9759 - val_loss: 0.5698 - val_categorical_accuracy: 0.9017\n",
      "Epoch 21/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0565 - categorical_accuracy: 0.9767Epoch 00021: val_loss did not improve\n",
      "1.001e-05 1e-05\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 0.0565 - categorical_accuracy: 0.9767 - val_loss: 0.5866 - val_categorical_accuracy: 0.9005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7f12ecda0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 47\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2170/2170 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45949072467017282, 0.90250119833352926]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_patch = extract_patches(read_data(1, 'QSM'), patch_shape=segment_size, extraction_step=(9, 9, 3)).shape[0]\n",
    "len_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3300/3300 [==============================] - 3s 930us/step\n",
      "2\n",
      "3300/3300 [==============================] - 3s 803us/step\n",
      "3\n",
      "3300/3300 [==============================] - 3s 773us/step\n",
      "4\n",
      "3300/3300 [==============================] - 3s 785us/step\n",
      "5\n",
      "3300/3300 [==============================] - 3s 774us/step\n",
      "6\n",
      "3300/3300 [==============================] - 3s 777us/step\n",
      "7\n",
      "3300/3300 [==============================] - 3s 770us/step\n",
      "8\n",
      "3300/3300 [==============================] - 3s 780us/step\n",
      "9\n",
      "3300/3300 [==============================] - 3s 792us/step\n",
      "10\n",
      "3300/3300 [==============================] - 3s 778us/step\n",
      "11\n",
      "3300/3300 [==============================] - 3s 786us/step\n",
      "12\n",
      "3300/3300 [==============================] - 3s 790us/step\n",
      "13\n",
      "3300/3300 [==============================] - 3s 782us/step\n",
      "14\n",
      "3300/3300 [==============================] - 3s 795us/step\n",
      "15\n",
      "3300/3300 [==============================] - 3s 785us/step\n",
      "16\n",
      "3300/3300 [==============================] - 3s 795us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_train = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_training):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_train = data_train[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_train[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    \n",
    "    segmentations_train = segmentations_train + [segmentation]\n",
    "    \n",
    "segmentations_train = np.stack(segmentations_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB50gGBd8oorSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa86ee7a0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvm+aAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa86ee7a320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Check false-positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_fpos = (label_train == 0) & (segmentations_train != 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_fpos = np.zeros(label_train.shape, dtype=precision_global)\n",
    "mask_fpos[idx_fpos == True] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhGQAACiEZAAAKIRkAAAohGQAACj+Af7VjdJNY9RzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa7f7add5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(200*(np.squeeze(mask_fpos[0:15,:,:,25])), rows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Rebuild training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((34305, 1, 27, 27, 21), (34305, 243, 11))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size, mask_fpos)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array('tmp/x_train.bc', x_train)\n",
    "save_array('tmp/y_train.bc', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_array('tmp/x_train.bc')\n",
    "y_train = load_array('tmp/y_train.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Regenerate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping for reducing over-fitting risk\n",
    "stopper = EarlyStopping(patience=patience, monitor='val_categorical_accuracy')\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('2'),\n",
    "    monitor='val_categorical_accuracy',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_categorical_accuracy', \n",
    "                                            patience=patience, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.1, \n",
    "                                            min_lr=1e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('2'),\n",
    "    monitor=monitor,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('2'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27444 samples, validate on 6861 samples\n",
      "Epoch 1/40\n",
      "27424/27444 [============================>.] - ETA: 0s - loss: 0.0260 - categorical_accuracy: 0.9895Epoch 00001: val_loss improved from inf to 0.33690, saving model to models/outrun_step_2.h5\n",
      "27444/27444 [==============================] - 170s 6ms/step - loss: 0.0260 - categorical_accuracy: 0.9895 - val_loss: 0.3369 - val_categorical_accuracy: 0.9566\n",
      "Epoch 2/40\n",
      "27424/27444 [============================>.] - ETA: 0s - loss: 0.0158 - categorical_accuracy: 0.9936Epoch 00002: val_loss did not improve\n",
      "27444/27444 [==============================] - 168s 6ms/step - loss: 0.0158 - categorical_accuracy: 0.9936 - val_loss: 0.3807 - val_categorical_accuracy: 0.9564\n",
      "Epoch 3/40\n",
      "27424/27444 [============================>.] - ETA: 0s - loss: 0.0120 - categorical_accuracy: 0.9952Epoch 00003: val_loss did not improve\n",
      "0.0001 1e-05\n",
      "27444/27444 [==============================] - 169s 6ms/step - loss: 0.0120 - categorical_accuracy: 0.9952 - val_loss: 0.3828 - val_categorical_accuracy: 0.9581\n",
      "Epoch 4/40\n",
      "27424/27444 [============================>.] - ETA: 0s - loss: 0.0093 - categorical_accuracy: 0.9963Epoch 00004: val_loss did not improve\n",
      "27444/27444 [==============================] - 170s 6ms/step - loss: 0.0093 - categorical_accuracy: 0.9963 - val_loss: 0.3798 - val_categorical_accuracy: 0.9581\n",
      "Epoch 5/40\n",
      "27424/27444 [============================>.] - ETA: 0s - loss: 0.0070 - categorical_accuracy: 0.9973 ETA: 7s - loss: 0.0070 - categorical_Epoch 00005: val_loss did not improve\n",
      "0.0001 1e-05\n",
      "27444/27444 [==============================] - 172s 6ms/step - loss: 0.0070 - categorical_accuracy: 0.9973 - val_loss: 0.4335 - val_categorical_accuracy: 0.9572\n",
      "Epoch 6/40\n",
      "27424/27444 [============================>.] - ETA: 0s - loss: 0.0053 - categorical_accuracy: 0.9980Epoch 00006: val_loss did not improve\n",
      "0.0001 1e-05\n",
      "27444/27444 [==============================] - 175s 6ms/step - loss: 0.0053 - categorical_accuracy: 0.9980 - val_loss: 0.4801 - val_categorical_accuracy: 0.9558\n",
      "Epoch 7/40\n",
      "27424/27444 [============================>.] - ETA: 0s - loss: 0.0063 - categorical_accuracy: 0.9978 ETA: 2s - loss: 0.0063 - cateEpoch 00007: val_loss did not improve\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "27444/27444 [==============================] - 175s 6ms/step - loss: 0.0063 - categorical_accuracy: 0.9978 - val_loss: 0.4047 - val_categorical_accuracy: 0.9576\n",
      "Epoch 8/40\n",
      "27424/27444 [============================>.] - ETA: 0s - loss: 0.0164 - categorical_accuracy: 0.9934Epoch 00008: val_loss improved from 0.33690 to 0.33092, saving model to models/outrun_step_2.h5\n",
      "27444/27444 [==============================] - 177s 6ms/step - loss: 0.0164 - categorical_accuracy: 0.9934 - val_loss: 0.3309 - val_categorical_accuracy: 0.9576\n",
      "Epoch 9/40\n",
      "27424/27444 [============================>.] - ETA: 0s - loss: 0.0156 - categorical_accuracy: 0.9937Epoch 00009: val_loss did not improve\n",
      "1.001e-05 1e-05\n",
      "27444/27444 [==============================] - 177s 6ms/step - loss: 0.0155 - categorical_accuracy: 0.9937 - val_loss: 0.3428 - val_categorical_accuracy: 0.9575\n",
      "Epoch 10/40\n",
      "27424/27444 [============================>.] - ETA: 0s - loss: 0.0148 - categorical_accuracy: 0.9940 ETA: 1s - loss: 0.0148 - categorical_accuracy: 0.99 - ETA: 1s - loss: 0.0148 - categorical_accu - ETA: 0s - loss: 0.0148 - categorical_accuracy: 0.99Epoch 00010: val_loss did not improve\n",
      "1.001e-05 1e-05\n",
      "27444/27444 [==============================] - 176s 6ms/step - loss: 0.0148 - categorical_accuracy: 0.9940 - val_loss: 0.3604 - val_categorical_accuracy: 0.9570\n",
      "Epoch 11/40\n",
      "27424/27444 [============================>.] - ETA: 0s - loss: 0.0140 - categorical_accuracy: 0.9944Epoch 00011: val_loss did not improve\n",
      "1.001e-05 1e-05\n",
      "27444/27444 [==============================] - 176s 6ms/step - loss: 0.0140 - categorical_accuracy: 0.9944 - val_loss: 0.3597 - val_categorical_accuracy: 0.9573\n",
      "Epoch 12/40\n",
      "27424/27444 [============================>.] - ETA: 0s - loss: 0.0132 - categorical_accuracy: 0.9947Epoch 00012: val_loss did not improve\n",
      "1.001e-05 1e-05\n",
      "27444/27444 [==============================] - 177s 6ms/step - loss: 0.0132 - categorical_accuracy: 0.9947 - val_loss: 0.3777 - val_categorical_accuracy: 0.9570\n",
      "Epoch 13/40\n",
      "27424/27444 [============================>.] - ETA: 0s - loss: 0.0125 - categorical_accuracy: 0.9951Epoch 00013: val_loss did not improve\n",
      "1.001e-05 1e-05\n",
      "27444/27444 [==============================] - 177s 6ms/step - loss: 0.0125 - categorical_accuracy: 0.9951 - val_loss: 0.3785 - val_categorical_accuracy: 0.9571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7f44e7dd8>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "# Load optimized weights\n",
    "model.load_weights(model_filename.format('1'))\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-4)\n",
    "\n",
    "# Start fine-tuning\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6861/6861 [==============================] - 6s 851us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33092002472511617, 0.95755856075538459]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "3300/3300 [==============================] - 3s 947us/step\n",
      "18\n",
      "3300/3300 [==============================] - 3s 762us/step\n",
      "19\n",
      "3300/3300 [==============================] - 3s 761us/step\n",
      "20\n",
      "3300/3300 [==============================] - 3s 771us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_test = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_test = data_test[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_test[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    \n",
    "    segmentations_test = segmentations_test + [segmentation]\n",
    "    \n",
    "segmentations_test = np.stack(segmentations_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABBEMgAABJEMAADhP3KgFw3Y0TWkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa7f0130d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_test[:,:,:,22]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa7f75bcd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_test[:,:,:,22]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pick the largest connected component for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    segmentation = np.squeeze(segmentations_test[i_case,:,:,:]);\n",
    "    tmp = np.zeros(segmentation.shape, dtype=segmentation.dtype)\n",
    "    \n",
    "    for class_idx in class_mapper_inv :\n",
    "        mask = (segmentation == class_idx)\n",
    "        \n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            labeled_mask, num_cc = ndimage.label(mask)\n",
    "            largest_cc_mask = (labeled_mask == (np.bincount(labeled_mask.flat)[1:].argmax() + 1))\n",
    "            \n",
    "            tmp[largest_cc_mask == 1] = class_idx\n",
    "        \n",
    "    segmentations_test[i_case,:,:,:] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Done with Step 3\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx)\n",
    "    \n",
    "    segmentation = np.squeeze(segmentations_test[i_case,:,:,:]);\n",
    "\n",
    "    save_data(segmentation, case_idx, 'label')    \n",
    "\n",
    "print(\"Done with Step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Calculate metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(m1, m2):\n",
    "    return 2*((m1==1) & (m2==1)).sum()/((m1==1).sum() + (m2==1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\t0.9992\tN/A\t0.9367\t0.8333\t0.8735\t0.7617\t0.7063\t0.9350\t0.8353\t0.8483\t0.9528\t0.7242\t\n",
      "18\t0.9990\tN/A\t1.0000\t0.5714\t0.8727\t0.8882\t0.7586\t0.8013\t0.8987\t0.7932\t0.7789\t0.8121\t\n",
      "19\t0.9992\tN/A\t1.0000\t0.9184\t0.9704\t0.9274\t0.9532\t0.9737\t0.9050\t0.8246\t0.6792\t0.6667\t\n",
      "20\t0.9987\tN/A\t0.9500\t0.7879\t0.8551\t0.9137\t0.9404\t0.9535\t0.6996\t0.6188\t0.9132\t0.6331\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    print('{:.4f}'.format(accuracy_score(label_test[i_case,:,:,:].flat, segmentations_test[i_case,:,:,:].flat)), end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(precision_score(label_test[i_case,:,:,:][mask], segmentations_test[i_case,:,:,:][mask], average='micro')), end='\\t')\n",
    "        else:\n",
    "            print('N/A', end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\t0\t0.8555\t0.8092\t0.8815\t0.8596\t0.8137\t0.8969\t0.8576\t0.8790\t0.8058\t0.7836\t\n",
      "18\t0\t0.0635\t0.3810\t0.8101\t0.8604\t0.8261\t0.8436\t0.5612\t0.7165\t0.6637\t0.8148\t\n",
      "19\t0\t0.8000\t0.8036\t0.8794\t0.8137\t0.8836\t0.8868\t0.8334\t0.8396\t0.6143\t0.2173\t\n",
      "20\t0\t0.9344\t0.7172\t0.7973\t0.8843\t0.7972\t0.7675\t0.7030\t0.6680\t0.5770\t0.5407\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(calc_dice((label_test[i_case,:,:,:]==class_idx).flat, (segmentations_test[i_case,:,:,:]==class_idx).flat)), end='\\t')\n",
    "        else:\n",
    "            print(0, end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
