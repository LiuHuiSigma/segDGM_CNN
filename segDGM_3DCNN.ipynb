{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "from utils import *\n",
    "from model_FCNN import generate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import keras\n",
    "reload(keras)\n",
    "from keras import backend as K\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "\n",
    "import model_FCNN\n",
    "reload(model_FCNN)\n",
    "from model_FCNN import generate_model\n",
    "\n",
    "import callback_custom\n",
    "reload(callback_custom);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11\n",
    "num_channel = 1\n",
    "\n",
    "# K-fold validation (K=5)\n",
    "n_training = 16\n",
    "n_test = 4\n",
    "\n",
    "idxs_training = list(range(1, 1+16))\n",
    "idxs_test = list(range(17, 17+4))\n",
    "\n",
    "patience = 5\n",
    "model_filename = 'models/outrun_step_{}.h5'\n",
    "csv_filename = 'log/outrun_step_{}.cvs'\n",
    "\n",
    "nb_epoch = 40\n",
    "validation_split = 0.10\n",
    "monitor = 'val_loss'#'val_categorical_accuracy'\n",
    "\n",
    "class_mapper = {0:0}\n",
    "class_mapper.update({ i+1:i for i in range(1, 1+10) })\n",
    "class_mapper_inv = {0:0}\n",
    "class_mapper_inv.update({ i:i+1 for i in range(1, 1+10) })\n",
    "\n",
    "matrix_size = (160, 220, 48)\n",
    "\n",
    "#extraction_step = (3, 3, 3)\n",
    "extraction_step = (5, 5, 3)\n",
    "\n",
    "segment_size = (27, 27, 21)\n",
    "core_size = (9, 9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "MAG_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "R2S_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "label_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_training):\n",
    "    QSM_train[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_train[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_train[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_train[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = np.stack((QSM_train, MAG_train, R2S_train), axis = 1)\n",
    "#data_train = np.stack((QSM_train, R2S_train), axis = 1)\n",
    "data_train = np.stack((QSM_train,), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "MAG_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "R2S_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "label_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_test):\n",
    "    QSM_test[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_test[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_test[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_test[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test = np.stack((QSM_test, MAG_test, R2S_test), axis = 1)\n",
    "#data_test = np.stack((QSM_test, R2S_test), axis = 1)\n",
    "data_test = np.stack((QSM_test,), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intensity normalisation (zero mean and unit variance)\n",
    "input_mean = 127.0\n",
    "input_std = 128.0\n",
    "data_train = (data_train - input_mean) / input_std\n",
    "data_test = (data_test - input_mean) / input_std\n",
    "\n",
    "# Map class label\n",
    "tmp = np.copy(label_train)\n",
    "for class_idx in class_mapper:\n",
    "    label_train[tmp == class_idx] = class_mapper[class_idx]\n",
    "tmp = np.copy(label_test)\n",
    "for class_idx in class_mapper:\n",
    "    label_test[tmp == class_idx] = class_mapper[class_idx]\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEACAYAAABBOusMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc6e1a33438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0,:,:,[29,25]]), scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3964, 1, 27, 27, 21), (3964, 243, 11))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Configure callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('1'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('1'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3567 samples, validate on 397 samples\n",
      "Epoch 1/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.8903 - categorical_accuracy: 0.7765 - val_loss: 0.7590 - val_categorical_accuracy: 0.7907\n",
      "Epoch 2/40\n",
      "3567/3567 [==============================] - 21s 6ms/step - loss: 0.5678 - categorical_accuracy: 0.8335 - val_loss: 0.5833 - val_categorical_accuracy: 0.8231\n",
      "Epoch 3/40\n",
      "3567/3567 [==============================] - 21s 6ms/step - loss: 0.4023 - categorical_accuracy: 0.8693 - val_loss: 0.4705 - val_categorical_accuracy: 0.8510\n",
      "Epoch 4/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.2949 - categorical_accuracy: 0.8942 - val_loss: 0.3328 - val_categorical_accuracy: 0.8932\n",
      "Epoch 5/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.2281 - categorical_accuracy: 0.9174 - val_loss: 0.3295 - val_categorical_accuracy: 0.8934\n",
      "Epoch 6/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1588 - categorical_accuracy: 0.9365 - val_loss: 0.3053 - val_categorical_accuracy: 0.9014\n",
      "Epoch 7/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1386 - categorical_accuracy: 0.9437 - val_loss: 0.3146 - val_categorical_accuracy: 0.9060\n",
      "Epoch 8/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1161 - categorical_accuracy: 0.95190.001 1e-05\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1160 - categorical_accuracy: 0.9520 - val_loss: 0.3632 - val_categorical_accuracy: 0.8996\n",
      "Epoch 9/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1043 - categorical_accuracy: 0.95700.001 1e-05\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1046 - categorical_accuracy: 0.9569 - val_loss: 0.4532 - val_categorical_accuracy: 0.8939\n",
      "Epoch 10/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0929 - categorical_accuracy: 0.96180.001 1e-05\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.0928 - categorical_accuracy: 0.9618 - val_loss: 0.4112 - val_categorical_accuracy: 0.9038\n",
      "Epoch 11/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0789 - categorical_accuracy: 0.96710.001 1e-05\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.0789 - categorical_accuracy: 0.9671 - val_loss: 0.3472 - val_categorical_accuracy: 0.9120\n",
      "Epoch 12/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0676 - categorical_accuracy: 0.9721\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.0676 - categorical_accuracy: 0.9721 - val_loss: 0.4019 - val_categorical_accuracy: 0.9119\n",
      "Epoch 13/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1206 - categorical_accuracy: 0.9500 - val_loss: 0.3220 - val_categorical_accuracy: 0.9056\n",
      "Epoch 14/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1104 - categorical_accuracy: 0.95380.0001 1e-05\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1105 - categorical_accuracy: 0.9537 - val_loss: 0.3479 - val_categorical_accuracy: 0.9030\n",
      "Epoch 15/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1057 - categorical_accuracy: 0.95580.0001 1e-05\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1057 - categorical_accuracy: 0.9558 - val_loss: 0.3380 - val_categorical_accuracy: 0.9057\n",
      "Epoch 16/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1012 - categorical_accuracy: 0.95770.0001 1e-05\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1011 - categorical_accuracy: 0.9577 - val_loss: 0.3416 - val_categorical_accuracy: 0.9079\n",
      "Epoch 17/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.0970 - categorical_accuracy: 0.9596\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.0969 - categorical_accuracy: 0.9596 - val_loss: 0.3538 - val_categorical_accuracy: 0.9071\n",
      "Epoch 18/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1264 - categorical_accuracy: 0.9481 - val_loss: 0.3313 - val_categorical_accuracy: 0.9039\n",
      "Epoch 19/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1188 - categorical_accuracy: 0.9508 - val_loss: 0.3228 - val_categorical_accuracy: 0.9051\n",
      "Epoch 20/40\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1166 - categorical_accuracy: 0.9515 - val_loss: 0.3148 - val_categorical_accuracy: 0.9063\n",
      "Epoch 21/40\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1150 - categorical_accuracy: 0.9521 - val_loss: 0.3124 - val_categorical_accuracy: 0.9063\n",
      "Epoch 22/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1136 - categorical_accuracy: 0.9527 ETA: 7s - loss: 0.1134 - categorical_ac - ETA:  - ETA: 1s - loss: 0.1132 - categorical_ac1.001e-05 1e-05\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1137 - categorical_accuracy: 0.9527 - val_loss: 0.3128 - val_categorical_accuracy: 0.9072\n",
      "Epoch 23/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1126 - categorical_accuracy: 0.95311.001e-05 1e-05\n",
      "3567/3567 [==============================] - 22s 6ms/step - loss: 0.1126 - categorical_accuracy: 0.9531 - val_loss: 0.3131 - val_categorical_accuracy: 0.9064\n",
      "Epoch 24/40\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1115 - categorical_accuracy: 0.9535 - val_loss: 0.3109 - val_categorical_accuracy: 0.9070\n",
      "Epoch 25/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1105 - categorical_accuracy: 0.95381.001e-05 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1105 - categorical_accuracy: 0.9538 - val_loss: 0.3173 - val_categorical_accuracy: 0.9060\n",
      "Epoch 26/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1095 - categorical_accuracy: 0.9542 ETA: 2s - loss: 0.1079 - cate1.001e-05 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1096 - categorical_accuracy: 0.9541 - val_loss: 0.3156 - val_categorical_accuracy: 0.9065\n",
      "Epoch 27/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1085 - categorical_accuracy: 0.95461.001e-05 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1086 - categorical_accuracy: 0.9546 - val_loss: 0.3262 - val_categorical_accuracy: 0.9057\n",
      "Epoch 28/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1078 - categorical_accuracy: 0.9549 ETA: 2s - loss: 0.1074 - ca1.001e-05 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1077 - categorical_accuracy: 0.9550 - val_loss: 0.3356 - val_categorical_accuracy: 0.9045\n",
      "Epoch 29/40\n",
      "3552/3567 [============================>.] - ETA: 0s - loss: 0.1069 - categorical_accuracy: 0.95521.001e-05 1e-05\n",
      "3567/3567 [==============================] - 23s 6ms/step - loss: 0.1069 - categorical_accuracy: 0.9552 - val_loss: 0.3240 - val_categorical_accuracy: 0.9061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc70498ed30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 47\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396/396 [==============================] - 3s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30588613766612427, 0.90123438835144043]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_patch = extract_patches(read_data(1, 'QSM'), patch_shape=segment_size, extraction_step=(9, 9, 3)).shape[0]\n",
    "len_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3300/3300 [==============================] - 3s 778us/step\n",
      "2\n",
      "3300/3300 [==============================] - 3s 767us/step\n",
      "3\n",
      "3300/3300 [==============================] - 2s 742us/step\n",
      "4\n",
      "3300/3300 [==============================] - 2s 749us/step\n",
      "5\n",
      "3300/3300 [==============================] - 2s 748us/step\n",
      "6\n",
      "3300/3300 [==============================] - 2s 756us/step\n",
      "7\n",
      "3300/3300 [==============================] - 3s 761us/step\n",
      "8\n",
      "3300/3300 [==============================] - 2s 755us/step\n",
      "9\n",
      "3300/3300 [==============================] - 2s 756us/step\n",
      "10\n",
      "3300/3300 [==============================] - 2s 755us/step\n",
      "11\n",
      "3300/3300 [==============================] - 3s 760us/step\n",
      "12\n",
      "3300/3300 [==============================] - 3s 759us/step\n",
      "13\n",
      "3300/3300 [==============================] - 3s 761us/step\n",
      "14\n",
      "3300/3300 [==============================] - 3s 763us/step\n",
      "15\n",
      "3300/3300 [==============================] - 2s 755us/step\n",
      "16\n",
      "3300/3300 [==============================] - 3s 767us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_train = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_training):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_train = data_train[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_train[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    \n",
    "    segmentations_train = segmentations_train + [segmentation]\n",
    "    \n",
    "segmentations_train = np.stack(segmentations_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB50gGBd8oorSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5985af9e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5985ae1c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Check false-positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_fpos = (label_train == 0) & (segmentations_train != 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_fpos = np.zeros(label_train.shape, dtype=precision_global)\n",
    "mask_fpos[idx_fpos == True] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHbgExiYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f596f6620b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(200*(np.squeeze(mask_fpos[0:15,:,:,25])), rows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Rebuild training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((19255, 1, 27, 27, 21), (19255, 243, 11))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size, mask_fpos)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array('tmp/x_train.bc', x_train)\n",
    "save_array('tmp/y_train.bc', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_array('tmp/x_train.bc')\n",
    "y_train = load_array('tmp/y_train.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Regenerate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('2'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('2'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17329 samples, validate on 1926 samples\n",
      "Epoch 1/40\n",
      "17329/17329 [==============================] - 103s 6ms/step - loss: 0.0346 - categorical_accuracy: 0.9864 - val_loss: 0.1712 - val_categorical_accuracy: 0.9658\n",
      "Epoch 2/40\n",
      "17329/17329 [==============================] - 104s 6ms/step - loss: 0.0252 - categorical_accuracy: 0.9897 - val_loss: 0.1957 - val_categorical_accuracy: 0.9663\n",
      "Epoch 3/40\n",
      "17312/17329 [============================>.] - ETA: 0s - loss: 0.0219 - categorical_accuracy: 0.99100.0001 1e-05\n",
      "17329/17329 [==============================] - 104s 6ms/step - loss: 0.0219 - categorical_accuracy: 0.9910 - val_loss: 0.2052 - val_categorical_accuracy: 0.9662\n",
      "Epoch 4/40\n",
      "17312/17329 [============================>.] - ETA: 0s - loss: 0.0193 - categorical_accuracy: 0.99200.0001 1e-05\n",
      "17329/17329 [==============================] - 105s 6ms/step - loss: 0.0193 - categorical_accuracy: 0.9920 - val_loss: 0.2458 - val_categorical_accuracy: 0.9658\n",
      "Epoch 5/40\n",
      "17312/17329 [============================>.] - ETA: 0s - loss: 0.0174 - categorical_accuracy: 0.99280.0001 1e-05\n",
      "17329/17329 [==============================] - 105s 6ms/step - loss: 0.0174 - categorical_accuracy: 0.9928 - val_loss: 0.2989 - val_categorical_accuracy: 0.9634\n",
      "Epoch 6/40\n",
      "17312/17329 [============================>.] - ETA: 0s - loss: 0.0154 - categorical_accuracy: 0.99360.0001 1e-05\n",
      "17329/17329 [==============================] - 106s 6ms/step - loss: 0.0154 - categorical_accuracy: 0.9936 - val_loss: 0.2189 - val_categorical_accuracy: 0.9667\n",
      "Epoch 7/40\n",
      "17312/17329 [============================>.] - ETA: 0s - loss: 0.0135 - categorical_accuracy: 0.9944\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "17329/17329 [==============================] - 107s 6ms/step - loss: 0.0136 - categorical_accuracy: 0.9944 - val_loss: 0.2973 - val_categorical_accuracy: 0.9654\n",
      "Epoch 8/40\n",
      "17329/17329 [==============================] - 108s 6ms/step - loss: 0.0248 - categorical_accuracy: 0.9899 - val_loss: 0.1546 - val_categorical_accuracy: 0.9673\n",
      "Epoch 9/40\n",
      "17312/17329 [============================>.] - ETA: 0s - loss: 0.0238 - categorical_accuracy: 0.99031.001e-05 1e-05\n",
      "17329/17329 [==============================] - 108s 6ms/step - loss: 0.0238 - categorical_accuracy: 0.9903 - val_loss: 0.1695 - val_categorical_accuracy: 0.9667\n",
      "Epoch 10/40\n",
      "17312/17329 [============================>.] - ETA: 0s - loss: 0.0232 - categorical_accuracy: 0.99051.001e-05 1e-05\n",
      "17329/17329 [==============================] - 108s 6ms/step - loss: 0.0232 - categorical_accuracy: 0.9905 - val_loss: 0.1797 - val_categorical_accuracy: 0.9662\n",
      "Epoch 11/40\n",
      "17312/17329 [============================>.] - ETA: 0s - loss: 0.0225 - categorical_accuracy: 0.99081.001e-05 1e-05\n",
      "17329/17329 [==============================] - 108s 6ms/step - loss: 0.0225 - categorical_accuracy: 0.9908 - val_loss: 0.1970 - val_categorical_accuracy: 0.9657\n",
      "Epoch 12/40\n",
      "17312/17329 [============================>.] - ETA: 0s - loss: 0.0220 - categorical_accuracy: 0.9910   ETA - ETA - ETA: 59s - loss: 0.0220 - categorical_accuracy: 0.91.001e-05 1e-05\n",
      "17329/17329 [==============================] - 109s 6ms/step - loss: 0.0220 - categorical_accuracy: 0.9910 - val_loss: 0.1971 - val_categorical_accuracy: 0.9657\n",
      "Epoch 13/40\n",
      "17312/17329 [============================>.] - ETA: 0s - loss: 0.0214 - categorical_accuracy: 0.99131.001e-05 1e-05\n",
      "17329/17329 [==============================] - 109s 6ms/step - loss: 0.0214 - categorical_accuracy: 0.9913 - val_loss: 0.1875 - val_categorical_accuracy: 0.9669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f597d25e860>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "# Load optimized weights\n",
    "model.load_weights(model_filename.format('1'))\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-4)\n",
    "\n",
    "# Start fine-tuning\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1925/1925 [==============================] - 2s 839us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15466259370051483, 0.96726183293701762]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "3300/3300 [==============================] - 2s 753us/step\n",
      "18\n",
      "3300/3300 [==============================] - 2s 734us/step\n",
      "19\n",
      "3300/3300 [==============================] - 2s 736us/step\n",
      "20\n",
      "3300/3300 [==============================] - 2s 741us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_test = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_test = data_test[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_test[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    #segmentation = reconstruct_volume_majority(pred_classes, matrix_size, extraction_step=(3, 3, 3))\n",
    "    \n",
    "    segmentations_test = segmentations_test + [segmentation]\n",
    "    \n",
    "segmentations_test = np.stack(segmentations_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5992118eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEQyAAAEkQwAAEEkAwBAEMkAABD+A8/pKBJ3dPDmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f599213ef28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pick the largest connected component for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    segmentation = np.squeeze(segmentations_test[i_case,:,:,:]);\n",
    "    tmp = np.zeros(segmentation.shape, dtype=segmentation.dtype)\n",
    "    \n",
    "    for class_idx in class_mapper_inv :\n",
    "        mask = (segmentation == class_idx)\n",
    "        \n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            labeled_mask, num_cc = ndimage.label(mask)\n",
    "            largest_cc_mask = (labeled_mask == (np.bincount(labeled_mask.flat)[1:].argmax() + 1))\n",
    "            \n",
    "            tmp[largest_cc_mask == 1] = class_idx\n",
    "        \n",
    "    segmentations_test[i_case,:,:,:] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Done with Step 3\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx)\n",
    "    \n",
    "    segmentation = np.copy(np.squeeze(segmentations_test[i_case,:,:,:]))\n",
    "    \n",
    "    tmp = np.copy(segmentation)\n",
    "    for class_idx in class_mapper_inv:\n",
    "        segmentation[tmp == class_idx] = class_mapper_inv[class_idx]\n",
    "    del tmp\n",
    "\n",
    "    save_data(segmentation, case_idx, 'label')    \n",
    "\n",
    "print(\"Done with Step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Calculate metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(m1, m2):\n",
    "    return 2*((m1==1) & (m2==1)).sum()/((m1==1).sum() + (m2==1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\t0.9992\tN/A\t0.9231\t0.8514\t0.7846\t0.6980\t0.7263\t0.9431\t0.8711\t0.8754\t0.9589\t0.7337\t\n",
      "18\t0.9989\tN/A\t0.0000\t0.8333\t0.8986\t0.8644\t0.7743\t0.7606\t0.8802\t0.7556\t0.8200\t0.8149\t\n",
      "19\t0.9991\tN/A\t0.9200\t0.9375\t0.9503\t0.8862\t0.9586\t0.9850\t0.8686\t0.8241\t0.6980\t0.7333\t\n",
      "20\t0.9988\tN/A\t0.8169\t0.8485\t0.7870\t0.9156\t0.9389\t0.9510\t0.6667\t0.6760\t0.7367\t0.7293\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    print('{:.4f}'.format(accuracy_score(label_test[i_case,:,:,:].flat, segmentations_test[i_case,:,:,:].flat)), end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(precision_score(label_test[i_case,:,:,:][mask], segmentations_test[i_case,:,:,:][mask], average='micro')), end='\\t')\n",
    "        else:\n",
    "            print('N/A', end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\t0\t0.9081\t0.7730\t0.8547\t0.8034\t0.8218\t0.9031\t0.8789\t0.8897\t0.8544\t0.8026\t\n",
      "18\t0\t0.0000\t0.1613\t0.6327\t0.8547\t0.8344\t0.8155\t0.7132\t0.6012\t0.3388\t0.7884\t\n",
      "19\t0\t0.6053\t0.6316\t0.8384\t0.7475\t0.8774\t0.8698\t0.8330\t0.8349\t0.6721\t0.1719\t\n",
      "20\t0\t0.8722\t0.7724\t0.7752\t0.8527\t0.7696\t0.7791\t0.6337\t0.6725\t0.6824\t0.7413\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(calc_dice((label_test[i_case,:,:,:]==class_idx).flat, (segmentations_test[i_case,:,:,:]==class_idx).flat)), end='\\t')\n",
    "        else:\n",
    "            print(0, end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
