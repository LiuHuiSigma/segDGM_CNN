{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "from utils import *\n",
    "from model_FCNN import generate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import keras\n",
    "reload(keras)\n",
    "from keras import backend as K\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "\n",
    "import model_FCNN\n",
    "reload(model_FCNN)\n",
    "from model_FCNN import generate_model\n",
    "\n",
    "import callback_custom\n",
    "reload(callback_custom);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11\n",
    "num_channel = 2\n",
    "\n",
    "# K-fold validation (K=5)\n",
    "n_training = 16\n",
    "n_test = 4\n",
    "\n",
    "#idxs_training = list(range(1, 1+16))\n",
    "#idxs_test = list(range(17, 17+4))\n",
    "idxs_training = list(range(1, 1+4)) + list(range(9, 9+12))\n",
    "idxs_test = list(range(5,5+4))\n",
    "\n",
    "patience = 5\n",
    "model_filename = 'models/outrun_step_{}.h5'\n",
    "csv_filename = 'log/outrun_step_{}.cvs'\n",
    "\n",
    "nb_epoch = 40\n",
    "validation_split = 0.10\n",
    "monitor = 'val_loss'#'val_categorical_accuracy'\n",
    "\n",
    "class_mapper = {0:0}\n",
    "class_mapper.update({ i+1:i for i in range(1, 1+10) })\n",
    "class_mapper_inv = {0:0}\n",
    "class_mapper_inv.update({ i:i+1 for i in range(1, 1+10) })\n",
    "\n",
    "matrix_size = (160, 220, 48)\n",
    "\n",
    "extraction_step = (3, 3, 1)\n",
    "#extraction_step = (5, 5, 3)\n",
    "\n",
    "segment_size = (27, 27, 21)\n",
    "core_size = (9, 9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "MAG_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "R2S_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "label_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_training):\n",
    "    QSM_train[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_train[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_train[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_train[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = np.stack((QSM_train, MAG_train, R2S_train), axis = 1)\n",
    "data_train = np.stack((QSM_train, R2S_train), axis = 1)\n",
    "#data_train = np.stack((QSM_train,), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "MAG_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "R2S_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "label_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_test):\n",
    "    QSM_test[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_test[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_test[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_test[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test = np.stack((QSM_test, MAG_test, R2S_test), axis = 1)\n",
    "data_test = np.stack((QSM_test, R2S_test), axis = 1)\n",
    "#data_test = np.stack((QSM_test,), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intensity normalisation (zero mean and unit variance)\n",
    "input_mean = 127.0\n",
    "input_std = 128.0\n",
    "data_train = (data_train - input_mean) / input_std\n",
    "data_test = (data_test - input_mean) / input_std\n",
    "\n",
    "# Map class label\n",
    "tmp = np.copy(label_train)\n",
    "for class_idx in class_mapper:\n",
    "    label_train[tmp == class_idx] = class_mapper[class_idx]\n",
    "tmp = np.copy(label_test)\n",
    "for class_idx in class_mapper:\n",
    "    label_test[tmp == class_idx] = class_mapper[class_idx]\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEACAYAAABBOusMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACB5JREFUeJzt3e1t1FgYhuHjFU2glJGUgSiDKQNRRlIGogymjIgyvD9W\nDsOzxOPx5xz7uqSVsgws589at169c9y0bVsAAIDf/tn6AAAAcG9EMgAABJEMAABBJAMAQBDJAAAQ\nRDIAAASRDAAAQSQDAEAQyQAAED5sfYBSSmmaxmv/gGq1bdtsfYY1eWYDNRv6zDZJBgCAIJIBACCI\nZAAACCIZAACCSAYAgCCSAQAgiGQAAAgiGQAAgkgGAIAgkgEAIIhkAAAIIhkAAIJIBgCAIJIBACCI\nZAAACCIZAACCSAYAgCCSAQAgiGQAAAgiGQAAgkgGAIAgkgEAIIhkAAAIIhkAAIJIBgCAIJIBACCI\nZAAACCIZAACCSAYAgCCSAQAgiGQAAAgiGQAAgkgGAIAgkgEAIIhkAAAIIhkAAIJIBgCAIJIBACCI\nZAAACCIZAACCSAYAgCCSAQAgiGQAAAgiGQAAgkgGAIAgkgEAIIhkAAAIIhkAAIJIBgCAIJIBACCI\nZAAACCIZAACCSAYAgCCSAQAgiGQAAAgiGQAAgkgGAIAgkgEAIIhkAAAIIhkAAIJIBgCAIJIBACCI\nZAAACCIZAACCSAYAgCCSAQAgiGQAAAgiGQAAgkgGAIAgkgEAIHzY+gAAwHH9/Pnz6u95enpa4STw\nJ5EMANy1ayEtolmCdQsAAAgmyQDA6p6fn8vpdCrn87mUUsrpdBq0evE37/05E2amaNq23foMpWma\n7Q8BMFLbts3WZ1iTZzZzeH5+7v38dDq9/Tw2nq8R0cc09JktkgEmEskwzrVQ7kyZMl8jlI9n6DPb\nTjIAAASTZICJTJJhvHuYJndMlY/BugXASkQyTDc0ljuPj48LneQ30bxP1i0AgGpcflFviKenp7d/\nYAkiGQAAgnULgImsW8B8bl27KGX5fWXT6n2xkwywEpEMyxgTzKXMt68sjvfJTjIAAIxkkgwwkUky\nLGuribJJ8j4NfWZ/WPogAABb6CL3ln1lYUzHJBlgIpNkWN7YafKl7pq5LpqHBvF7rdQ0h/pffzfs\nJAMAwEgiGQC4e7e+bKTP0JeQtG377hSZ/RPJAEAVTqfTrLHcRxwjkgEAIIhkAKAqS02Tu/UKU2RK\ncQUcAFChy1Ce4+YLSK6Aozpfvnx5+/nl5WXDk8B/XAEH2+sL5SGT5zE95Aq4OrkCDgAARjJJpjqX\nk+QhTJtZmkky1GtKB5kk12noM1skUzXBzD0QyVCvsR0kkOtl3QIAAEYySaZ6t06TO6bKzMUkGepk\ninxMQ5/ZroCjSo+Pj6WUUs7n88YnAeAoxPGxiGSq0wVy93MXype/DgB/Y3rMUHaSAQAgiGSq0jct\ntmMMwDVjJsKmyMfki3tU5dpKxfl87v0in5BmCb64B1AP9ySzS32R7Et8bEUkA9TDPckAADCSSKYq\npsUAwBqsWwBMZN0CoB7WLQAAYCSRDAAAQSQDAEDwWmqq9PHjx7eff/36teFJAIA9MkkGAIDgdguq\ncjlBTibKbMXtFgD1GPrMtm5BFfriGABgbtYtAAAgmCSzK58+fer9/MePHyudBAComUjmUC4jWjAD\nHNvr62vv5w8PDyudhHskkqlC96U8u8kATHUtjqEUO8kAAPA/JslUJSfKl9e+XdtHBoBb5MTZ+sWx\niGSq1MWxMAbgVl3sWrugj0imSlPj2Jf2AIA+dpIBACCYJFOFWybHpsQAx/X169d3P/v27duk//bl\neob95P0TyeyKQAY4pr44hjGsWwAAQDBJpgomxADM7eHhYfQNF6+vr1Yudk4kAwDVmWu94jJ0XQnH\nJZEMAFAEM3+ykwwAAEEkAwBVWeMmC/vGNG3bbn2G0jTN9ocAGKlt22brM6zJM5stTAnj9+5H/v79\n+x///vnz59F/B/UY+sw2SQYAgOCLewDAbuUUOafH731mqoxJMgCwS7cEcrrl97JPdpIBJrKTDPOb\nYwd5rtA1Vd4XO8kAADCSnWQAoHqXqxUmyMxBJAMAd2HsisUSgQzWLQAAIJgkAwCbubfpsRULOiIZ\nANjErYG89FqFQOaSdQsAYHUCmXsnkgEAIFi3AABWM3SCPOVteX1MjBlKJAMAm1sqiksRxozjtdQA\nE3ktNdyumyh7CQhr81pqAAAYySQZYCKTZBhv6PTYdJi5DH1mi2SAiUQyQD2sWwAAwEgiGQAAgkgG\nAIAgkgEAIIhkAAAIIhkAAIJIBgCAIJIBACCIZAAACCIZAACCSAYAgCCSAQAgiGQAAAgiGQAAgkgG\nAIAgkgEAIIhkAAAIIhkAAIJIBgCAIJIBACCIZAAACCIZAACCSAYAgCCSAQAgiGQAAAgiGQAAgkgG\nAIAgkgEAIIhkAAAIIhkAAIJIBgCAIJIBACCIZAAACCIZAACCSAYAgCCSAQAgiGQAAAgiGQAAgkgG\nAIAgkgEAIIhkAAAIIhkAAIJIBgCAIJIBACCIZAAACCIZAACCSAYAgCCSAQAgiGQAAAgiGQAAgkgG\nAIAgkgEAIIhkAAAIIhkAAIJIBgCAIJIBACCIZAAACCIZAACCSAYAgCCSAQAgiGQAAAgiGQAAgkgG\nAIAgkgEAIIhkAAAIIhkAAIJIBgCAIJIBACCIZAAACCIZAABC07bt1mcAAIC7YpIMAABBJAMAQBDJ\nAAAQRDIAAASRDAAAQSQDAEAQyQAAEEQyAAAEkQwAAEEkAwBAEMkAABBEMgAABJEMAABBJAMAQBDJ\nAAAQRDIAAASRDAAAQSQDAEAQyQAAEEQyAAAEkQwAAEEkAwBAEMkAABD+BVQuFTOpKN5WAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab01f2ee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0,:,:,[29,25]]), scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((33401, 2, 27, 27, 21), (33401, 243, 11))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Configure callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('1'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('1'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30060 samples, validate on 3341 samples\n",
      "Epoch 1/40\n",
      "30060/30060 [==============================] - 186s 6ms/step - loss: 0.3684 - categorical_accuracy: 0.8824 - val_loss: 0.2664 - val_categorical_accuracy: 0.9226\n",
      "Epoch 2/40\n",
      "30060/30060 [==============================] - 185s 6ms/step - loss: 0.0845 - categorical_accuracy: 0.9653 - val_loss: 0.3606 - val_categorical_accuracy: 0.9209\n",
      "Epoch 3/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0455 - categorical_accuracy: 0.98170.001 1e-05\n",
      "30060/30060 [==============================] - 186s 6ms/step - loss: 0.0455 - categorical_accuracy: 0.9817 - val_loss: 0.4383 - val_categorical_accuracy: 0.9236\n",
      "Epoch 4/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0382 - categorical_accuracy: 0.98580.001 1e-05\n",
      "30060/30060 [==============================] - 186s 6ms/step - loss: 0.0382 - categorical_accuracy: 0.9858 - val_loss: 0.4179 - val_categorical_accuracy: 0.9252\n",
      "Epoch 5/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0140 - categorical_accuracy: 0.99480.001 1e-05\n",
      "30060/30060 [==============================] - 187s 6ms/step - loss: 0.0140 - categorical_accuracy: 0.9948 - val_loss: 0.5816 - val_categorical_accuracy: 0.9267\n",
      "Epoch 6/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0113 - categorical_accuracy: 0.99610.001 1e-05\n",
      "30060/30060 [==============================] - 188s 6ms/step - loss: 0.0113 - categorical_accuracy: 0.9961 - val_loss: 0.4695 - val_categorical_accuracy: 0.9213\n",
      "Epoch 7/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0091 - categorical_accuracy: 0.9969\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "30060/30060 [==============================] - 189s 6ms/step - loss: 0.0091 - categorical_accuracy: 0.9969 - val_loss: 0.6002 - val_categorical_accuracy: 0.9277\n",
      "Epoch 8/40\n",
      "30060/30060 [==============================] - 190s 6ms/step - loss: 0.0780 - categorical_accuracy: 0.9675 - val_loss: 0.3792 - val_categorical_accuracy: 0.9212TA: 3s - loss: 0.0\n",
      "Epoch 9/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0495 - categorical_accuracy: 0.97970.0001 1e-05\n",
      "30060/30060 [==============================] - 190s 6ms/step - loss: 0.0495 - categorical_accuracy: 0.9797 - val_loss: 0.5394 - val_categorical_accuracy: 0.9141\n",
      "Epoch 10/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0302 - categorical_accuracy: 0.9881   ETA: 1:02 - loss: 0. - ETA: 59s - loss: 0.0324 - - ETA: 53s - loss: 0.0320.0001 1e-05\n",
      "30060/30060 [==============================] - 190s 6ms/step - loss: 0.0302 - categorical_accuracy: 0.9881 - val_loss: 0.6072 - val_categorical_accuracy: 0.9181\n",
      "Epoch 11/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0176 - categorical_accuracy: 0.99340.0001 1e-05\n",
      "30060/30060 [==============================] - 190s 6ms/step - loss: 0.0176 - categorical_accuracy: 0.9934 - val_loss: 0.7235 - val_categorical_accuracy: 0.9164\n",
      "Epoch 12/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0109 - categorical_accuracy: 0.9961 ETA: 4s -\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "30060/30060 [==============================] - 190s 6ms/step - loss: 0.0109 - categorical_accuracy: 0.9961 - val_loss: 0.8256 - val_categorical_accuracy: 0.9150\n",
      "Epoch 13/40\n",
      "30060/30060 [==============================] - 190s 6ms/step - loss: 0.0954 - categorical_accuracy: 0.9604 - val_loss: 0.2677 - val_categorical_accuracy: 0.9262\n",
      "Epoch 14/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0879 - categorical_accuracy: 0.9633 - ETA: 29s - loss: 0.0882 - c1.001e-05 1e-05\n",
      "30060/30060 [==============================] - 190s 6ms/step - loss: 0.0879 - categorical_accuracy: 0.9633 - val_loss: 0.2842 - val_categorical_accuracy: 0.9238\n",
      "Epoch 15/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0831 - categorical_accuracy: 0.96531.001e-05 1e-05\n",
      "30060/30060 [==============================] - 190s 6ms/step - loss: 0.0831 - categorical_accuracy: 0.9653 - val_loss: 0.3096 - val_categorical_accuracy: 0.9226\n",
      "Epoch 16/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0787 - categorical_accuracy: 0.9671 - ETA: 37s - loss: 0 - ETA: 30s - loss: 0.0791 -1.001e-05 1e-05\n",
      "30060/30060 [==============================] - 190s 6ms/step - loss: 0.0787 - categorical_accuracy: 0.9671 - val_loss: 0.3227 - val_categorical_accuracy: 0.9228\n",
      "Epoch 17/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0745 - categorical_accuracy: 0.9689 - ETA: 33s1.001e-05 1e-05\n",
      "30060/30060 [==============================] - 190s 6ms/step - loss: 0.0745 - categorical_accuracy: 0.9689 - val_loss: 0.3420 - val_categorical_accuracy: 0.9227\n",
      "Epoch 18/40\n",
      "30048/30060 [============================>.] - ETA: 0s - loss: 0.0703 - categorical_accuracy: 0.9708  - ETA: 3 - ETA: 28s - loss: 0.0709  - ETA: 11s - loss: 0.0706 - categorical_accur - E - ETA: 4s -1.001e-05 1e-05\n",
      "30060/30060 [==============================] - 190s 6ms/step - loss: 0.0703 - categorical_accuracy: 0.9708 - val_loss: 0.3620 - val_categorical_accuracy: 0.9216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faadb6d8b00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 47\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3340/3340 [==============================] - 3s 797us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26649031562362602, 0.92253991401124147]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_patch = extract_patches(read_data(1, 'QSM'), patch_shape=segment_size, extraction_step=(9, 9, 3)).shape[0]\n",
    "len_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3300/3300 [==============================] - ETA:  - 3s 815us/step\n",
      "2\n",
      "3300/3300 [==============================] - 3s 766us/step\n",
      "3\n",
      "3300/3300 [==============================] - 3s 772us/step\n",
      "4\n",
      "3300/3300 [==============================] - 3s 768us/step\n",
      "9\n",
      "3300/3300 [==============================] - 3s 771us/step\n",
      "10\n",
      "3300/3300 [==============================] - 3s 774us/step\n",
      "11\n",
      "3300/3300 [==============================] - 3s 776us/step\n",
      "12\n",
      "3300/3300 [==============================] - 3s 780us/step\n",
      "13\n",
      "3300/3300 [==============================] - 3s 774us/step\n",
      "14\n",
      "3300/3300 [==============================] - 3s 789us/step\n",
      "15\n",
      "3300/3300 [==============================] - 3s 782us/step\n",
      "16\n",
      "3300/3300 [==============================] - 3s 789us/step\n",
      "17\n",
      "3300/3300 [==============================] - 3s 786us/step\n",
      "18\n",
      "3300/3300 [==============================] - 3s 785us/step\n",
      "19\n",
      "3300/3300 [==============================] - 3s 787us/step\n",
      "20\n",
      "3300/3300 [==============================] - 3s 794us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_train = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_training):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_train = data_train[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_train[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    \n",
    "    segmentations_train = segmentations_train + [segmentation]\n",
    "    \n",
    "segmentations_train = np.stack(segmentations_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAhEMgAABCIZAACC/wF3KsfdbY8i4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faab1553860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faab1527da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Check false-positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_fpos = (label_train == 0) & (segmentations_train != 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_fpos = np.zeros(label_train.shape, dtype=precision_global)\n",
    "mask_fpos[idx_fpos == True] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faad2eecba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(200*(np.squeeze(mask_fpos[0:15,:,:,25])), rows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Rebuild training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8112, 2, 27, 27, 21), (8112, 243, 11))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_step_ft = (6,6,3)\n",
    "x_train, y_train = build_set(data_train, label_train, extraction_step_ft, segment_size, core_size, mask_fpos)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array('tmp/x_train.bc', x_train)\n",
    "save_array('tmp/y_train.bc', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_array('tmp/x_train.bc')\n",
    "y_train = load_array('tmp/y_train.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Regenerate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('2'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('2'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7300 samples, validate on 812 samples\n",
      "Epoch 1/40\n",
      "7300/7300 [==============================] - 44s 6ms/step - loss: 0.0528 - categorical_accuracy: 0.9798 - val_loss: 0.0044 - val_categorical_accuracy: 0.9985\n",
      "Epoch 2/40\n",
      "7300/7300 [==============================] - 44s 6ms/step - loss: 0.0410 - categorical_accuracy: 0.9835 - val_loss: 0.0070 - val_categorical_accuracy: 0.9973\n",
      "Epoch 3/40\n",
      "7300/7300 [==============================] - 44s 6ms/step - loss: 0.0368 - categorical_accuracy: 0.9851 - val_loss: 0.0056 - val_categorical_accuracy: 0.9976\n",
      "Epoch 4/40\n",
      "7296/7300 [============================>.] - ETA: 0s - loss: 0.0336 - categorical_accuracy: 0.98640.0001 1e-05\n",
      "7300/7300 [==============================] - 44s 6ms/step - loss: 0.0336 - categorical_accuracy: 0.9864 - val_loss: 0.0059 - val_categorical_accuracy: 0.9976\n",
      "Epoch 5/40\n",
      "7300/7300 [==============================] - 44s 6ms/step - loss: 0.0312 - categorical_accuracy: 0.9873 - val_loss: 0.0049 - val_categorical_accuracy: 0.9980\n",
      "Epoch 6/40\n",
      "7296/7300 [============================>.] - ETA: 0s - loss: 0.0291 - categorical_accuracy: 0.98810.0001 1e-05\n",
      "7300/7300 [==============================] - 45s 6ms/step - loss: 0.0291 - categorical_accuracy: 0.9881 - val_loss: 0.0081 - val_categorical_accuracy: 0.9969\n",
      "Epoch 7/40\n",
      "7300/7300 [==============================] - 45s 6ms/step - loss: 0.0266 - categorical_accuracy: 0.9892 - val_loss: 0.0032 - val_categorical_accuracy: 0.9987\n",
      "Epoch 8/40\n",
      "7296/7300 [============================>.] - ETA: 0s - loss: 0.0245 - categorical_accuracy: 0.9900 ETA: 5s - l - ETA: 1s - loss: 0.0245 - categorica0.0001 1e-05\n",
      "7300/7300 [==============================] - 46s 6ms/step - loss: 0.0245 - categorical_accuracy: 0.9900 - val_loss: 0.0086 - val_categorical_accuracy: 0.9968\n",
      "Epoch 9/40\n",
      "7296/7300 [============================>.] - ETA: 0s - loss: 0.0223 - categorical_accuracy: 0.99100.0001 1e-05\n",
      "7300/7300 [==============================] - 46s 6ms/step - loss: 0.0223 - categorical_accuracy: 0.9910 - val_loss: 0.0037 - val_categorical_accuracy: 0.9985\n",
      "Epoch 10/40\n",
      "7296/7300 [============================>.] - ETA: 0s - loss: 0.0205 - categorical_accuracy: 0.99180.0001 1e-05\n",
      "7300/7300 [==============================] - 46s 6ms/step - loss: 0.0205 - categorical_accuracy: 0.9918 - val_loss: 0.0066 - val_categorical_accuracy: 0.9977\n",
      "Epoch 11/40\n",
      "7296/7300 [============================>.] - ETA: 0s - loss: 0.0191 - categorical_accuracy: 0.99240.0001 1e-05\n",
      "7300/7300 [==============================] - 45s 6ms/step - loss: 0.0191 - categorical_accuracy: 0.9924 - val_loss: 0.0043 - val_categorical_accuracy: 0.9985\n",
      "Epoch 12/40\n",
      "7296/7300 [============================>.] - ETA: 0s - loss: 0.0173 - categorical_accuracy: 0.99310.0001 1e-05\n",
      "7300/7300 [==============================] - 45s 6ms/step - loss: 0.0173 - categorical_accuracy: 0.9931 - val_loss: 0.0048 - val_categorical_accuracy: 0.9984\n",
      "Epoch 13/40\n",
      "7296/7300 [============================>.] - ETA: 0s - loss: 0.0162 - categorical_accuracy: 0.9935\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "7300/7300 [==============================] - 45s 6ms/step - loss: 0.0162 - categorical_accuracy: 0.9935 - val_loss: 0.0036 - val_categorical_accuracy: 0.9987\n",
      "Epoch 14/40\n",
      "7296/7300 [============================>.] - ETA: 0s - loss: 0.0230 - categorical_accuracy: 0.99081.001e-05 1e-05\n",
      "7300/7300 [==============================] - 45s 6ms/step - loss: 0.0230 - categorical_accuracy: 0.9907 - val_loss: 0.0046 - val_categorical_accuracy: 0.9983\n",
      "Epoch 15/40\n",
      "7296/7300 [============================>.] - ETA: 0s - loss: 0.0222 - categorical_accuracy: 0.99111.001e-05 1e-05\n",
      "7300/7300 [==============================] - 45s 6ms/step - loss: 0.0222 - categorical_accuracy: 0.9911 - val_loss: 0.0046 - val_categorical_accuracy: 0.9983\n",
      "Epoch 16/40\n",
      "7296/7300 [============================>.] - ETA: 0s - loss: 0.0218 - categorical_accuracy: 0.99121.001e-05 1e-05\n",
      "7300/7300 [==============================] - 45s 6ms/step - loss: 0.0218 - categorical_accuracy: 0.9913 - val_loss: 0.0051 - val_categorical_accuracy: 0.9982\n",
      "Epoch 17/40\n",
      "7296/7300 [============================>.] - ETA: 0s - loss: 0.0215 - categorical_accuracy: 0.99141.001e-05 1e-05\n",
      "7300/7300 [==============================] - 45s 6ms/step - loss: 0.0215 - categorical_accuracy: 0.9914 - val_loss: 0.0054 - val_categorical_accuracy: 0.9981\n",
      "Epoch 18/40\n",
      "7296/7300 [============================>.] - ETA: 0s - loss: 0.0211 - categorical_accuracy: 0.99151.001e-05 1e-05\n",
      "7300/7300 [==============================] - 45s 6ms/step - loss: 0.0212 - categorical_accuracy: 0.9915 - val_loss: 0.0064 - val_categorical_accuracy: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faad2e046a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "# Load optimized weights\n",
    "model.load_weights(model_filename.format('1'))\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-4)\n",
    "\n",
    "# Start fine-tuning\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811/811 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0032079768180215567, 0.99866021179241549]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3300/3300 [==============================] - 3s 798us/step\n",
      "6\n",
      "3300/3300 [==============================] - 3s 766us/step\n",
      "7\n",
      "3300/3300 [==============================] - 3s 770us/step\n",
      "8\n",
      "3300/3300 [==============================] - 3s 771us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_test = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_test = data_test[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_test[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    #segmentation = reconstruct_volume_majority(pred_classes, matrix_size, extraction_step=(3, 3, 3))\n",
    "    \n",
    "    segmentations_test = segmentations_test + [segmentation]\n",
    "    \n",
    "segmentations_test = np.stack(segmentations_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCEQyAAAEIhkAAAKRDAAAgUgGAIDgL/X/8nQG4GQiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa5d843e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIIhkAAAIIhkAAIJIBgCA8But16i+xQtVMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa5d9b7400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pick the largest connected component for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    segmentation = np.squeeze(segmentations_test[i_case,:,:,:]);\n",
    "    tmp = np.zeros(segmentation.shape, dtype=segmentation.dtype)\n",
    "    \n",
    "    for class_idx in class_mapper_inv :\n",
    "        mask = (segmentation == class_idx)\n",
    "        \n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            labeled_mask, num_cc = ndimage.label(mask)\n",
    "            largest_cc_mask = (labeled_mask == (np.bincount(labeled_mask.flat)[1:].argmax() + 1))\n",
    "            \n",
    "            tmp[largest_cc_mask == 1] = class_idx\n",
    "        \n",
    "    segmentations_test[i_case,:,:,:] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Done with Step 3\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx)\n",
    "    \n",
    "    segmentation = np.copy(np.squeeze(segmentations_test[i_case,:,:,:]))\n",
    "    \n",
    "    tmp = np.copy(segmentation)\n",
    "    for class_idx in class_mapper_inv:\n",
    "        segmentation[tmp == class_idx] = class_mapper_inv[class_idx]\n",
    "    del tmp\n",
    "\n",
    "    save_data(segmentation, case_idx, 'label')    \n",
    "\n",
    "print(\"Done with Step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Calculate metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(m1, m2):\n",
    "    return 2*((m1==1) & (m2==1)).sum()/((m1==1).sum() + (m2==1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\t0.9993\tN/A\t0.8485\t0.9625\t0.9328\t0.7902\t0.9525\t0.9277\t0.8466\t0.8701\t0.6604\t0.7470\t\n",
      "6\t0.9989\tN/A\t0.8611\t0.8400\t0.9191\t0.8939\t0.9566\t0.9776\t0.9375\t0.8797\t0.9565\t1.0000\t\n",
      "7\t0.9993\tN/A\t0.9043\t0.8953\t0.9586\t0.9462\t0.9229\t0.9340\t0.8753\t0.8675\t0.8085\t0.8630\t\n",
      "8\t0.9992\tN/A\t0.9211\t0.9077\t0.9438\t0.9184\t0.8622\t0.8275\t0.9391\t0.9136\t0.9404\t0.8632\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    print('{:.4f}'.format(accuracy_score(label_test[i_case,:,:,:].flat, segmentations_test[i_case,:,:,:].flat)), end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(precision_score(label_test[i_case,:,:,:][mask], segmentations_test[i_case,:,:,:][mask], average='micro')), end='\\t')\n",
    "        else:\n",
    "            print('N/A', end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\t0\t0.9032\t0.8603\t0.6831\t0.8100\t0.8630\t0.9197\t0.8136\t0.8551\t0.7704\t0.7178\t\n",
      "6\t0\t0.8671\t0.7778\t0.6667\t0.7289\t0.7733\t0.8033\t0.8320\t0.8012\t0.5591\t0.3238\t\n",
      "7\t0\t0.8854\t0.7979\t0.8770\t0.8571\t0.9001\t0.8483\t0.8899\t0.8238\t0.7677\t0.8376\t\n",
      "8\t0\t0.9150\t0.7867\t0.8682\t0.7200\t0.8853\t0.8756\t0.8560\t0.8459\t0.6296\t0.6821\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(calc_dice((label_test[i_case,:,:,:]==class_idx).flat, (segmentations_test[i_case,:,:,:]==class_idx).flat)), end='\\t')\n",
    "        else:\n",
    "            print(0, end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
