{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "from utils import *\n",
    "from model_FCNN import generate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import keras\n",
    "reload(keras)\n",
    "from keras import backend as K\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "\n",
    "import model_FCNN\n",
    "reload(model_FCNN)\n",
    "from model_FCNN import generate_model\n",
    "\n",
    "import callback_custom\n",
    "reload(callback_custom);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11\n",
    "num_channel = 2\n",
    "\n",
    "# K-fold validation (K=5)\n",
    "n_training = 16\n",
    "n_test = 4\n",
    "\n",
    "#idxs_training = list(range(1, 1+16))\n",
    "#idxs_test = list(range(17, 17+4))\n",
    "idxs_training = list(range(5, 5+16))\n",
    "idxs_test = list(range(1,1+4))\n",
    "\n",
    "patience = 5\n",
    "model_filename = 'models/outrun_step_{}.h5'\n",
    "csv_filename = 'log/outrun_step_{}.cvs'\n",
    "\n",
    "nb_epoch = 40\n",
    "validation_split = 0.10\n",
    "monitor = 'val_loss'#'val_categorical_accuracy'\n",
    "\n",
    "class_mapper = {0:0}\n",
    "class_mapper.update({ i+1:i for i in range(1, 1+10) })\n",
    "class_mapper_inv = {0:0}\n",
    "class_mapper_inv.update({ i:i+1 for i in range(1, 1+10) })\n",
    "\n",
    "matrix_size = (160, 220, 48)\n",
    "\n",
    "extraction_step = (3, 3, 1)\n",
    "#extraction_step = (5, 5, 3)\n",
    "\n",
    "segment_size = (27, 27, 21)\n",
    "core_size = (9, 9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "MAG_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "R2S_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "label_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_training):\n",
    "    QSM_train[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_train[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_train[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_train[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = np.stack((QSM_train, MAG_train, R2S_train), axis = 1)\n",
    "data_train = np.stack((QSM_train, R2S_train), axis = 1)\n",
    "#data_train = np.stack((QSM_train,), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "MAG_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "R2S_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "label_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_test):\n",
    "    QSM_test[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_test[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_test[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_test[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test = np.stack((QSM_test, MAG_test, R2S_test), axis = 1)\n",
    "data_test = np.stack((QSM_test, R2S_test), axis = 1)\n",
    "#data_test = np.stack((QSM_test,), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intensity normalisation (zero mean and unit variance)\n",
    "input_mean = 127.0\n",
    "input_std = 128.0\n",
    "data_train = (data_train - input_mean) / input_std\n",
    "data_test = (data_test - input_mean) / input_std\n",
    "\n",
    "# Map class label\n",
    "tmp = np.copy(label_train)\n",
    "for class_idx in class_mapper:\n",
    "    label_train[tmp == class_idx] = class_mapper[class_idx]\n",
    "tmp = np.copy(label_test)\n",
    "for class_idx in class_mapper:\n",
    "    label_test[tmp == class_idx] = class_mapper[class_idx]\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEACAYAAABBOusMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDAAA8RPAWLk2kGwFLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efdba39c898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0,:,:,[29,25]]), scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((32992, 2, 27, 27, 21), (32992, 243, 11))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Configure callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('1'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('1'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29692 samples, validate on 3300 samples\n",
      "Epoch 1/40\n",
      "29692/29692 [==============================] - 186s 6ms/step - loss: 0.3608 - categorical_accuracy: 0.8860 - val_loss: 0.2252 - val_categorical_accuracy: 0.9220\n",
      "Epoch 2/40\n",
      "29692/29692 [==============================] - 180s 6ms/step - loss: 0.0987 - categorical_accuracy: 0.9596 - val_loss: 0.2917 - val_categorical_accuracy: 0.9266\n",
      "Epoch 3/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0467 - categorical_accuracy: 0.98090.001 1e-05\n",
      "29692/29692 [==============================] - 180s 6ms/step - loss: 0.0467 - categorical_accuracy: 0.9809 - val_loss: 0.4356 - val_categorical_accuracy: 0.9217\n",
      "Epoch 4/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0240 - categorical_accuracy: 0.99070.001 1e-05\n",
      "29692/29692 [==============================] - 181s 6ms/step - loss: 0.0240 - categorical_accuracy: 0.9907 - val_loss: 0.5728 - val_categorical_accuracy: 0.9236\n",
      "Epoch 5/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0214 - categorical_accuracy: 0.99220.001 1e-05\n",
      "29692/29692 [==============================] - 182s 6ms/step - loss: 0.0214 - categorical_accuracy: 0.9922 - val_loss: 0.6293 - val_categorical_accuracy: 0.9230\n",
      "Epoch 6/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0080 - categorical_accuracy: 0.99720.001 1e-05\n",
      "29692/29692 [==============================] - 185s 6ms/step - loss: 0.0080 - categorical_accuracy: 0.9972 - val_loss: 0.6462 - val_categorical_accuracy: 0.9227\n",
      "Epoch 7/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0150 - categorical_accuracy: 0.9949\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "29692/29692 [==============================] - 187s 6ms/step - loss: 0.0150 - categorical_accuracy: 0.9949 - val_loss: 0.6792 - val_categorical_accuracy: 0.9214\n",
      "Epoch 8/40\n",
      "29692/29692 [==============================] - 188s 6ms/step - loss: 0.0798 - categorical_accuracy: 0.9664 - val_loss: 0.3645 - val_categorical_accuracy: 0.9160\n",
      "Epoch 9/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0516 - categorical_accuracy: 0.9786   ETA: 1:02 - loss: 0.0 - ETA: 59s - loss: 0.0552 - ETA: 52s - loss: - ETA: 45s - loss: - ETA: 37s - loss: 0.0540 - categor - ETA: 33s 0.0001 1e-05\n",
      "29692/29692 [==============================] - 188s 6ms/step - loss: 0.0516 - categorical_accuracy: 0.9786 - val_loss: 0.5155 - val_categorical_accuracy: 0.9147\n",
      "Epoch 10/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0314 - categorical_accuracy: 0.98750.0001 1e-05\n",
      "29692/29692 [==============================] - 187s 6ms/step - loss: 0.0314 - categorical_accuracy: 0.9875 - val_loss: 0.6007 - val_categorical_accuracy: 0.9153\n",
      "Epoch 11/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0182 - categorical_accuracy: 0.99300.0001 1e-05\n",
      "29692/29692 [==============================] - 184s 6ms/step - loss: 0.0182 - categorical_accuracy: 0.9930 - val_loss: 0.7505 - val_categorical_accuracy: 0.9138\n",
      "Epoch 12/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0106 - categorical_accuracy: 0.9961\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "29692/29692 [==============================] - 184s 6ms/step - loss: 0.0106 - categorical_accuracy: 0.9961 - val_loss: 0.8023 - val_categorical_accuracy: 0.9150\n",
      "Epoch 13/40\n",
      "29692/29692 [==============================] - 189s 6ms/step - loss: 0.0952 - categorical_accuracy: 0.9602 - val_loss: 0.2429 - val_categorical_accuracy: 0.9229oss: 0.0953 - categorical_accuracy: 0.96\n",
      "Epoch 14/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0885 - categorical_accuracy: 0.96291.001e-05 1e-05\n",
      "29692/29692 [==============================] - 191s 6ms/step - loss: 0.0885 - categorical_accuracy: 0.9628 - val_loss: 0.2618 - val_categorical_accuracy: 0.9213\n",
      "Epoch 15/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0840 - categorical_accuracy: 0.96471.001e-05 1e-05\n",
      "29692/29692 [==============================] - 188s 6ms/step - loss: 0.0840 - categorical_accuracy: 0.9647 - val_loss: 0.2730 - val_categorical_accuracy: 0.9211\n",
      "Epoch 16/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0797 - categorical_accuracy: 0.9665 - ETA: 53s - loss: 0.0802 - categorica - ETA: 49s  - ETA: 40s -  - ETA: 32s - loss: 0.0798 - categorical_accur -  - ETA: 19s - loss: 0.07991.001e-05 1e-05\n",
      "29692/29692 [==============================] - 188s 6ms/step - loss: 0.0797 - categorical_accuracy: 0.9665 - val_loss: 0.2919 - val_categorical_accuracy: 0.9197\n",
      "Epoch 17/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0755 - categorical_accuracy: 0.96831.001e-05 1e-05\n",
      "29692/29692 [==============================] - 187s 6ms/step - loss: 0.0755 - categorical_accuracy: 0.9683 - val_loss: 0.3152 - val_categorical_accuracy: 0.9184\n",
      "Epoch 18/40\n",
      "29664/29692 [============================>.] - ETA: 0s - loss: 0.0713 - categorical_accuracy: 0.97011.001e-05 1e-05\n",
      "29692/29692 [==============================] - 186s 6ms/step - loss: 0.0713 - categorical_accuracy: 0.9701 - val_loss: 0.3380 - val_categorical_accuracy: 0.9174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efdbabc5a20>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 47\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3299/3299 [==============================] - 3s 894us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22528750823133731, 0.9219801498926492]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_patch = extract_patches(read_data(1, 'QSM'), patch_shape=segment_size, extraction_step=(9, 9, 3)).shape[0]\n",
    "len_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3300/3300 [==============================] - 3s 838us/step\n",
      "6\n",
      "3300/3300 [==============================] - 3s 819us/step\n",
      "7\n",
      "3300/3300 [==============================] - 3s 789us/step\n",
      "8\n",
      "3300/3300 [==============================] - 3s 791us/step\n",
      "9\n",
      "3300/3300 [==============================] - 3s 796us/step\n",
      "10\n",
      "3300/3300 [==============================] - 3s 801us/step\n",
      "11\n",
      "3300/3300 [==============================] - 3s 795us/step\n",
      "12\n",
      "3300/3300 [==============================] - 3s 799us/step\n",
      "13\n",
      "3300/3300 [==============================] - 3s 806us/step\n",
      "14\n",
      "3300/3300 [==============================] - 3s 812us/step\n",
      "15\n",
      "3300/3300 [==============================] - 3s 812us/step\n",
      "16\n",
      "3300/3300 [==============================] - 3s 813us/step\n",
      "17\n",
      "3300/3300 [==============================] - 3s 810us/step\n",
      "18\n",
      "3300/3300 [==============================] - 3s 815us/step\n",
      "19\n",
      "3300/3300 [==============================] - 3s 811us/step\n",
      "20\n",
      "3300/3300 [==============================] - 3s 817us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_train = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_training):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_train = data_train[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_train[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    \n",
    "    segmentations_train = segmentations_train + [segmentation]\n",
    "    \n",
    "segmentations_train = np.stack(segmentations_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEL1JREFUeJzt3X1O28oawOHxVTeBWEayjIplkGUglhGWEXUZdBkRy/D5\ng2swL3biQKjn43mk6ra951RW3zPjXyaGdH3fJwAA4N3/1r4AAADIjUgGAIBAJAMAQCCSAQAgEMkA\nABCIZAAACEQyAAAEIhkAAAKRDAAAwa+1LyCllLqu87F/K+r7vrvWn2WW6zLLelxrlua4LmuyHmZZ\nj6WzdJIMAACBSAYAgEAkAwBAIJIBACAQyQAAEIhkAAAIRDIAAAQiGQAAApEMAACBSAYAgEAkAwBA\nIJIBACAQyQAAEIhkAAAIRDIAAAQiGQAAApEMAACBSAYAgEAkAwBAIJJh5Pn5ee1LAAAy8GvtC4A1\n7ff7T783F8rb7fanLwcAsnbqMKm2+2TX9/3a15C6rlv/IhrW9313rT+rpFlOBXJKKe12u5RSmbHc\n6iynlL6RX2uWpc+xdNZkPVqf5Vfeac11r106S5FM8wt/LpY3m83sv1P6wl+ixFmOxblOzTPXOaYk\nkmthTdbDLF9DOe6b5+I5x31WJLOYhf/u1Oly3Bz6vk9dd7W/uqswy3fnZjlW8iZ+TulzLJ01WQ+z\nfHfJ/jrIaZ8VySxm4X8WN4DhEYyp9ZJTKJvlZ1Ob+dxGXuImfk4tcyyVNVkPs/yo5FBeOkvf3QIm\nDFE8/nkOLyi53HiWg/1+n81mDVCiqb01pbr2VyfJeHW8UO6nyCmZ5ZxzX6SZIyfJdbAm62GW0y55\nTDEXTpLhh+UWyMw7deIx6Pv+7Qf/3v39/dqXACw0Xq+nDhs2m82HvbW0/dVJMl4dLxDXSa6BbJan\nLXnWPJfZtnSSPBXIT09PK1zJ9bW4JsfzrGWOKbU5y0vs9/tPwZzrvdMX7v2w+/v7aha/hV8Pszxv\nCOW5Z81L28TPKW2OtQVWy2tymGUNc0yp7Vl+VY4HECmJ5B9X0+K38Othlpcb9sCcNvCU2ovk4ftY\n//37t6pQbm1NjudYm9ZmWbOls/Sx1BcYfxhB6Rs38Cq3OG7R3Af32GfLtdlsqgxl2iKSAciKOC6b\nOKYWHrfAW0gVMct6tPa4Ra2syXqYZT08bgFAMW5ublJKKb28vKx8JXzVMMOUzJE6+D7JF7i5uXn7\nAcB1jPdU+yvU53g8rn0JXyKSL+CVMdTpeDwWu4nX5uXlJf3+/fvtB+UY7pHD/5of4721xD3W4xYX\niov/z58/a14O8AUPDw9vPx9/u7Hj8Zhub2/XuKSmzUWV/bU8c9+phDaM99aUUrq9vf0Qx6XtsSL5\nG2zgbRkv9JIWOR/VtonXYOrE0f5aHodH7Yr76ljJe6xI/iKbQHvGC72kRc67uJE/Pj6udCXMsbeW\ny+zadCqQBzGUSyGS4YuEclnOnXSkVOYzczUQV1CmuX11OIA4HA4ppZTu7u7eQrmk+6ZIhhnD4j91\n2ljagm/V1EY+nuuwkZslwDKnAnnYUwel7rG+uwVMGC/+8c9LW+BMG59yjDfzuLED8NklgVwyn7iH\nTxEamTtxHC/6u7u7bL+Izyw/mtvI574C/+7u7icv5yI+ca8O1mQ9zHLa0igucX8VyVj4aTqmzn0r\no5wW/MAs3x0Ohw8zmtvIc5xjSiK5FtZkPczyXYlhPCaSWazlhf+dt4VyXPwtz3JsyVxznN+YSK6D\nNVkPs6zH0ln6wj24UO5xhRkB8H1OkvHqeOTUCWQJ4WWW9XCSXAdrsh5mWQ+PW7CYhV8Ps6yHSK6D\nNVkPs6zH0ln6FnAAABCIZAAACEQyAAAEIhkAAAKRDAAAgUgGAIBAJAMAQCCSAQAgEMkAABCIZAAA\nCEQyAAAEIhkAAAKRDAAAgUgGAIBAJAMAQCCSAQAgEMkAABCIZAAACEQyAAAEIhkAAIKu7/u1rwEA\nALLiJBkAAAKRDAAAgUgGAIBAJAMAQCCSAQAgEMkAABCIZAAACEQyAAAEIhkAAAKRDAAAgUgGAIBA\nJAMAQCCSAQAgEMkAABCIZAAACEQyAAAEIhkAAAKRDAAAgUgGAIBAJAMAQCCSAQAgEMkAABCIZAAA\nCEQyAAAEIhkAAAKRDAAAgUgGAIBAJAMAQCCSAQAgEMkAABCIZAAACEQyAAAEIhkAAAKRDAAAgUgG\nAIBAJAMAQCCSAQAgEMkAABCIZAAACEQyAAAEIhkAAAKRDAAAgUgGAIBAJAMAQPBr7QtIKaWu6/q1\nr6Flfd931/qzzHJdZlmPa83SHNdlTdbDLOuxdJZOkgEAIBDJAAAQiGQAAAhEMgAABCIZAAACkQwA\nAIFIBgCAQCQDAEAgkgEAIBDJAAAQiGQAAAhEMgAABCIZAAACkQwAAIFIBgCAQCQDAEAgkgEAIBDJ\nAAAQiGQAAAh+rX0BAEC9np+f336+3W5XvBK4TNf3/drXkLquW/8iGtb3fXetP8ss12WW9bjWLEua\n4zimBqVHVctrcmqec0qYc8uzrM3SWYpkLPyKtDzLUzfkEm7AkUieVtosW16Tg/1+n3a73dn55j5b\ns6yHSGax1hf+3Mad+4Y9peVZln4DjkTyeSXMtOU1Odjv959+b7PZzP7zuc7VLOshklms9YU/bOC7\n3S6lVHY0m+XHm/HcTFuaZQ1zHMyFVc7zbH1NjpUey63NcumL1tzmtIRIZrHWFn40tXHPvTWY+2Zg\nlsvjqpVZljjHlC4P5ZTynGnra3Ks9PXZ4iyfn58/zKKWx9pEMou1uPCjWkLZLM0yKnWOKc1HVUnz\ntCY/OhfK2+02xS7puqv9FX5Lq7Mcz6yGZ8tTEslcoNWFP2Xp24G5bgJm+WpJXOU6w4FIfrU0lHOd\npzU5be7F7FSTiOT1TT3KVvKpskhmsZYXfnTqhlwCs3x3bpbjvS+Xm/CYSH536vSxlpvxEjXMcjAV\nXXM9ksv6bH2Wl75L1/d9NrOLls7SJ+7BSCkxzHm73W52nrkHMh/NzTH3QGbeqfVJnqbmNRXOU4/M\nlEokQ2Djrkucp0Auk3VZp3OxbI3mb7vdfvhRSyCn5HELkreQamKWy+T8NuDA4xZ1sCaXy/UL9gZm\n+VH89qk5P08eeSb5H7m/v09PT09rX8a3WPj1MMt6iOQ6WJP1MMvTRPIPqfE/lpJY+PUwy3qI5DpY\nk/Uwy9NyfydgzBfu/bBT39AeAKBVOQfyJZwk49VxRcyyHk6S62BNLnc8Ht9+fnt7u+KVTDPLejhJ\nBgCKcDweP4TxOJhhLSIZaMLDw0N6eHhIKb3egN2EyzSeI3WzRlnbr7UvoFQ3Nzfp5eVl7cvgH8r9\nrUCmxaAa/zqeXpG3qTge1qU5lmmY6fBdom5vbz/stdZoGWq9PzpJ/qJxIP/+/XvFK+EnDKdV41Mr\nbwWWZyqqHh8fq9rEWxVna02WZzzDx8fHFa+Ea6rpnTqR/E0CuT6n3soVV+U4NcfD4fA2y1o289rN\nzdOL1zKdeoeH8kzdG2tYjx63+KY/f/6sfQlc0ZKNWijXYRzK5G1uXR4Oh5TS+1v05lmGuXd4BvGR\nC/LS0jsAvgUcvq3N/83diIdNYLghp5TS3d3dP7mmS5nl/A14PL9BrnNMybeAG5xal3GmOc7Tmvxo\nap7jzx2IM8zpxY9Znn6BM/XCJpfZRUtn6SQZ0vyNeLPZTMYVZSktkHl17pEZynIukFN6n+uwPnON\nrBadO4Co8RE2kUzzlmzcA2GVtzjLEk+QeXXqhSvlWbo2KUec4eFwSHd3d1U9/uRxC5p/C2nJRl1K\nVJnl6VmWMseU2n7cYiqoUjo931xna00e3mazNIrNMi9feYGT6wwHS2cpkml24Q/mFnvui3yKWeb/\njOpSLUfyWIlhPGZNlh3GYy3OcniRU9McUxLJXKDFhV8rs6xHi5Fc2404JWuyJq3N8pLHYUpakymJ\nZC7Q2sKvmVnWo8VIHotfwFUqa7Ierc6yxq/rEMks1urCr5FZ1qP1SK6FNVkPs6zH0ln6xD0AAAhE\nMgAABCIZAAACkQwAAIFIBgCAQCQDAEAgkgEAIBDJAAAQiGQAAAhEMgAABCIZAAACkQwAAIFIBgCA\nQCQDAEAgkgEAIBDJAAAQiGQAAAhEMgAABCIZAAACkQwAAEHX9/3a1wAAAFlxkgwAAIFIBgCAQCQD\nAEAgkgEAIBDJAAAQiGQAAAhEMgAABCIZAAACkQwAAIFIBgCAQCQDAEAgkgEAIBDJAAAQiGQAAAhE\nMgAABCIZAAACkQwAAIFIBgCAQCQDAEAgkgEAIBDJAAAQiGQAAAhEMgAABCIZAAACkQwAAIFIBgCA\nQCQDAEAgkgEAIBDJAAAQiGQAAAhEMgAABCIZAAACkQwAAIFIBgCAQCQDAEAgkgEAIBDJAAAQiGQA\nAAhEMgAABCIZAAACkQwAAIFIBgCAQCQDAEAgkgEAIPi19gWklFLXdf3a19Cyvu+7a/1ZZrkus6zH\nNWcJwOWcJAMAQCCSAQAgEMkAABCIZAAACEQyAAAEIhkAAAKRDAAAgUgGAIBAJAMAQCCSAQAgEMkA\nABCIZAAACEQyAAAEIhkAAAKRDAAAgUgGAIBAJAMAQCCSAQAgEMkAABCIZAAACH6tfQEleX5+PvvP\nbLfbf3AlAAD8pK7v+7WvIXVdt/5FfMG5aC4lmPu+7671Z5U6y1qYZT2uOUsALieSv2C/33/6vd1u\nNxvNuceysKqHWb469QI29/U4EMkA6xLJXzQVyimltNlsZv+dXG/OwqoeZvluWKOlvoAVyQDr8oV7\nX7Tb7SZ/f7vdZn3jhdbs9/vZNbnk6wwAaJOT5G9aeqKcczg7fayHWX4U1+fcOz05rk8nyQDrEslX\nMPeM8tj477nr8rr3Cat6mOVnU+uzhFgWyQDr8rjFFex2u9nHL1L6GMhTvwZ+ztTa/Pv376ffyymQ\nAVifSL6iqVieCuLcTpKhRUMUb7fbtNlsUt/3XsAC8MbjFj9o7u82t0j2Fn1K9/f36enpae3L+Daz\nPG386MXwgjau01zWp8ctANYlkn9QrjffSFjVwywvl+vXC4hkgHX5WOoflNMNF/gs10AGYH0iGWiW\nMAZgji/cAwCAQCQDAEAgkgEAIBDJAAAQ+MK9H3Q8Hj/93u3t7QpXAgDAJZwk/yBBDPk7Ho+TL2gB\naJuT5Ct7eHhIj4+PKaXpk+Tj8SieYSUPDw+z/5+1CcCYT9y7knjzHUI5pc+xnNuN2Ke01cMs500F\n8uPjY7br0yfuAaxLJF/BqUBOSSTz75jlZ3NxfDgc3n692Wzefp7L+hTJAOvyuMU3TMXx4XD4cPNN\nKZ+bLrRk7tGKGMgpva5Rj1sAMOYk+YvGN+Cpm250d3f305f0ZU4f62GWr+ZOj1NKs2s1tzXqJBlg\nXSL5C84FcZTbzTcSVvUwy9f1Oay5JWs11/UpkgHWJZIvcEkc53rjnSKs6mGWr06t1VLWpkgGWJdI\nvlDJj1XMEVb1MMt6iGSAdYlkhFVFzLIeIhlgXT5xDwAAApEMAACBSAYAgEAkAwBAIJIBACAQyQAA\nEIhkAAAIRDIAAAQiGQAAApEMAACBSAYAgEAkAwBAIJIBACAQyQAAEIhkAAAIRDIAAAQiGQAAApEM\nAACBSAYAgEAkAwBAIJIBACDo+r5f+xoAACArTpIBACAQyQAAEIhkAAAIRDIAAAQiGQAAApEMAACB\nSAYAgEAkAwBAIJIBACAQyQAAEIhkAAAIRDIAAAQiGQAAApEMAACBSAYAgEAkAwBAIJIBACAQyQAA\nEIhkAAAIRDIAAAQiGQAAApEMAACBSAYAgOA/z1OSt0uUzVcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efdba2d3f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efea6a74a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Check false-positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_fpos = (label_train == 0) & (segmentations_train != 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_fpos = np.zeros(label_train.shape, dtype=precision_global)\n",
    "mask_fpos[idx_fpos == True] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADgxJREFUeJzt3ctypEgSBVByTB/F/6/4K3pRnT1ZLilFPlBE3Dhn1WbT\nXYOVp8PFiYDLvu8LAADwf/9rfQAAANAbIRkAAAohGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRkA\nAAohGQAAio/WB7Asy3K5XHz2r6F93y/v+rPUsi21zPGuWqpjW3oyh1rmOFpLk2QAACiEZAAAKIRk\nAAAohGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAohGQAACiE5B9s27Zs29b6MIBv6FEAziAk\n3+HCC+PQrwC8k5AMDG1d1//+WVDul4k/MJrLvu+tj2G5XC7tD2Ji+75f3vVnqWVbM9fyGsBuQ/PI\n3lXLnuq4bVtMfY6auSfTqGWOo7UUktH4QdQyR2JInpGezKGWOY7W0nILAAAohGQAACiEZABeZlMe\nkEZIBuAlAjKQSEgG4GWzvbUCyCckA3DYV1NjARlI9NH6AKBHM77PFb5jOQUwI+9Jxrsfg6hljh7e\nk2xq/Do9mUMtPxt1oOQ9yXAikzVms67rkBdD4HFHr3H1nJB2bRSS4QnCAjPxeweOWNc1KihbboFH\nSEHUMkcPyy14nZ7MoZY5jtbSxj1gWnXiYWJKouu60VHXjzK+23PtSL9Bk2TcHQdRy+f0GB5MkjPo\nyRxqmcPGPYADakBOWk8Hv03/zG3btqjfgJBcHClu0g8AZnU9mdcJcm8T5Zk4t47v2j9qOad7b8EZ\n8TdhuQUeIQVRyxyWW2SYqSdvbzp7XML0qplqmc5yCwCGczttGnHyxB9pAXlE+ud1QvJBfmzjS1sr\nNSP1m4ugNRb16ot6vG6KV8C94zVPfmzjS3vJeaprjfRcv858nZO6/x69BvdZk8w066xmuCCk1zJx\nneN3rEnOkN6TM1HLHEdrKSQzRePPEq5mqOUshOQMejLHLLWc4Xpp494JPKofV3rDQwrn2QzXOqrn\neF5dmphUc5Nkprk7noFa5jBJzqAnc6hlDpNkGETSXTeAcxophGQ44KzXx3kkCaSxvC2D65KQDId8\n96nNV08iLiYA9OiV61NKwBaS4QWvhtyUE8mo6hMC9QD42U/nypQBkI172Ixw0AivxVHLz76rW+/1\n7GHjXu9/RyPQkznU8mejnDO8J5nDNH4OtczRS0helpypUAt6Moda/m3k84OQzGEaP4da/u3Mzyef\nrYeQvCxjXwh7oCdzqGUOIZnDNH4OtczRS0heFkH5FXoyh1rmEJI5bITGd5E+ZoRackxPIZnn6ckc\naplDSOawkRp/lE0BrYxUS+4TkjPoyRxqmUNI5jCNn0MtcwjJGfRkDrXM4bPUAADwJCEZAAAKIRmA\nYdWvJgK8i5AMAACFjXsHJb9VwWaEHGqZw8a9DHoyh1rmsHHvjTzKAwCYi0ky7o6DqGWOxEly8hO5\n7+jJHGqZwyQZAACeJCQzLcto4HfNNkUGxvbR+gCgpdug7AIOAFwJyUxPOAYAKhv3sBkhiFrmSNy4\nNyM9mUMtc9i4BwAATxKSAQCgEJIBAKAQkgEAoBCSAQCgEJIBAKAQkgEAoBCSAQCg6OJjIgAA0BOT\nZAAAKIRkAAAohGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAohGQA\nACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAo\nhGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRk\nAAAohGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAoPlofwLIsy+Vy\n2Vsfw8z2fb+8689Sy7bUMse7aqmObenJHGqZ42gtTZIBAKAQkgEAoBCSAQCgEJIBAKAQkgEAoBCS\nAQCgEJIBAKAQkgEAoBCSgSFt29b6EAAIdtn39h998eWZtnxFKEdKLbdtW9Z1vfu/V/f+/RH54l6G\nlJ5ELZP44h4wtHuT4nVd/wrFaQEZgPY+Wh8AQLWu6+HlFF/9u0IzAK8ySQaGZm0yAGewJhnrrILM\nWMt765d/WtvcM2uSM8zYk6nUMsfRWgrJaPwgaplDSM6gJ3OoZQ4b9wAA4ElCMgAAFEIy0JzNd/A7\n9BocZ00y1lkF6bmW14vzqBvpfps1yRl67kkeo5Y5rEkGuiEgw5zq5Nokm5EIycCpbgOyCyT04zf6\nsd4Yu1FmJEIycDoBGfpw24e/GVj1PyOyJhnrrIL0WkvLLR5nTXKGXnuSx6llDmuS4UEmHedZ17VJ\nQN62TV0noMZ9uFcHNWJEJsm4Ow6ilsf1/slqk+QMs/Vk8lOj2Wp51WqJzplMkuGGKcbcvqp/yske\neuE8m+n6JHDGvSVCMvxrtuafyVeB2FKMLGrZDzeguWarreUWTPsI6Rm9P0pUyxyWW2TQkznUMofl\nFnCCVhvQOI8JJMD7JJ1TP1ofAEArvW/eAxhF709an2GSDHck3RHzNwF5THoS2vtuM3TaOdWaZKyz\nCqKWOaxJzqAnc6hlDmuSmVp9c4HpE8DrnEuZyZQh+dUmv/73ThbjSHsEBNDC9Vzq+set1N+D5RZ4\nhBRELXNYbpFBT+ZQyxyWWwAAw0idRvbM3/l9QvKT/LD6oA48ym8G4A9LEe+z3AKPkO4Y7TVhapnD\ncov7RulNPfmYR+tab3rP/E2oZQ7LLeDGs9PDES7CPMYkOYPeHFvtw8QPUTA+IZmp1FfDMR8X4fb0\nILUPn+3L2/9Ob/+uGa6nllsw3SOkUR7TPmPUWpoifWa5xeN67O1Re5LP1PKzHnvuiKO1FJLR+AeM\nciJQy6+NUr9b6SH5N9eStqQnH9Nzr6plDiGZwzR+jllq2fOF9F3SQ/LVO2vZ4+9ixJ7s8e+xByPW\nkq8JyW+UfsLQ+DnUMscsITmdnsyhljm83eKNkgPy7NI3HcxELaFPM2zwIpNJMu6Og6hljpknybeB\navQhhZ7MMWstE5+mW27BYbM2fiK1zDFzSE6iJ3OoZQ7LLQAAeNrsy2RMknF3HEQtc5gkZ9CTOdQy\nx9Fafpx9IAAjSlyHB8+a5b3WcMskGXfHQdTyPXrYOGaSnEFP5lDLHNYkAzzpGoxNywDmJSQDU/pp\nQ4qADDA3IRkY0iu7rmffsQ3Az4RkYFivfMnLpLhfbmKAHti4h80IQWaqZfpuexv3MszUk+nUMoeN\ne0Ask0YAziYkAxFeWXoBAJWPiQDDuV1aIRgDcAZrkrHOKoha5rAmOYOezKGWOaxJBgCAJwnJAABQ\nCMkAAFAIyQAAUAjJAABQCMkAAFAIyQAAUAjJAABQCMkAAFB08cU9AADoiUkyAAAUQjIAABRCMgAA\nFEIyAAAUQjIAABRCMgAAFEIyAAAUQjIAABRCMgAAFEIyAAAUQjIAABRCMgAAFEIyAAAUQjIAABRC\nMgAAFEIyAAAUQjIAABRCMgAAFEIyAAAUQjIAABRCMgAAFEIyAAAUQjIAABRCMgAAFEIyAAAUQjIA\nABRCMgAAFEIyAAAUQjIAABRCMgAAFEIyAAAUQjIAABRCMgAAFEIyAAAUQjIAABRCMgAAFEIyAAAU\nQjIAABRCMgAAFEIyAAAUQjIAABRCMgAAFEIyAAAUQjIAABQfrQ9gWZblcrnsrY9hZvu+X971Z6ll\nW2qZ4521BOBxJskAAFAIyQAAUAjJAABQCMkAAFAIyQAAUAjJAABQCMkAAFAIyQAAUAjJAABQCMkA\nAFAIyQAAUAjJAABQCMkAAFAIyQAAUAjJAABQCMkAAFAIyQAAUAjJAABQCMkAAFAIyQAAUAjJAABQ\nfLQ+gNFs2/bfP6/r2vBIAAA4y2Xf99bHsFwul/YH8aJt24YNzfu+X971ZyXUcmRqmeOdtQTgcUIy\ngtWS84RALT8b9QZWSAZoa4o1ybcBKPH/D/jeiAEZgPZMkjF9DKKWz+lx2mySDNCWkHyS6zS5twvv\nVwSrHGqZQ0gGaEtIPlmPE6pKsPraSDc6V2qZQ0gGaEtIPtEIAXlZBKskaplDSAZoa4qNe62MEJB7\n1WLzow2XAMCVkEyXfusGI+XVb7yHGyUAroRkgH+5UQLgKjokb9tmMhTsHbUVigCAr3y0PoAzCUC5\n3PwAAGfydgu8ESGIWubwdguAtqKXWzzCZBIAgCsh+V9nLc0QvsehVgDAleUWeET/g1E+CrMsapnE\ncguAtkyST2QymWGUgAwAvI9JMqaPQdQyh0kyQFsmySczTYb29CEAjzJJPsn1ojzCo3rTxxxqmcMk\nGaAtk+Q3up1Wres6REDuiWkfrfjtAVCZJGP6GEQtvzfS051lMUkGaE1IRrAKopZ/jBaIvyIkA7Rl\nucVJPL6Fdu4td9KbABxhkozpYxC1zGGSDNCWSTIAABSxIXnbNo9VAQB4iuUWndi2rdkmI4/oc6hl\nDsstANqKnSSPyOQbAKAPJsmYPgZRyxwmyQBtmSQDAEAhJAMAQCEkAwBAISQDAEAhJAMAQCEkAwBA\nISQzDe+hBgCO8p5kvFs3iFrm8J5kgLZMkgEAoBCSAQCgEJIBAKAQkgEAoBCSAQCgEJIBAKAQkgEA\noBCSAQCgEJIBAKDo4ot7AADQE5NkAAAohGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAohGQA\nACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAohGQAACiEZAAAKIRkAAAo\nhGQAACiEZAAAKIRkAAAohGQAACj+AR2zBK0p6JVbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efea64a8f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(200*(np.squeeze(mask_fpos[0:15,:,:,25])), rows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Rebuild training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8006, 2, 27, 27, 21), (8006, 243, 11))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_step_ft = (6,6,3)\n",
    "x_train, y_train = build_set(data_train, label_train, extraction_step_ft, segment_size, core_size, mask_fpos)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle array\n",
    "idxs_shuffle = shuffle(x_train)\n",
    "idxs_shuffle = shuffle(y_train, idxs_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array('tmp/x_train.bc', x_train)\n",
    "save_array('tmp/y_train.bc', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_array('tmp/x_train.bc')\n",
    "y_train = load_array('tmp/y_train.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Regenerate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from callback_custom import EarlyStoppingLowLR\n",
    "from callback_custom import ReduceLROnPlateauBestWeight\n",
    "\n",
    "\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('2'),\n",
    "    monitor=monitor,\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "\n",
    "stopper = EarlyStoppingLowLR(patience=patience, monitor=monitor, thresh_LR=1e-5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateauBestWeight(filepath=model_filename.format('2'),\n",
    "                                                      monitor=monitor, \n",
    "                                                      patience=patience, \n",
    "                                                      verbose=1, \n",
    "                                                      factor=0.1, \n",
    "                                                      min_lr=1.001e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7205 samples, validate on 801 samples\n",
      "Epoch 1/40\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0553 - categorical_accuracy: 0.9784 - val_loss: 0.0024 - val_categorical_accuracy: 0.9996\n",
      "Epoch 2/40\n",
      "7205/7205 [==============================] - 43s 6ms/step - loss: 0.0413 - categorical_accuracy: 0.9832 - val_loss: 0.0036 - val_categorical_accuracy: 0.9988\n",
      "Epoch 3/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0366 - categorical_accuracy: 0.98490.0001 1e-05\n",
      "7205/7205 [==============================] - 43s 6ms/step - loss: 0.0366 - categorical_accuracy: 0.9849 - val_loss: 0.0057 - val_categorical_accuracy: 0.9978\n",
      "Epoch 4/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0336 - categorical_accuracy: 0.98610.0001 1e-05\n",
      "7205/7205 [==============================] - 44s 6ms/step - loss: 0.0336 - categorical_accuracy: 0.9861 - val_loss: 0.0066 - val_categorical_accuracy: 0.9973\n",
      "Epoch 5/40\n",
      "7205/7205 [==============================] - 44s 6ms/step - loss: 0.0310 - categorical_accuracy: 0.9871 - val_loss: 0.0032 - val_categorical_accuracy: 0.9988\n",
      "Epoch 6/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0294 - categorical_accuracy: 0.98780.0001 1e-05\n",
      "7205/7205 [==============================] - 44s 6ms/step - loss: 0.0294 - categorical_accuracy: 0.9878 - val_loss: 0.0039 - val_categorical_accuracy: 0.9985\n",
      "Epoch 7/40\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0275 - categorical_accuracy: 0.9887 - val_loss: 0.0019 - val_categorical_accuracy: 0.9993\n",
      "Epoch 8/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0248 - categorical_accuracy: 0.9898 - ETA: 44s - loss: 0.0337 - categorical_accuracy: 0. - ETA: 43s - loss: - ETA: 0s - loss: 0.0248 - categorical_accuracy: 0.980.0001 1e-05\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0248 - categorical_accuracy: 0.9898 - val_loss: 0.0065 - val_categorical_accuracy: 0.9975\n",
      "Epoch 9/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0229 - categorical_accuracy: 0.99070.0001 1e-05\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0229 - categorical_accuracy: 0.9907 - val_loss: 0.0053 - val_categorical_accuracy: 0.9981\n",
      "Epoch 10/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0212 - categorical_accuracy: 0.99140.0001 1e-05\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0212 - categorical_accuracy: 0.9914 - val_loss: 0.0027 - val_categorical_accuracy: 0.9989\n",
      "Epoch 11/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0195 - categorical_accuracy: 0.99210.0001 1e-05\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0195 - categorical_accuracy: 0.9922 - val_loss: 0.0032 - val_categorical_accuracy: 0.9988\n",
      "Epoch 12/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0189 - categorical_accuracy: 0.99240.0001 1e-05\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0188 - categorical_accuracy: 0.9924 - val_loss: 0.0023 - val_categorical_accuracy: 0.9990\n",
      "Epoch 13/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0167 - categorical_accuracy: 0.9933 ETA: 3s - los\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.001e-05.\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0167 - categorical_accuracy: 0.9933 - val_loss: 0.0038 - val_categorical_accuracy: 0.9985\n",
      "Epoch 14/40\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0237 - categorical_accuracy: 0.9904 - val_loss: 0.0022 - val_categorical_accuracy: 0.9992\n",
      "Epoch 15/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0228 - categorical_accuracy: 0.9907 ETA: 1s - loss: 0.0228 - categorical_ac1.001e-05 1e-05\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0228 - categorical_accuracy: 0.9908 - val_loss: 0.0024 - val_categorical_accuracy: 0.9991\n",
      "Epoch 16/40\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0224 - categorical_accuracy: 0.9910 - val_loss: 0.0020 - val_categorical_accuracy: 0.9992\n",
      "Epoch 17/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0220 - categorical_accuracy: 0.9911 ETA: 2s - loss: 0.0220 - cate1.001e-05 1e-05\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0220 - categorical_accuracy: 0.9911 - val_loss: 0.0027 - val_categorical_accuracy: 0.9990\n",
      "Epoch 18/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0217 - categorical_accuracy: 0.99131.001e-05 1e-05\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0217 - categorical_accuracy: 0.9913 - val_loss: 0.0027 - val_categorical_accuracy: 0.9990\n",
      "Epoch 19/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0214 - categorical_accuracy: 0.99141.001e-05 1e-05\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0214 - categorical_accuracy: 0.9914 - val_loss: 0.0024 - val_categorical_accuracy: 0.9991\n",
      "Epoch 20/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0211 - categorical_accuracy: 0.99161.001e-05 1e-05\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0211 - categorical_accuracy: 0.9916 - val_loss: 0.0029 - val_categorical_accuracy: 0.9989\n",
      "Epoch 21/40\n",
      "7200/7205 [============================>.] - ETA: 0s - loss: 0.0208 - categorical_accuracy: 0.99171.001e-05 1e-05\n",
      "7205/7205 [==============================] - 45s 6ms/step - loss: 0.0208 - categorical_accuracy: 0.9917 - val_loss: 0.0024 - val_categorical_accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efe9affc7f0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "# Load optimized weights\n",
    "model.load_weights(model_filename.format('1'))\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-4)\n",
    "\n",
    "# Start fine-tuning\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0019452046148944646, 0.99926935911178594]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_start_valid = int(len(x_train)*validation_split)\n",
    "model.evaluate(x_train[-idx_start_valid:], y_train[-idx_start_valid:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3300/3300 [==============================] - 3s 860us/step\n",
      "2\n",
      "3300/3300 [==============================] - 3s 800us/step\n",
      "3\n",
      "3300/3300 [==============================] - 3s 801us/step\n",
      "4\n",
      "3300/3300 [==============================] - 3s 802us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_test = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_test = data_test[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_test[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    #segmentation = reconstruct_volume_majority(pred_classes, matrix_size, extraction_step=(3, 3, 3))\n",
    "    \n",
    "    segmentations_test = segmentations_test + [segmentation]\n",
    "    \n",
    "segmentations_test = np.stack(segmentations_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAj+B12u+P2qx1o1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efd71a79eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efeb65234a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_test[:,:,:,23]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pick the largest connected component for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    segmentation = np.squeeze(segmentations_test[i_case,:,:,:]);\n",
    "    tmp = np.zeros(segmentation.shape, dtype=segmentation.dtype)\n",
    "    \n",
    "    for class_idx in class_mapper_inv :\n",
    "        mask = (segmentation == class_idx)\n",
    "        \n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            labeled_mask, num_cc = ndimage.label(mask)\n",
    "            largest_cc_mask = (labeled_mask == (np.bincount(labeled_mask.flat)[1:].argmax() + 1))\n",
    "            \n",
    "            tmp[largest_cc_mask == 1] = class_idx\n",
    "        \n",
    "    segmentations_test[i_case,:,:,:] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Done with Step 3\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx)\n",
    "    \n",
    "    segmentation = np.copy(np.squeeze(segmentations_test[i_case,:,:,:]))\n",
    "    \n",
    "    tmp = np.copy(segmentation)\n",
    "    for class_idx in class_mapper_inv:\n",
    "        segmentation[tmp == class_idx] = class_mapper_inv[class_idx]\n",
    "    del tmp\n",
    "\n",
    "    save_data(segmentation, case_idx, 'label')    \n",
    "\n",
    "print(\"Done with Step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Calculate metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(m1, m2):\n",
    "    return 2*((m1==1) & (m2==1)).sum()/((m1==1).sum() + (m2==1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t0.9991\tN/A\t0.8784\t0.8406\t0.9524\t0.9302\t0.9153\t0.9249\t0.8402\t0.8072\t0.7797\t0.8155\t\n",
      "2\t0.9992\tN/A\t0.9286\t0.8478\t0.9316\t0.9394\t0.9908\t0.9645\t0.9348\t0.9522\t0.8557\t0.7773\t\n",
      "3\t0.9986\tN/A\t0.9398\t0.8878\t0.9532\t0.9583\t0.9060\t0.8978\t0.8790\t0.9058\t0.0000\t0.7158\t\n",
      "4\t0.9987\tN/A\t0.8209\t0.8163\t0.8705\t0.9231\t0.7877\t0.8666\t0.9278\t0.8684\t0.7901\t0.9147\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    print('{:.4f}'.format(accuracy_score(label_test[i_case,:,:,:].flat, segmentations_test[i_case,:,:,:].flat)), end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(precision_score(label_test[i_case,:,:,:][mask], segmentations_test[i_case,:,:,:][mask], average='micro')), end='\\t')\n",
    "        else:\n",
    "            print('N/A', end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t0\t0.9155\t0.8855\t0.8889\t0.7477\t0.8268\t0.8531\t0.7894\t0.7986\t0.7629\t0.7657\t\n",
      "2\t0\t0.8478\t0.7959\t0.8226\t0.8986\t0.7797\t0.8746\t0.8060\t0.8817\t0.7944\t0.6248\t\n",
      "3\t0\t0.8715\t0.8614\t0.8740\t0.8578\t0.8084\t0.8651\t0.6875\t0.7774\t0.0000\t0.7674\t\n",
      "4\t0\t0.8943\t0.7619\t0.7832\t0.3396\t0.7076\t0.8168\t0.8046\t0.7018\t0.7222\t0.8036\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(calc_dice((label_test[i_case,:,:,:]==class_idx).flat, (segmentations_test[i_case,:,:,:]==class_idx).flat)), end='\\t')\n",
    "        else:\n",
    "            print(0, end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
