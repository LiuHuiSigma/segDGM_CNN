{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "from utils import *\n",
    "from model_FCNN import generate_model\n",
    "\n",
    "seed = 47\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import keras\n",
    "reload(keras)\n",
    "from keras import backend as K\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "\n",
    "import model_FCNN\n",
    "reload(model_FCNN)\n",
    "from model_FCNN import generate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11\n",
    "num_channel = 1\n",
    "\n",
    "# K-fold validation (K=5)\n",
    "n_training = 16\n",
    "n_test = 4\n",
    "\n",
    "idxs_training = list(range(1, 1+16))\n",
    "idxs_test = list(range(17, 17+4))\n",
    "\n",
    "patience = 5\n",
    "model_filename = 'models/outrun_step_{}.h5'\n",
    "csv_filename = 'log/outrun_step_{}.cvs'\n",
    "\n",
    "nb_epoch = 40\n",
    "validation_split = 0.20\n",
    "\n",
    "class_mapper = {0:0}\n",
    "class_mapper.update({ i+1:i for i in range(1, 1+10) })\n",
    "class_mapper_inv = {0:0}\n",
    "class_mapper_inv.update({ i:i+1 for i in range(1, 1+10) })\n",
    "\n",
    "matrix_size = (160, 220, 48)\n",
    "\n",
    "extraction_step = (3, 3, 3)\n",
    "#extraction_step = (9, 9, 3)\n",
    "\n",
    "segment_size = (27, 27, 21)\n",
    "core_size = (9, 9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "MAG_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "R2S_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "label_train = np.empty(((n_training,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_training):\n",
    "    QSM_train[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_train[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_train[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_train[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = np.stack((QSM_train, MAG_train, R2S_train), axis = 1)\n",
    "data_train = np.stack((QSM_train,), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSM_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "MAG_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "R2S_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "label_test = np.empty(((n_test,) + matrix_size), dtype=precision_global)\n",
    "for i, case_idx in enumerate(idxs_test):\n",
    "    QSM_test[i, :, :, :] = read_data(case_idx, 'QSM')\n",
    "    MAG_test[i, :, :, :] = read_data(case_idx, 'MAG')\n",
    "    R2S_test[i, :, :, :] = read_data(case_idx, 'R2S')\n",
    "    label_test[i, :, :, :] = read_data(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test = np.stack((QSM_test, MAG_test, R2S_test), axis = 1)\n",
    "data_test = np.stack((QSM_test,), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intensity normalisation (zero mean and unit variance)\n",
    "input_mean = 127.0\n",
    "input_std = 128.0\n",
    "data_train = (data_train - input_mean) / input_std\n",
    "data_test = (data_test - input_mean) / input_std\n",
    "\n",
    "# Map class label\n",
    "tmp = np.copy(label_train)\n",
    "for class_idx in class_mapper:\n",
    "    label_train[tmp == class_idx] = class_mapper[class_idx]\n",
    "tmp = np.copy(label_test)\n",
    "for class_idx in class_mapper:\n",
    "    label_test[tmp == class_idx] = class_mapper[class_idx]\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEACAYAAABBOusMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b8d6bfb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0,:,:,[29,25]]), scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10850, 1, 27, 27, 21), (10850, 243, 11))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Configure callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping for reducing over-fitting risk\n",
    "stopper = EarlyStopping(patience=patience, monitor='val_categorical_accuracy')\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('1'),\n",
    "    monitor='val_categorical_accuracy',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_categorical_accuracy', \n",
    "                                            patience=patience, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.1, \n",
    "                                            min_lr=1e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8680 samples, validate on 2170 samples\n",
      "Epoch 1/40\n",
      "8680/8680 [==============================] - 52s 6ms/step - loss: 0.6949 - categorical_accuracy: 0.8071 - val_loss: 0.5322 - val_categorical_accuracy: 0.8379\n",
      "Epoch 2/40\n",
      "8680/8680 [==============================] - 52s 6ms/step - loss: 0.2574 - categorical_accuracy: 0.9113 - val_loss: 0.3430 - val_categorical_accuracy: 0.8872\n",
      "Epoch 3/40\n",
      "8680/8680 [==============================] - 53s 6ms/step - loss: 0.1247 - categorical_accuracy: 0.9494 - val_loss: 0.6736 - val_categorical_accuracy: 0.8805\n",
      "Epoch 4/40\n",
      "8680/8680 [==============================] - 54s 6ms/step - loss: 0.0937 - categorical_accuracy: 0.9617 - val_loss: 0.5185 - val_categorical_accuracy: 0.8925\n",
      "Epoch 5/40\n",
      "8680/8680 [==============================] - 53s 6ms/step - loss: 0.0670 - categorical_accuracy: 0.9726 - val_loss: 0.6284 - val_categorical_accuracy: 0.8909\n",
      "Epoch 6/40\n",
      "8680/8680 [==============================] - 54s 6ms/step - loss: 0.0507 - categorical_accuracy: 0.9795 - val_loss: 0.6536 - val_categorical_accuracy: 0.8877\n",
      "Epoch 7/40\n",
      "8680/8680 [==============================] - 54s 6ms/step - loss: 0.0374 - categorical_accuracy: 0.9851 - val_loss: 0.8111 - val_categorical_accuracy: 0.8876\n",
      "Epoch 8/40\n",
      "8680/8680 [==============================] - 55s 6ms/step - loss: 0.0270 - categorical_accuracy: 0.9894 - val_loss: 0.8614 - val_categorical_accuracy: 0.8871\n",
      "Epoch 9/40\n",
      "8680/8680 [==============================] - 55s 6ms/step - loss: 0.0258 - categorical_accuracy: 0.9902 - val_loss: 0.9052 - val_categorical_accuracy: 0.8821\n",
      "Epoch 10/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 0.0210 - categorical_accuracy: 0.9922\n",
      "Epoch 00010: reducing learning rate to 0.00010000000474974513.\n",
      "8680/8680 [==============================] - 55s 6ms/step - loss: 0.0210 - categorical_accuracy: 0.9922 - val_loss: 0.9860 - val_categorical_accuracy: 0.8909\n",
      "Epoch 11/40\n",
      "8680/8680 [==============================] - 55s 6ms/step - loss: 0.0039 - categorical_accuracy: 0.9988 - val_loss: 1.1417 - val_categorical_accuracy: 0.8904\n",
      "Epoch 12/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 0.0012 - categorical_accuracy: 0.9998 - val_loss: 1.2175 - val_categorical_accuracy: 0.8904ss: 0.0015 - categorical_acc - ETA: 3 - E - ETA: 1s - loss: 0.0012 - categorica\n",
      "Epoch 13/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 6.0015e-04 - categorical_accuracy: 0.9999 - val_loss: 1.2644 - val_categorical_accuracy: 0.890810e-04 - ETA: 3s - loss: 6.1\n",
      "Epoch 14/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 3.2742e-04 - categorical_accuracy: 1.0000 - val_loss: 1.3151 - val_categorical_accuracy: 0.8903\n",
      "Epoch 15/40\n",
      "8672/8680 [============================>.] - ETA: 0s - loss: 1.9480e-04 - categorical_accuracy: 1.0000 ETA: 3s - loss: 1.9649e-04 - cate - ETA: 0s - loss: 1.9571e-04 - categorical_accuracy\n",
      "Epoch 00015: reducing learning rate to 1.0000000474974514e-05.\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 1.9485e-04 - categorical_accuracy: 1.0000 - val_loss: 1.3378 - val_categorical_accuracy: 0.8906\n",
      "Epoch 16/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 1.3812e-04 - categorical_accuracy: 1.0000 - val_loss: 1.3471 - val_categorical_accuracy: 0.8903\n",
      "Epoch 17/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 1.3082e-04 - categorical_accuracy: 1.0000 - val_loss: 1.3505 - val_categorical_accuracy: 0.8903\n",
      "Epoch 18/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 1.2445e-04 - categorical_accuracy: 1.0000 - val_loss: 1.3536 - val_categorical_accuracy: 0.8903\n",
      "Epoch 19/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 1.1797e-04 - categorical_accuracy: 1.0000 - val_loss: 1.3569 - val_categorical_accuracy: 0.8903\n",
      "Epoch 20/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 1.1133e-04 - categorical_accuracy: 1.0000 - val_loss: 1.3613 - val_categorical_accuracy: 0.8902\n",
      "Epoch 21/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 1.0450e-04 - categorical_accuracy: 1.0000 - val_loss: 1.3644 - val_categorical_accuracy: 0.8903.0239e-04 - categ - ETA - ETA: 2s - loss: 1.0349e-04 \n",
      "Epoch 22/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 9.7531e-05 - categorical_accuracy: 1.0000 - val_loss: 1.3701 - val_categorical_accuracy: 0.8902\n",
      "Epoch 23/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 9.0386e-05 - categorical_accuracy: 1.0000 - val_loss: 1.3770 - val_categorical_accuracy: 0.8902loss: 8.8504 - ETA: 8s - ETA: 3s - loss: 9.0551e-0\n",
      "Epoch 24/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 8.3359e-05 - categorical_accuracy: 1.0000 - val_loss: 1.3806 - val_categorical_accuracy: 0.8902\n",
      "Epoch 25/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 7.6415e-05 - categorical_accuracy: 1.0000 - val_loss: 1.3865 - val_categorical_accuracy: 0.8902\n",
      "Epoch 26/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 6.9527e-05 - categorical_accuracy: 1.0000 - val_loss: 1.3909 - val_categorical_accuracy: 0.8902\n",
      "Epoch 27/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 6.2893e-05 - categorical_accuracy: 1.0000 - val_loss: 1.3954 - val_categorical_accuracy: 0.8902ss: 6.2857e-05 - categori\n",
      "Epoch 28/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 5.6510e-05 - categorical_accuracy: 1.0000 - val_loss: 1.4037 - val_categorical_accuracy: 0.8901 ETA: 34s - loss: 5.5366e-05 -  - ETA: 29s - ETA - ETA: 2s - loss: 5.6698e-05 \n",
      "Epoch 29/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 5.0478e-05 - categorical_accuracy: 1.0000 - val_loss: 1.4099 - val_categorical_accuracy: 0.8901\n",
      "Epoch 30/40\n",
      "8680/8680 [==============================] - 56s 6ms/step - loss: 4.4863e-05 - categorical_accuracy: 1.0000 - val_loss: 1.4131 - val_categorical_accuracy: 0.8902\n",
      "Epoch 31/40\n",
      "8680/8680 [==============================] - 55s 6ms/step - loss: 3.9610e-05 - categorical_accuracy: 1.0000 - val_loss: 1.4206 - val_categorical_accuracy: 0.8901\n",
      "Epoch 32/40\n",
      "8680/8680 [==============================] - 55s 6ms/step - loss: 3.4861e-05 - categorical_accuracy: 1.0000 - val_loss: 1.4280 - val_categorical_accuracy: 0.8901\n",
      "Epoch 33/40\n",
      "8680/8680 [==============================] - 53s 6ms/step - loss: 3.0449e-05 - categorical_accuracy: 1.0000 - val_loss: 1.4324 - val_categorical_accuracy: 0.8901\n",
      "Epoch 34/40\n",
      "8680/8680 [==============================] - 53s 6ms/step - loss: 2.6531e-05 - categorical_accuracy: 1.0000 - val_loss: 1.4394 - val_categorical_accuracy: 0.8901\n",
      "Epoch 35/40\n",
      "5120/8680 [================>.............] - ETA: 22s - loss: 2.3017e-05 - categorical_accuracy: 1.0000- ETA: 26s - loss: 2.3406e-05 - catego"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5a708a9c79b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     callbacks=callbacks)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# freeing space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(model_filename.format(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_patch = extract_patches(read_data(1, 'QSM'), patch_shape=segment_size, extraction_step=(9, 9, 3)).shape[0]\n",
    "len_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3300/3300 [==============================] - 3s 825us/step\n",
      "2\n",
      "3300/3300 [==============================] - 2s 752us/step\n",
      "3\n",
      "3300/3300 [==============================] - 2s 749us/step\n",
      "4\n",
      "3300/3300 [==============================] - 2s 757us/step\n",
      "5\n",
      "3300/3300 [==============================] - 2s 753us/step\n",
      "6\n",
      "3300/3300 [==============================] - 2s 757us/step\n",
      "7\n",
      "3300/3300 [==============================] - 3s 768us/step\n",
      "8\n",
      "3300/3300 [==============================] - 3s 758us/step\n",
      "9\n",
      "3300/3300 [==============================] - 3s 766us/step\n",
      "10\n",
      "3300/3300 [==============================] - 3s 763us/step\n",
      "11\n",
      "3300/3300 [==============================] - 3s 765us/step\n",
      "12\n",
      "3300/3300 [==============================] - 3s 762us/step\n",
      "13\n",
      "3300/3300 [==============================] - 2s 755us/step\n",
      "14\n",
      "3300/3300 [==============================] - 3s 764us/step\n",
      "15\n",
      "3300/3300 [==============================] - 3s 761us/step\n",
      "16\n",
      "3300/3300 [==============================] - 3s 765us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_train = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_training):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_train = data_train[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_train[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    \n",
    "    segmentations_train = segmentations_train + [segmentation]\n",
    "    \n",
    "segmentations_train = np.stack(segmentations_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB50gGBd8oorSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b78866a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAQAgEJIBACAQkgEAIPh/D3HDE2aCrKkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b7883e6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_train[0:15,:,:,25]), rows=3, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Check false-positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_fpos = (label_train == 0) & (segmentations_train != 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_fpos = np.zeros(label_train.shape, dtype=precision_global)\n",
    "mask_fpos[idx_fpos == True] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFOCAYAAAB0aIAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b4a65b2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(200*(np.squeeze(mask_fpos[0:15,:,:,25])), rows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Rebuild training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((35450, 1, 27, 27, 21), (35450, 243, 11))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = build_set(data_train, label_train, extraction_step, segment_size, core_size, mask_fpos)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tmp/x_train.bc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-7e5543c9d0cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp/x_train.bc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp/y_train.bc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/segDGM_3DCNN/utils.py\u001b[0m in \u001b[0;36msave_array\u001b[0;34m(file_name, arr)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrootdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray.__cinit__ (bcolz/carray_ext.c:14817)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray._create_carray (bcolz/carray_ext.c:16431)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray._mkdirs (bcolz/carray_ext.c:18455)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmp/x_train.bc'"
     ]
    }
   ],
   "source": [
    "save_array('tmp/x_train.bc', x_train)\n",
    "save_array('tmp/y_train.bc', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_array('tmp/x_train.bc')\n",
    "y_train = load_array('tmp/y_train.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Regenerate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping for reducing over-fitting risk\n",
    "stopper = EarlyStopping(patience=patience, monitor='val_categorical_accuracy')\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format('2'),\n",
    "    monitor='val_categorical_accuracy',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_categorical_accuracy', \n",
    "                                            patience=patience, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.1, \n",
    "                                            min_lr=1e-5)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28360 samples, validate on 7090 samples\n",
      "Epoch 1/40\n",
      "28360/28360 [==============================] - 173s 6ms/step - loss: 0.0222 - categorical_accuracy: 0.9911 - val_loss: 0.3386 - val_categorical_accuracy: 0.9587\n",
      "Epoch 2/40\n",
      "28360/28360 [==============================] - 173s 6ms/step - loss: 0.0125 - categorical_accuracy: 0.9950 - val_loss: 0.3928 - val_categorical_accuracy: 0.9575\n",
      "Epoch 3/40\n",
      "28360/28360 [==============================] - 174s 6ms/step - loss: 0.0092 - categorical_accuracy: 0.9964 - val_loss: 0.4412 - val_categorical_accuracy: 0.9569\n",
      "Epoch 4/40\n",
      "28360/28360 [==============================] - 174s 6ms/step - loss: 0.0067 - categorical_accuracy: 0.9974 - val_loss: 0.4304 - val_categorical_accuracy: 0.9578\n",
      "Epoch 5/40\n",
      "28360/28360 [==============================] - 175s 6ms/step - loss: 0.0049 - categorical_accuracy: 0.9981 - val_loss: 0.4656 - val_categorical_accuracy: 0.9576\n",
      "Epoch 6/40\n",
      "28360/28360 [==============================] - 175s 6ms/step - loss: 0.0037 - categorical_accuracy: 0.9986 - val_loss: 0.4867 - val_categorical_accuracy: 0.9572\n",
      "Epoch 7/40\n",
      "28352/28360 [============================>.] - ETA: 0s - loss: 0.0029 - categorical_accuracy: 0.9990\n",
      "Epoch 00007: reducing learning rate to 1e-05.\n",
      "28360/28360 [==============================] - 177s 6ms/step - loss: 0.0029 - categorical_accuracy: 0.9990 - val_loss: 0.5324 - val_categorical_accuracy: 0.9566\n",
      "Epoch 8/40\n",
      "28360/28360 [==============================] - 179s 6ms/step - loss: 8.7253e-04 - categorical_accuracy: 0.9998 - val_loss: 0.5226 - val_categorical_accuracy: 0.9574\n",
      "Epoch 9/40\n",
      " 7232/28360 [======>.......................] - ETA: 2:10 - loss: 6.3249e-04 - categorical_accuracy: 0.9999"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-083c987d114d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     callbacks=callbacks)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# freeing space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "\n",
    "# Load optimized weights\n",
    "model.load_weights(model_filename.format('1'))\n",
    "\n",
    "K.set_value(model.optimizer.lr, 1e-4)\n",
    "\n",
    "# Start fine-tuning\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "#del x_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(model_filename.format('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = generate_model(num_classes, num_channel, segment_size, core_size)\n",
    "model.load_weights(model_filename.format('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "3300/3300 [==============================] - 3s 813us/step\n",
      "18\n",
      "3300/3300 [==============================] - 2s 750us/step\n",
      "19\n",
      "3300/3300 [==============================] - 3s 759us/step\n",
      "20\n",
      "3300/3300 [==============================] - 2s 756us/step\n"
     ]
    }
   ],
   "source": [
    "segmentations_test = []\n",
    "\n",
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "\n",
    "    print(case_idx)\n",
    "    input_test = data_test[i_case, :, :, :, :]\n",
    "\n",
    "    x_test = np.zeros((len_patch, num_channel,) + segment_size, dtype=precision_global)\n",
    "    for i_channel in range(num_channel):\n",
    "        x_test[:, i_channel, :, :, :] = extract_patches(input_test[i_channel], patch_shape=segment_size, extraction_step=(9, 9, 3))\n",
    "\n",
    "    pred = model.predict(x_test, verbose=1)\n",
    "    pred_classes = np.argmax(pred, axis=2)\n",
    "    pred_classes = pred_classes.reshape((len(pred_classes), 9, 9, 3))\n",
    "    segmentation = reconstruct_volume(pred_classes, matrix_size)\n",
    "    \n",
    "    segmentations_test = segmentations_test + [segmentation]\n",
    "    \n",
    "segmentations_test = np.stack(segmentations_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABk5JREFUeJzt3dFN41oQgGH7iiYQZUAZEWWQMlDK2JSBKCMpA1GG7wMy\nhCFOnBDiMz7f98TCSmtpR0c/g23arusaAADgy39TXwAAAJRGJAMAQCCSAQAgEMkAABCIZAAACEQy\nAAAEIhkAAAKRDAAAgUgGAIDgZuoLaJqmadvWr/3j17qua6/9b5pdLsHsktW1Z9fccglj59YmGQAA\nApEMAACBSAYAgEAkAwBAIJIBACAQyQAAEIhkAAAIRDIAAAQiGQAAApEMAACBSAYAgEAkAwBAIJIB\nACAQyQAAEIhkAAAIRDIAAAQiGQAAApEMAACBSAYAgEAkAwBAIJIBACAQyQAAEIhkAAAIRDIAAAQi\nGQAAApEMAACBSAYAgEAkAwBAIJIBACAQyQAAEIjkAm02m2az2Ux9GQAA1bqZ+gIYti+UHx4eJrgS\nAIC6tF3XTX0NTdu2019EoYY2ymL5p67r2mv/m2aXSzC7ZHXt2TW3XMLYuRXJBfn379/ezy+Xy8+P\nYzSL5S9Cg6zMLlmJZDISyYkdi+VD2+XNZlNtOAsNsjK7ZCWSyUgkz8C+WD4Wyr0aQ1lokJXZLU88\nf3d/oscXkUxGY+fW2y2S6Q/uYxHs7RgAlzP0Ez5gvmySCzbmUD50v3Kvlq2ybRxZmd3yHDp/bZW/\n2CSTkU3yDJx6EA/FsK0ywGkOnb+2ylAHm+QEjh3IQ/cp17JB7tnGkZXZLZut8jCbZDLy4N7MnBLK\ntcVxT2iQldktn1DeTySTkdstKrPvgb6u65oSvgkCmDO3X8A8ieQkfrOpEMoAv1PzthhqdTP1BTDe\ncrkctbEQxVzb09PT4NfW6/UVrwT+ztgzGJgHm+RkhrYZh7YcbXv12x2pzKEQPhTQkI2NMtTDg3uJ\n9RuN/tCO/5e1xbGHn8owFMU2ysPMbi6HfhtqbTy4N73dM9c5O87YuXW7RWK2xwDX5XYLSrNerz9D\nWTBflk0ys2EbN437+/tvf95utz+2yQ7rw8xuLjbJX2ySy+L5kHG8Ag6YzHq9/jyQHcxkc39//+Ob\nv121BjHl83zIZdkkMxu2cdPYjYntdjvhleRldsvSz7R5Ps4muVz7otjS4oN7koGrEBLMjZkGmsYm\nmRmxjSMrs0tWNslk5J5k4Kpub2+nvgQAuBibZGbDNm4aMY7f398nupK8zC5Z2SSTkXuSgavrA3mx\nWHz7/Ovr6xSXA1CleAb3nMWncbsFAMAMLBaLwUDuv854Nskz8vb21jRN09zd3U18JdQk3l5hiwxQ\nJufxaURyMs/Pz58fr1arvX+nj+WmEcxMx2FMLZ6fnwfPY5jS6+trs1gsnMdnEsmJ7QZz03wE8W4g\nN81HMAtl/truIewwZk72BUZ/9q5Wqx/nMEzhUAg7k8/n7RaJHDuM+01GDOWmqWOj7A0BZGV2y3Uo\nkqMat8nebkFG3pM8M6dsK/YF8b5wBuA0NsdQD5GcwJhDOW4w7u7uqtgeA/ylsT+qrnGLDHMnkgt3\nTiADcHlus4C6eHCvYKf+WO/l5eXbnx8fHz8/tlUGOJ/bLKA+IrlQYw/k1Wr1I453iWOA8419YBqY\nH2+3KNDYWywOxXFvd5s8d94QQFZmtzzieBxvtyCjsXNrk1yYSwYyAJcljqEeNsmFuHQc17RB7tnG\nkZXZLcu+81gc72eTTEY2yTOweyi/vLwIZIArE8dQL5vkAhyL3z56h/6eKP5gG0dWZpesbJLJyG/c\nAwCAM9kkF6jfGNsQn8Y2jqzMLlnZJJPR2LkVycyG0CArs0tWIpmM3G4BAABnEskAABCIZAAACEQy\nAAAEIhkAAAKRDAAAgUgGAIBAJAMAQCCSAQAgEMkAABCIZAAACEQyAAAEIhkAAAKRDAAAgUgGAIBA\nJAMAQCCSAQAgEMkAABCIZAAACEQyAAAEIhkAAAKRDAAAgUgGAIBAJAMAQCCSAQAgEMkAABCIZAAA\nCEQyAAAEIhkAAAKRDAAAgUgGAIBAJAMAQNB2XTf1NQAAQFFskgEAIBDJAAAQiGQAAAhEMgAABCIZ\nAAACkQwAAIFIBgCAQCQDAEAgkgEAIBDJAAAQiGQAAAhEMgAABCIZAAACkQwAAIFIBgCAQCQDAEAg\nkgEAIBDJAAAQiGQAAAhEMgAABCIZAAACkQwAAIFIBgCA4H9fJbHxJa5xTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b494f82e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(label_test[:,:,:,27]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACMCAYAAACOPzQbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b48cc74a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(np.squeeze(segmentations_test[:,:,:,27]), rows=1, scale = (0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pick the largest connected component for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    segmentation = np.squeeze(segmentations_test[i_case,:,:,:]);\n",
    "    tmp = np.zeros(segmentation.shape, dtype=segmentation.dtype)\n",
    "    \n",
    "    for class_idx in class_mapper_inv :\n",
    "        mask = (segmentation == class_idx)\n",
    "        \n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            labeled_mask, num_cc = ndimage.label(mask)\n",
    "            largest_cc_mask = (labeled_mask == (np.bincount(labeled_mask.flat)[1:].argmax() + 1))\n",
    "            \n",
    "            tmp[largest_cc_mask == 1] = class_idx\n",
    "        \n",
    "    segmentations_test[i_case,:,:,:] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Done with Step 3\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx)\n",
    "    \n",
    "    segmentation = np.squeeze(segmentations_test[i_case,:,:,:]);\n",
    "\n",
    "    save_data(segmentation, case_idx, 'label')    \n",
    "\n",
    "print(\"Done with Step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Calculate metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(m1, m2):\n",
    "    return 2*((m1==1) & (m2==1)).sum()/((m1==1).sum() + (m2==1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\t0.9991\tN/A\t0.9167\t0.9231\t0.8436\t0.7955\t0.7045\t0.8865\t0.8592\t0.8307\t0.9529\t0.8426\t\n",
      "18\t0.9990\tN/A\t1.0000\t1.0000\t0.8381\t0.9310\t0.7935\t0.7741\t0.8553\t0.7827\t0.7366\t0.8000\t\n",
      "19\t0.9992\tN/A\t0.8776\t0.8929\t0.9257\t0.8804\t0.9678\t0.9598\t0.8530\t0.8526\t0.6609\t0.8028\t\n",
      "20\t0.9987\tN/A\t0.9655\t0.8571\t0.9500\t0.9105\t0.9532\t0.9507\t0.6842\t0.6552\t0.8274\t0.7791\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    print('{:.4f}'.format(accuracy_score(label_test[i_case,:,:,:].flat, segmentations_test[i_case,:,:,:].flat)), end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(precision_score(label_test[i_case,:,:,:][mask], segmentations_test[i_case,:,:,:][mask], average='micro')), end='\\t')\n",
    "        else:\n",
    "            print('N/A', end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\t0\t0.8652\t0.7792\t0.8830\t0.8615\t0.7977\t0.8872\t0.8359\t0.8591\t0.6901\t0.8273\t\n",
      "18\t0\t0.0323\t0.0351\t0.7586\t0.8282\t0.8394\t0.8392\t0.6167\t0.6638\t0.7607\t0.7918\t\n",
      "19\t0\t0.8600\t0.8403\t0.7784\t0.7845\t0.8931\t0.8760\t0.7789\t0.8676\t0.5560\t0.6196\t\n",
      "20\t0\t0.9333\t0.8054\t0.7056\t0.8847\t0.7467\t0.7940\t0.6360\t0.6860\t0.6113\t0.6513\t\n"
     ]
    }
   ],
   "source": [
    "for i_case, case_idx in enumerate(idxs_test):\n",
    "    print(case_idx, end='\\t')\n",
    "    for class_idx in class_mapper_inv:\n",
    "        mask = (np.squeeze(segmentations_test[i_case,:,:,:]) == class_idx)\n",
    "        if class_idx != 0 and mask.sum() > 0:\n",
    "            print('{:.4f}'.format(calc_dice((label_test[i_case,:,:,:]==class_idx).flat, (segmentations_test[i_case,:,:,:]==class_idx).flat)), end='\\t')\n",
    "        else:\n",
    "            print(0, end='\\t')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
